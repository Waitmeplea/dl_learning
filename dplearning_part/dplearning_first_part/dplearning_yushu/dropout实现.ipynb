{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-18T02:30:22.587718Z",
     "start_time": "2025-03-18T02:25:40.192581Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "import sys\n",
    "\n",
    "sys.path.append('book_material')\n",
    "from dataset.mnist import *\n",
    "(x_train, t_train), (x_test, t_test) = load_mnist(normalize=True, one_hot_label = True)\n",
    "\n",
    "##wb是模型本身的参数因此放在构造函数中无需手动进行更改 其他则由输入的x决定\n",
    "class Affine:\n",
    "    def __init__(self,w,b):\n",
    "        self.w=w\n",
    "        self.b=b\n",
    "        self.x=None\n",
    "        self.dw=None\n",
    "        self.db=None\n",
    "        self.dx=None\n",
    "    def forward(self,x):\n",
    "        if x.ndim==1:\n",
    "            x = x.reshape(1,-1)\n",
    "        self.x=x\n",
    "        output=np.dot(self.x, self.w)+self.b\n",
    "        return output\n",
    "    def backward(self,d_out):\n",
    "\n",
    "        self.dx=np.dot(d_out,self.w.T)\n",
    "        self.dw=np.dot(self.x.T,d_out)\n",
    "        self.db=np.sum(d_out,axis=0)\n",
    "        return self.dx\n",
    "\n",
    "class Relu:\n",
    "    def __init__(self):\n",
    "        self.mask=None\n",
    "    def forward(self,x):\n",
    "        self.mask=x>0\n",
    "        out=self.mask*x\n",
    "        return out\n",
    "    def backward(self,d_out):\n",
    "        dx=self.mask*d_out\n",
    "        return dx\n",
    "\n",
    "\n",
    "\n",
    "class Softmaxwithloss:\n",
    "    def __init__(self):\n",
    "        self.t=None\n",
    "        self.x=None\n",
    "        self.y=None\n",
    "        self.dx=None\n",
    "        self.batch_size = None\n",
    "        self.w_rate=0.1\n",
    "        self.w=None\n",
    "    def forward(self,x):\n",
    "        if x.ndim==1:\n",
    "            x = x.reshape(1,-1)\n",
    "        self.x=x-np.max(x,axis=-1,keepdims=True)\n",
    "        self.batch_size = x.shape[0]\n",
    "        self.y=np.exp(self.x)/np.sum(np.exp(self.x),axis=-1,keepdims=True)\n",
    "\n",
    "        return self.y\n",
    "    def loss(self,x,t):\n",
    "\n",
    "\n",
    "\n",
    "        out=self.forward(x)\n",
    "        self.t=t\n",
    "        if t.ndim!=1:\n",
    "            loss_rate=np.sum(-self.t*np.log(out+1e-7))/self.batch_size\n",
    "        else:\n",
    "            loss_rate=-np.sum(np.log(out[np.arange(len(t)),t]+1e-7))/self.batch_size\n",
    "\n",
    "\n",
    "        return  loss_rate\n",
    "\n",
    "    def backward(self,t=None):\n",
    "\n",
    "        self.t=t\n",
    "        if self.t.ndim!=1:\n",
    "            dx = (self.y - self.t) / self.batch_size\n",
    "        else:\n",
    "            y_c=self.y.copy()\n",
    "\n",
    "            y_c[np.arange(len(self.t)),self.t] -=1\n",
    "            dx=y_c/self.batch_size\n",
    "\n",
    "        self.dx=dx\n",
    "\n",
    "        return self.dx\n",
    "\n",
    "class dropout:\n",
    "    def __init__(self, rate=0.1):\n",
    "        self.rate = rate\n",
    "        self.mask = None\n",
    "        self.mode= 'train'\n",
    "    def forward(self, x):\n",
    "        if self.mode=='train':\n",
    "            self.mode = 'train'\n",
    "            self.mask = np.random.binomial(1,1-self.rate,size=x.shape)\n",
    "            out = x*np.true_divide(self.mask,(1-self.rate))\n",
    "        else:\n",
    "            self.mode = 'test'\n",
    "            self.mask = np.ones(x.shape)\n",
    "            out=x\n",
    "        return out\n",
    "\n",
    "    def backward(self, d_out):\n",
    "        ###正向的时候 x m*n维  mask是m*n维 输出 m*n维 逐元素相乘\n",
    "        ###反向传播的时候 d_out m*n维 同样也是逐元素相乘\n",
    "        return d_out * self.mask\n",
    "\n",
    "\n",
    "\n",
    "class MultiLayersNetwork:\n",
    "    def __init__(self, input_size, output_size,rate=0.1 ,hidden_size_list=None,weight=1):\n",
    "        if hidden_size_list is None:\n",
    "            self.hidden_size_list = [100, 100, 100]\n",
    "        else:\n",
    "            self.hidden_size_list = hidden_size_list\n",
    "        self.input_size = input_size\n",
    "\n",
    "        self.output_size = output_size\n",
    "        self.params=dict()\n",
    "        self.sourcedata=None\n",
    "        self.layers= dict()\n",
    "        self.weight=weight\n",
    "        self.w_dict=None\n",
    "        self.rate=rate\n",
    "        self.input_detail={}\n",
    "        #生成层\n",
    "        parameter_size_list=self.hidden_size_list\n",
    "        parameter_size_list.insert(0,input_size)\n",
    "        parameter_size_list.append(self.output_size)\n",
    "        self.hidden_size_list=parameter_size_list\n",
    "\n",
    "        for i in range(len(parameter_size_list) - 1): # 遍历所有 Affine 层\n",
    "            scale = np.sqrt(self.weight / parameter_size_list[i])\n",
    "            self.params['W' + str(i)] = np.random.randn(parameter_size_list[i], parameter_size_list[i + 1]) * scale # 使用 randn 初始化\n",
    "            self.params['b' + str(i)] = np.zeros(parameter_size_list[i + 1]) # 偏置初始化为 0\n",
    "            self.layers['affine' + str(i)] = Affine(self.params['W' + str(i)], self.params['b' + str(i)])\n",
    "\n",
    "            if i < len(parameter_size_list) - 2: # 除了最后一层 Affine，都添加 Relu 和dropout层\n",
    "                self.layers['dropout' + str(i)] = dropout(self.rate)\n",
    "                self.layers['relu' + str(i)] = Relu()\n",
    "\n",
    "            else: # 最后一层 Affine 之后添加 Softmaxwithloss\n",
    "                self.layers['Activation_function'] = Softmaxwithloss()\n",
    "\n",
    "\n",
    "\n",
    "    def set_dropout_mode(self,mode):\n",
    "        if mode=='train':\n",
    "            pass\n",
    "        else:\n",
    "            for i in self.layers.keys():\n",
    "                if isinstance(self.layers[i],dropout):\n",
    "                    self.layers[i].mode=mode\n",
    "\n",
    "    def predict(self, x):\n",
    "        inputs=x\n",
    "        for key,func in self.layers.items():\n",
    "            inputs=func.forward(inputs)\n",
    "            self.input_detail[key]=inputs\n",
    "        return inputs\n",
    "\n",
    "    def loss(self,x,t,weight_decay_lambda=0):\n",
    "        w_decay=0\n",
    "        for w_key in self.params.keys():\n",
    "            if 'W' in w_key:\n",
    "                w_decay += 0.5*weight_decay_lambda * np.sum(self.params[w_key]**2)\n",
    "\n",
    "        inputs=x\n",
    "        for key,func in self.layers.items():\n",
    "            if key=='Activation_function':\n",
    "                loss_value=func.loss(inputs,t)+w_decay\n",
    "            else:\n",
    "                inputs=func.forward(inputs)\n",
    "\n",
    "\n",
    "\n",
    "        return loss_value\n",
    "\n",
    "    def backward(self,t,d_out=1):\n",
    "\n",
    "        back_list=list(self.layers.keys())\n",
    "        back_list.reverse()\n",
    "        d_out=d_out\n",
    "        for key in back_list:\n",
    "            if key=='Activation_function':\n",
    "\n",
    "                d_out=self.layers[key].backward(t=t)\n",
    "\n",
    "            else:\n",
    "                d_out=self.layers[key].backward(d_out)\n",
    "\n",
    "    def gradient(self,t,weight_decay_lambda=0):\n",
    "\n",
    "        self.backward(d_out=1,t=t)\n",
    "        grads=dict()\n",
    "        for idx in range(len(self.hidden_size_list)-1):\n",
    "            grads['W'+str(idx)]=self.layers['affine'+str(idx)].dw+weight_decay_lambda*(self.params['W'+str(idx)])\n",
    "            grads['b'+str(idx)]=self.layers['affine'+str(idx)].db\n",
    "        return grads\n",
    "    def accuracy(self,x,t):\n",
    "        if t.ndim!=1: t=np.argmax(t,axis=1)\n",
    "        y=np.argmax(self.predict(x),axis=1)\n",
    "        return np.sum(y==t)/y.shape[0]\n",
    "\n",
    "\n",
    "### 总结 当训练集过少次数过低的时候 难以过拟合 所以使用正则手段没用 \n",
    "mln7=MultiLayersNetwork(input_size=784,output_size=10,rate=0.1,hidden_size_list=[100,100,100,100,100,100,100,100,100],weight=2)\n",
    "\n",
    "mask=np.random.choice(60000,size=10000)\n",
    "x_mask=x_train[mask]\n",
    "t_mask=t_train[mask]\n",
    "loss_list=[]\n",
    "mln7.set_dropout_mode('test')\n",
    "for i in range(1000):\n",
    "    loss_list.append(mln7.loss(x_mask,t_mask,weight_decay_lambda=0.0))\n",
    "    grads=mln7.gradient(t=t_mask)\n",
    "    for key in grads.keys():\n",
    "        mln7.params[key] -=0.1*grads[key]\n",
    "mln7.set_dropout_mode('test')\n",
    "mln7.accuracy(x_test,t_test)"
   ],
   "id": "a4dca2dea2de5c3a",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9434"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 108
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-18T02:25:04.522900Z",
     "start_time": "2025-03-18T02:25:04.497192Z"
    }
   },
   "cell_type": "code",
   "source": "mln7.accuracy(x_mask,t_mask)",
   "id": "6da3b2908ae426d9",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 107
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "",
   "id": "65b3ee6644fe03c"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-18T02:24:07.133760Z",
     "start_time": "2025-03-18T02:24:07.122369Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "9248aef21eceb199",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 0. 2. 0. 2. 2. 0. 0. 0. 2. 0. 0. 0. 0. 0. 2. 2. 0. 2. 0. 2. 0. 0. 0.\n",
      "  2. 0. 0. 2. 2. 2. 2. 0. 2. 0. 0. 2. 0. 2. 0. 2. 2. 2. 2. 0. 0. 0. 2. 0.\n",
      "  0. 0. 0. 2. 0. 2. 2. 2. 2. 0. 0. 2. 0. 0. 0. 2. 0. 2. 2. 2. 0. 2. 2. 2.\n",
      "  0. 2. 0. 0. 0. 0. 2. 0. 0. 2. 2. 0. 2. 2. 2. 2. 2. 2. 2. 2. 2. 0. 2. 0.\n",
      "  2. 0. 0. 0.]]\n"
     ]
    }
   ],
   "execution_count": 105
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-18T02:22:44.646963Z",
     "start_time": "2025-03-18T02:22:44.641266Z"
    }
   },
   "cell_type": "code",
   "source": "mln7.input_detail['affine6']",
   "id": "17bc7490448e4f0b",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.18548159, -0.00616037,  0.08482984, ..., -0.12593171,\n",
       "        -0.09261184,  0.21550057],\n",
       "       [-0.32329175,  0.05640867, -0.27356264, ..., -0.54540084,\n",
       "        -0.28913599,  0.72764212],\n",
       "       [-0.0599832 ,  0.11419436, -0.23372228, ..., -0.21511901,\n",
       "        -0.12375964,  0.25477153],\n",
       "       ...,\n",
       "       [-0.14460058,  0.0633298 , -0.09135575, ..., -0.21712407,\n",
       "        -0.12749988,  0.26417222],\n",
       "       [-0.08824096,  0.24601549, -0.27485167, ..., -0.29114132,\n",
       "        -0.3333861 ,  0.4019106 ],\n",
       "       [ 0.24132348,  0.69647077, -1.02724083, ..., -0.58827353,\n",
       "        -0.62175684,  1.10057868]])"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 99
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "568a8522a03f102b"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
