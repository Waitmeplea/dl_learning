{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-05-21T13:01:08.501821Z",
     "start_time": "2025-05-21T13:01:04.358315Z"
    }
   },
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "\n",
    "src, tgt = tokenize_nmt(preprocess_nmt(read_data_nmt()),num_examples=600)\n",
    "src_vocab = Vocal(src, min_feq=2,\n",
    "                  reserved_tokens=['<pad>', '<bos>', '<eos>'])\n",
    "tgt_vocab = Vocal(tgt, min_feq=2,\n",
    "                  reserved_tokens=['<pad>', '<bos>', '<eos>'])\n",
    "src_data, src_valid = build_array_nmt(src, src_vocab, 10)\n",
    "tgt_data, tgt_valid = build_array_nmt(tgt, tgt_vocab, 10)\n",
    "dataset = torch.utils.data.TensorDataset(src_data, src_valid, tgt_data, tgt_valid)\n",
    "## 训练数据\n",
    "train_data = torch.utils.data.DataLoader(dataset=dataset, batch_size=64, shuffle=False)"
   ],
   "outputs": [],
   "execution_count": 17
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Bahdanau 注意力 只需要修改decoder部分",
   "id": "f5129c8ec1ef9a57"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-21T13:01:08.524854Z",
     "start_time": "2025-05-21T13:01:08.518130Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        super(Encoder, self).__init__()\n",
    "        pass\n",
    "\n",
    "    def forward(self, X, *args, **kwargs):\n",
    "        raise NotImplementedError\n",
    "\n",
    "\n",
    "class Decoder(nn.Module):\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        super(Decoder, self).__init__()\n",
    "        pass\n",
    "\n",
    "    def init_state(self, enc_outputs, *args, **kwargs):\n",
    "        raise NotImplementedError\n",
    "\n",
    "    def forward(self, X, state, *args, **kwargs):\n",
    "        raise NotImplementedError\n",
    "\n",
    "\n",
    "class EncoderDecoder(nn.Module):\n",
    "    def __init__(self, encoder, decoder, *args, **kwargs):\n",
    "        super(EncoderDecoder, self).__init__(*args, **kwargs)\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "\n",
    "    def forward(self, enc_x, dec_x, *args, **kwargs):\n",
    "        enc_outputs = self.encoder(enc_x, *args, **kwargs)\n",
    "        dec_state = self.decoder.init_state(enc_outputs, *args, **kwargs)\n",
    "        return self.decoder(dec_x, dec_state, *args, **kwargs)\n",
    "\n",
    "class Seq2SeqEncoder_hmy(Encoder):\n",
    "    \"\"\"输入一个x batch_size*num_steps或num_steps*batch_size \n",
    "    输出output batch_size num_steps \n",
    "    隐藏状态 numlayers * batch_size * hidden_size\"\"\"\n",
    "\n",
    "    def __init__(self, vocab_size, embed_size, hidden_size,num_layers, dropout=0.1, *args, **kwargs):\n",
    "        super(Seq2SeqEncoder_hmy, self).__init__(*args, **kwargs)\n",
    "        self.vocab_size = vocab_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.embed = nn.Embedding(vocab_size, embed_size)\n",
    "        self.rnn = nn.LSTM(embed_size, hidden_size,num_layers, dropout=dropout, batch_first=True)\n",
    "\n",
    "    def forward(self, X, *args, **kwargs):\n",
    "        embed_x = self.embed(X)\n",
    "        outputs, state = self.rnn(embed_x)\n",
    "        return outputs, state\n",
    "    \n",
    "\n",
    "class AdditiveAttention_hmy(nn.Module):\n",
    "    \"\"\"加性注意力\"\"\"\n",
    "    def __init__(self,key_size,query_size,num_hiddens,dropout,**kwargs):\n",
    "        super(AdditiveAttention_hmy,self).__init__(**kwargs)\n",
    "        self.W_k = nn.Linear(key_size,num_hiddens,bias=False)\n",
    "        self.W_q = nn.Linear(query_size,num_hiddens,bias=False)\n",
    "        self.W_v = nn.Linear(num_hiddens,1,bias=False)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "    # queries 维度应该是 batch_size * 要查询的数量 * q_size向量长度\n",
    "    # keys 维度是 batch_size * keys的数量（key-value)键值对 * key向量长度\n",
    "    # values与key相等 value_size可以不一样\n",
    "    def forward(self, queries, keys, values, valid_lens): ## valid_len从输入来的 屏蔽掉填充部分\n",
    "        queries,keys=self.W_q(queries),self.W_k(keys)\n",
    "        queries=queries.unsqueeze(2)\n",
    "        keys=keys.unsqueeze(1)\n",
    "        features = queries + keys\n",
    "        features = torch.tanh(features)\n",
    "        scores = self.W_v(features).squeeze(-1)\n",
    "        self.attention_weights = masked_softmax(scores, valid_lens)\n",
    "        attention_temp=self.dropout(self.attention_weights)\n",
    "        return torch.bmm(attention_temp, values)\n",
    "    \n",
    "    \n",
    "class AttentionDecoder(Decoder):\n",
    "    \"\"\"带有注意力机制解码器的基本接口\"\"\"\n",
    "    def __init__(self,**kwargs):\n",
    "        super(AttentionDecoder, self).__init__(**kwargs)\n",
    "    @property\n",
    "    def attention_weight(self):\n",
    "        raise NotImplementedError"
   ],
   "id": "3ee269894a468e8c",
   "outputs": [],
   "execution_count": 18
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-21T13:01:33.260498Z",
     "start_time": "2025-05-21T13:01:33.256301Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class Seq2SeqAttentionDecoder(AttentionDecoder):\n",
    "    \"\"\"通过encoder传来的原始序列的编码信息 进行解码翻译\"\"\"\n",
    "    def __init__(self,vocab_size,embed_size,num_hiddens,num_layers,dropout=0,**kwargs):\n",
    "        super(Seq2SeqAttentionDecoder, self).__init__(**kwargs)\n",
    "        self.attention=AdditiveAttention_hmy(num_hiddens,num_hiddens,num_hiddens,dropout=dropout)\n",
    "        \n",
    "        self.embedding=nn.Embedding(vocab_size,embed_size)\n",
    "        self.rnn=nn.LSTM(embed_size+num_hiddens,num_hiddens,num_layers,batch_first=True,dropout=dropout)\n",
    "        self.dense=nn.Linear(num_hiddens,vocab_size)\n",
    "\n",
    "    def init_state(self,encoder_out,enc_valid_lens,*args):\n",
    "        outputs,hidden_state=encoder_out\n",
    "        return outputs,hidden_state,enc_valid_lens\n",
    "\n",
    "    def forward(self,X,state,*args,**kwargs):\n",
    "        #ouputs batch_size,num_steps,num_hiddens\n",
    "        enc_outputs, hidden_state, enc_valid_lens = state\n",
    "        (H,C)=hidden_state\n",
    "        X=self.embedding(X).permute(1,0,2)\n",
    "        dec_outputs, self._attention_weights = [], []\n",
    "        for x in X:\n",
    "            #，unsqueeze(1) 这一步的目的就是为了给 Decoder 的顶层隐藏状态显式地添加一个维度，用来表示 Query 的数量 (在这个时间步是 1)，\n",
    "            # 从而使其形状符合 Attention 模块期望的 (batch_size, num_queries, feature_size) 输入格式，使得 Attention 模块可以正确地进行批处理和内部计算。\n",
    "            # query的形状为(batch_size,1,num_hiddens)\n",
    "            query=H[-1].unsqueeze(1)\n",
    "            # qkv 和q的有效长度\n",
    "            # query batch_size,1,num_hiddens\n",
    "            # context batch_size,num_steps,num_hiddens\n",
    "            context=self.attention(query,enc_outputs,enc_outputs,enc_valid_lens)\n",
    "            # x为batch_size,1,embed+hidden_size\n",
    "            x=torch.cat((context,x.unsqueeze(1)),dim=-1)\n",
    "            out,hidden_state=self.rnn(x,hidden_state)\n",
    "            dec_outputs.append(out)\n",
    "            self._attention_weights.append(self.attention.attention_weights)\n",
    "        dec_outputs = self.dense(torch.cat(dec_outputs, dim=1))\n",
    "        return dec_outputs, [enc_outputs, hidden_state,\n",
    "                                          enc_valid_lens]\n",
    "    @property\n",
    "    def attention_weights(self):\n",
    "        return self._attention_weights"
   ],
   "id": "40a1b347a1b82404",
   "outputs": [],
   "execution_count": 25
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-21T13:01:33.600609Z",
     "start_time": "2025-05-21T13:01:33.597608Z"
    }
   },
   "cell_type": "code",
   "source": [
    "encoder = Seq2SeqEncoder_hmy(vocab_size=10, embed_size=8, hidden_size=16,\n",
    "                             num_layers=2)\n",
    "\n",
    "decoder = Seq2SeqAttentionDecoder(vocab_size=10, embed_size=8, num_hiddens=16,\n",
    "                                  num_layers=2)"
   ],
   "id": "8a5c5f40fcd868db",
   "outputs": [],
   "execution_count": 26
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-21T13:01:33.942901Z",
     "start_time": "2025-05-21T13:01:33.941217Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "309dec60488126a8",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-21T13:01:34.421754Z",
     "start_time": "2025-05-21T13:01:34.409156Z"
    }
   },
   "cell_type": "code",
   "source": [
    "X = torch.zeros((4, 7), dtype=torch.long)  # (batch_size,num_steps)\n",
    "state = decoder.init_state(encoder(X), None)\n",
    "output, state = decoder(X, state)\n",
    "output.shape, len(state), state[0].shape, len(state[1]), state[1][0].shape"
   ],
   "id": "acd4f30acd7c6260",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([4, 7, 10]), 3, torch.Size([4, 7, 16]), 2, torch.Size([2, 4, 16]))"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 27
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-21T13:01:35.312144Z",
     "start_time": "2025-05-21T13:01:35.308706Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def sequence_mask(X, valid_len, value=0):\n",
    "    \"\"\"在序列中屏蔽不相关的项\"\"\"\n",
    "    # 首先x是二维的 最内层维度是句子长度 注意：是训练集所以才知道句子真实长度\n",
    "    # 拿出总的长度 得到长度\n",
    "    maxlen = X.shape[1]\n",
    "    # 然后用总长度生成一个1维的向量 使用函数扩展成2维以便与valid_len进行广播\n",
    "    mask = torch.unsqueeze(torch.arange(0, maxlen, dtype=torch.long), dim=0)\n",
    "    # mask在0维度扩充 valid在1维度扩充 因为每一个valid对应的是每一个x valid的数字其实是x的第二维向量\n",
    "    mask = (mask < torch.unsqueeze(valid_len, dim=1))  # 这里小于号就够了 因为<eos>所在位置的索引其实是valid_len-1\n",
    "    X[~mask] = value\n",
    "    return X\n",
    "\n",
    "\n",
    "# 拓展的softmax因为对填充值进行softmax其实没有什么意义\n",
    "class MaskedSoftmaxCELoss(nn.CrossEntropyLoss):\n",
    "    def forward(self, pred, label, valid_len):\n",
    "        weights = torch.ones_like(label)\n",
    "        weights = sequence_mask(weights, valid_len)\n",
    "        self.reduction = 'none'\n",
    "        pred = pred.permute(0, 2, 1)\n",
    "        # 交叉熵损失期望的两个输入 x是 batch_size vocab_size seq_lenth \n",
    "        # y 是 batch_size seq_len\n",
    "        unweight_loss = super().forward(pred, label)\n",
    "        weights_loss = unweight_loss * weights\n",
    "        return weights_loss.mean(dim=1)\n",
    "\n",
    "loss = MaskedSoftmaxCELoss()"
   ],
   "id": "d4e9fcbce639c0fb",
   "outputs": [],
   "execution_count": 28
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-21T13:01:36.522065Z",
     "start_time": "2025-05-21T13:01:36.518121Z"
    }
   },
   "cell_type": "code",
   "source": [
    "embed_size, num_hiddens, num_layers, dropout = 32, 32, 2, 0.1\n",
    "batch_size, num_steps = 64, 10\n",
    "lr, num_epochs = 0.005, 250\n",
    "\n",
    "encoder=Seq2SeqEncoder_hmy(vocab_size=len(src_vocab), embed_size=32, hidden_size=32,num_layers=2)\n",
    "decoder=Seq2SeqAttentionDecoder(vocab_size=len(tgt_vocab), embed_size=32, num_hiddens=32,num_layers=2)\n",
    "net=EncoderDecoder(encoder, decoder)"
   ],
   "id": "269edf30c66a23f1",
   "outputs": [],
   "execution_count": 29
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-21T13:03:42.269558Z",
     "start_time": "2025-05-21T13:01:38.197934Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# train\n",
    "optimizer = optim.Adam(net.parameters(), lr=0.005)\n",
    "for epoch in range(300):\n",
    "    for batch in train_data:\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        src,src_valid,tgt,tgt_valid=batch\n",
    "        Y=torch.cat((torch.tensor([tgt_vocab['<bos>']]).unsqueeze(0).repeat(tgt.shape[0],1),tgt),dim=1)[:,:-1]\n",
    "        # 易错点1：训练的时候应该使用带有bos的Y 表示强制教学 此时输出的y_hat实际上是没有bos的\n",
    "        y_hat,_=net(src,Y,src_valid)\n",
    "        # 点2 因为输出的y_hat 没有bos 因此在计算loss的时候应该使用原始序列作为目标序列\n",
    "        l=loss(y_hat,tgt,tgt_valid).sum()\n",
    "        l.backward()\n",
    "        grad_clipping(net, 1)\n",
    "        optimizer.step()\n",
    "    print(l)"
   ],
   "id": "a4382de9572cfb4b",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(53.0358, grad_fn=<SumBackward0>)\n",
      "tensor(43.2106, grad_fn=<SumBackward0>)\n",
      "tensor(41.9331, grad_fn=<SumBackward0>)\n",
      "tensor(40.8712, grad_fn=<SumBackward0>)\n",
      "tensor(41.0336, grad_fn=<SumBackward0>)\n",
      "tensor(40.4952, grad_fn=<SumBackward0>)\n",
      "tensor(39.7365, grad_fn=<SumBackward0>)\n",
      "tensor(38.7306, grad_fn=<SumBackward0>)\n",
      "tensor(37.9568, grad_fn=<SumBackward0>)\n",
      "tensor(36.6157, grad_fn=<SumBackward0>)\n",
      "tensor(36.1713, grad_fn=<SumBackward0>)\n",
      "tensor(34.9458, grad_fn=<SumBackward0>)\n",
      "tensor(33.9696, grad_fn=<SumBackward0>)\n",
      "tensor(32.3891, grad_fn=<SumBackward0>)\n",
      "tensor(30.8281, grad_fn=<SumBackward0>)\n",
      "tensor(29.7276, grad_fn=<SumBackward0>)\n",
      "tensor(28.6182, grad_fn=<SumBackward0>)\n",
      "tensor(28.6453, grad_fn=<SumBackward0>)\n",
      "tensor(27.3400, grad_fn=<SumBackward0>)\n",
      "tensor(26.8034, grad_fn=<SumBackward0>)\n",
      "tensor(26.1405, grad_fn=<SumBackward0>)\n",
      "tensor(25.5864, grad_fn=<SumBackward0>)\n",
      "tensor(24.7411, grad_fn=<SumBackward0>)\n",
      "tensor(24.0848, grad_fn=<SumBackward0>)\n",
      "tensor(23.7306, grad_fn=<SumBackward0>)\n",
      "tensor(23.0300, grad_fn=<SumBackward0>)\n",
      "tensor(22.3656, grad_fn=<SumBackward0>)\n",
      "tensor(21.8535, grad_fn=<SumBackward0>)\n",
      "tensor(21.6823, grad_fn=<SumBackward0>)\n",
      "tensor(21.2247, grad_fn=<SumBackward0>)\n",
      "tensor(20.6198, grad_fn=<SumBackward0>)\n",
      "tensor(20.1701, grad_fn=<SumBackward0>)\n",
      "tensor(20.0657, grad_fn=<SumBackward0>)\n",
      "tensor(19.6799, grad_fn=<SumBackward0>)\n",
      "tensor(19.2008, grad_fn=<SumBackward0>)\n",
      "tensor(19.0148, grad_fn=<SumBackward0>)\n",
      "tensor(18.9946, grad_fn=<SumBackward0>)\n",
      "tensor(18.4062, grad_fn=<SumBackward0>)\n",
      "tensor(18.1084, grad_fn=<SumBackward0>)\n",
      "tensor(17.8634, grad_fn=<SumBackward0>)\n",
      "tensor(17.4397, grad_fn=<SumBackward0>)\n",
      "tensor(17.0061, grad_fn=<SumBackward0>)\n",
      "tensor(16.6894, grad_fn=<SumBackward0>)\n",
      "tensor(16.9650, grad_fn=<SumBackward0>)\n",
      "tensor(16.3925, grad_fn=<SumBackward0>)\n",
      "tensor(16.1721, grad_fn=<SumBackward0>)\n",
      "tensor(15.8312, grad_fn=<SumBackward0>)\n",
      "tensor(15.5588, grad_fn=<SumBackward0>)\n",
      "tensor(15.3541, grad_fn=<SumBackward0>)\n",
      "tensor(15.1818, grad_fn=<SumBackward0>)\n",
      "tensor(14.9363, grad_fn=<SumBackward0>)\n",
      "tensor(14.7956, grad_fn=<SumBackward0>)\n",
      "tensor(14.4351, grad_fn=<SumBackward0>)\n",
      "tensor(14.1232, grad_fn=<SumBackward0>)\n",
      "tensor(13.8152, grad_fn=<SumBackward0>)\n",
      "tensor(13.5424, grad_fn=<SumBackward0>)\n",
      "tensor(13.2897, grad_fn=<SumBackward0>)\n",
      "tensor(13.3984, grad_fn=<SumBackward0>)\n",
      "tensor(13.0466, grad_fn=<SumBackward0>)\n",
      "tensor(12.9001, grad_fn=<SumBackward0>)\n",
      "tensor(12.6603, grad_fn=<SumBackward0>)\n",
      "tensor(12.7937, grad_fn=<SumBackward0>)\n",
      "tensor(12.3723, grad_fn=<SumBackward0>)\n",
      "tensor(12.4653, grad_fn=<SumBackward0>)\n",
      "tensor(11.6588, grad_fn=<SumBackward0>)\n",
      "tensor(11.8596, grad_fn=<SumBackward0>)\n",
      "tensor(11.5608, grad_fn=<SumBackward0>)\n",
      "tensor(11.3921, grad_fn=<SumBackward0>)\n",
      "tensor(11.1534, grad_fn=<SumBackward0>)\n",
      "tensor(11.3675, grad_fn=<SumBackward0>)\n",
      "tensor(11.1587, grad_fn=<SumBackward0>)\n",
      "tensor(10.8652, grad_fn=<SumBackward0>)\n",
      "tensor(10.3884, grad_fn=<SumBackward0>)\n",
      "tensor(10.0908, grad_fn=<SumBackward0>)\n",
      "tensor(10.2875, grad_fn=<SumBackward0>)\n",
      "tensor(9.7904, grad_fn=<SumBackward0>)\n",
      "tensor(9.5232, grad_fn=<SumBackward0>)\n",
      "tensor(9.4516, grad_fn=<SumBackward0>)\n",
      "tensor(9.3603, grad_fn=<SumBackward0>)\n",
      "tensor(8.9516, grad_fn=<SumBackward0>)\n",
      "tensor(8.8303, grad_fn=<SumBackward0>)\n",
      "tensor(8.4407, grad_fn=<SumBackward0>)\n",
      "tensor(8.2084, grad_fn=<SumBackward0>)\n",
      "tensor(8.1057, grad_fn=<SumBackward0>)\n",
      "tensor(8.2028, grad_fn=<SumBackward0>)\n",
      "tensor(7.9538, grad_fn=<SumBackward0>)\n",
      "tensor(7.8370, grad_fn=<SumBackward0>)\n",
      "tensor(7.7408, grad_fn=<SumBackward0>)\n",
      "tensor(7.4630, grad_fn=<SumBackward0>)\n",
      "tensor(7.5631, grad_fn=<SumBackward0>)\n",
      "tensor(7.3623, grad_fn=<SumBackward0>)\n",
      "tensor(7.0737, grad_fn=<SumBackward0>)\n",
      "tensor(7.0333, grad_fn=<SumBackward0>)\n",
      "tensor(6.7109, grad_fn=<SumBackward0>)\n",
      "tensor(6.5938, grad_fn=<SumBackward0>)\n",
      "tensor(6.3954, grad_fn=<SumBackward0>)\n",
      "tensor(6.2750, grad_fn=<SumBackward0>)\n",
      "tensor(6.3137, grad_fn=<SumBackward0>)\n",
      "tensor(6.2944, grad_fn=<SumBackward0>)\n",
      "tensor(6.0946, grad_fn=<SumBackward0>)\n",
      "tensor(5.9984, grad_fn=<SumBackward0>)\n",
      "tensor(6.0587, grad_fn=<SumBackward0>)\n",
      "tensor(6.0497, grad_fn=<SumBackward0>)\n",
      "tensor(5.9376, grad_fn=<SumBackward0>)\n",
      "tensor(5.7854, grad_fn=<SumBackward0>)\n",
      "tensor(5.6333, grad_fn=<SumBackward0>)\n",
      "tensor(5.5207, grad_fn=<SumBackward0>)\n",
      "tensor(5.5102, grad_fn=<SumBackward0>)\n",
      "tensor(5.3060, grad_fn=<SumBackward0>)\n",
      "tensor(5.5531, grad_fn=<SumBackward0>)\n",
      "tensor(5.0629, grad_fn=<SumBackward0>)\n",
      "tensor(5.1744, grad_fn=<SumBackward0>)\n",
      "tensor(4.9683, grad_fn=<SumBackward0>)\n",
      "tensor(4.9159, grad_fn=<SumBackward0>)\n",
      "tensor(4.7120, grad_fn=<SumBackward0>)\n",
      "tensor(4.9658, grad_fn=<SumBackward0>)\n",
      "tensor(4.7766, grad_fn=<SumBackward0>)\n",
      "tensor(4.6208, grad_fn=<SumBackward0>)\n",
      "tensor(4.3071, grad_fn=<SumBackward0>)\n",
      "tensor(4.3786, grad_fn=<SumBackward0>)\n",
      "tensor(4.5153, grad_fn=<SumBackward0>)\n",
      "tensor(4.4710, grad_fn=<SumBackward0>)\n",
      "tensor(4.2256, grad_fn=<SumBackward0>)\n",
      "tensor(4.0186, grad_fn=<SumBackward0>)\n",
      "tensor(3.9911, grad_fn=<SumBackward0>)\n",
      "tensor(4.1380, grad_fn=<SumBackward0>)\n",
      "tensor(3.8784, grad_fn=<SumBackward0>)\n",
      "tensor(3.8306, grad_fn=<SumBackward0>)\n",
      "tensor(3.6490, grad_fn=<SumBackward0>)\n",
      "tensor(3.6347, grad_fn=<SumBackward0>)\n",
      "tensor(3.6990, grad_fn=<SumBackward0>)\n",
      "tensor(3.7752, grad_fn=<SumBackward0>)\n",
      "tensor(3.5948, grad_fn=<SumBackward0>)\n",
      "tensor(3.3051, grad_fn=<SumBackward0>)\n",
      "tensor(3.1341, grad_fn=<SumBackward0>)\n",
      "tensor(3.1680, grad_fn=<SumBackward0>)\n",
      "tensor(2.9804, grad_fn=<SumBackward0>)\n",
      "tensor(2.9637, grad_fn=<SumBackward0>)\n",
      "tensor(3.2696, grad_fn=<SumBackward0>)\n",
      "tensor(2.9019, grad_fn=<SumBackward0>)\n",
      "tensor(2.8378, grad_fn=<SumBackward0>)\n",
      "tensor(2.8941, grad_fn=<SumBackward0>)\n",
      "tensor(2.8080, grad_fn=<SumBackward0>)\n",
      "tensor(3.1051, grad_fn=<SumBackward0>)\n",
      "tensor(2.9076, grad_fn=<SumBackward0>)\n",
      "tensor(2.7483, grad_fn=<SumBackward0>)\n",
      "tensor(2.6077, grad_fn=<SumBackward0>)\n",
      "tensor(2.7111, grad_fn=<SumBackward0>)\n",
      "tensor(2.5178, grad_fn=<SumBackward0>)\n",
      "tensor(2.6447, grad_fn=<SumBackward0>)\n",
      "tensor(2.4664, grad_fn=<SumBackward0>)\n",
      "tensor(2.5330, grad_fn=<SumBackward0>)\n",
      "tensor(2.4116, grad_fn=<SumBackward0>)\n",
      "tensor(2.4618, grad_fn=<SumBackward0>)\n",
      "tensor(2.3615, grad_fn=<SumBackward0>)\n",
      "tensor(2.3112, grad_fn=<SumBackward0>)\n",
      "tensor(2.3038, grad_fn=<SumBackward0>)\n",
      "tensor(2.1926, grad_fn=<SumBackward0>)\n",
      "tensor(2.2725, grad_fn=<SumBackward0>)\n",
      "tensor(2.2163, grad_fn=<SumBackward0>)\n",
      "tensor(2.1694, grad_fn=<SumBackward0>)\n",
      "tensor(2.1839, grad_fn=<SumBackward0>)\n",
      "tensor(2.1093, grad_fn=<SumBackward0>)\n",
      "tensor(2.1042, grad_fn=<SumBackward0>)\n",
      "tensor(2.0883, grad_fn=<SumBackward0>)\n",
      "tensor(2.1321, grad_fn=<SumBackward0>)\n",
      "tensor(1.9314, grad_fn=<SumBackward0>)\n",
      "tensor(2.4690, grad_fn=<SumBackward0>)\n",
      "tensor(1.9444, grad_fn=<SumBackward0>)\n",
      "tensor(1.9195, grad_fn=<SumBackward0>)\n",
      "tensor(1.9009, grad_fn=<SumBackward0>)\n",
      "tensor(1.9175, grad_fn=<SumBackward0>)\n",
      "tensor(1.9213, grad_fn=<SumBackward0>)\n",
      "tensor(1.8580, grad_fn=<SumBackward0>)\n",
      "tensor(1.8427, grad_fn=<SumBackward0>)\n",
      "tensor(1.8053, grad_fn=<SumBackward0>)\n",
      "tensor(1.8677, grad_fn=<SumBackward0>)\n",
      "tensor(1.7982, grad_fn=<SumBackward0>)\n",
      "tensor(1.8111, grad_fn=<SumBackward0>)\n",
      "tensor(1.7616, grad_fn=<SumBackward0>)\n",
      "tensor(1.7749, grad_fn=<SumBackward0>)\n",
      "tensor(1.7628, grad_fn=<SumBackward0>)\n",
      "tensor(1.7599, grad_fn=<SumBackward0>)\n",
      "tensor(1.7053, grad_fn=<SumBackward0>)\n",
      "tensor(1.7421, grad_fn=<SumBackward0>)\n",
      "tensor(1.6690, grad_fn=<SumBackward0>)\n",
      "tensor(1.7406, grad_fn=<SumBackward0>)\n",
      "tensor(1.7311, grad_fn=<SumBackward0>)\n",
      "tensor(1.7082, grad_fn=<SumBackward0>)\n",
      "tensor(1.6700, grad_fn=<SumBackward0>)\n",
      "tensor(1.7022, grad_fn=<SumBackward0>)\n",
      "tensor(1.6900, grad_fn=<SumBackward0>)\n",
      "tensor(1.8342, grad_fn=<SumBackward0>)\n",
      "tensor(1.6746, grad_fn=<SumBackward0>)\n",
      "tensor(1.8286, grad_fn=<SumBackward0>)\n",
      "tensor(1.7105, grad_fn=<SumBackward0>)\n",
      "tensor(1.6659, grad_fn=<SumBackward0>)\n",
      "tensor(1.6575, grad_fn=<SumBackward0>)\n",
      "tensor(1.6969, grad_fn=<SumBackward0>)\n",
      "tensor(1.7430, grad_fn=<SumBackward0>)\n",
      "tensor(1.7596, grad_fn=<SumBackward0>)\n",
      "tensor(1.6403, grad_fn=<SumBackward0>)\n",
      "tensor(1.6733, grad_fn=<SumBackward0>)\n",
      "tensor(1.6099, grad_fn=<SumBackward0>)\n",
      "tensor(1.6764, grad_fn=<SumBackward0>)\n",
      "tensor(1.5984, grad_fn=<SumBackward0>)\n",
      "tensor(1.6488, grad_fn=<SumBackward0>)\n",
      "tensor(1.6332, grad_fn=<SumBackward0>)\n",
      "tensor(1.6476, grad_fn=<SumBackward0>)\n",
      "tensor(1.5949, grad_fn=<SumBackward0>)\n",
      "tensor(1.5852, grad_fn=<SumBackward0>)\n",
      "tensor(1.5865, grad_fn=<SumBackward0>)\n",
      "tensor(1.6286, grad_fn=<SumBackward0>)\n",
      "tensor(1.6119, grad_fn=<SumBackward0>)\n",
      "tensor(1.8014, grad_fn=<SumBackward0>)\n",
      "tensor(1.6489, grad_fn=<SumBackward0>)\n",
      "tensor(1.5569, grad_fn=<SumBackward0>)\n",
      "tensor(1.6903, grad_fn=<SumBackward0>)\n",
      "tensor(1.5840, grad_fn=<SumBackward0>)\n",
      "tensor(1.6447, grad_fn=<SumBackward0>)\n",
      "tensor(1.6092, grad_fn=<SumBackward0>)\n",
      "tensor(1.5448, grad_fn=<SumBackward0>)\n",
      "tensor(1.6094, grad_fn=<SumBackward0>)\n",
      "tensor(1.6400, grad_fn=<SumBackward0>)\n",
      "tensor(1.5940, grad_fn=<SumBackward0>)\n",
      "tensor(1.7062, grad_fn=<SumBackward0>)\n",
      "tensor(1.5825, grad_fn=<SumBackward0>)\n",
      "tensor(1.5682, grad_fn=<SumBackward0>)\n",
      "tensor(1.6022, grad_fn=<SumBackward0>)\n",
      "tensor(1.5544, grad_fn=<SumBackward0>)\n",
      "tensor(1.5782, grad_fn=<SumBackward0>)\n",
      "tensor(1.5383, grad_fn=<SumBackward0>)\n",
      "tensor(1.5171, grad_fn=<SumBackward0>)\n",
      "tensor(1.5213, grad_fn=<SumBackward0>)\n",
      "tensor(1.7038, grad_fn=<SumBackward0>)\n",
      "tensor(1.5028, grad_fn=<SumBackward0>)\n",
      "tensor(1.5571, grad_fn=<SumBackward0>)\n",
      "tensor(1.5315, grad_fn=<SumBackward0>)\n",
      "tensor(1.5322, grad_fn=<SumBackward0>)\n",
      "tensor(1.5806, grad_fn=<SumBackward0>)\n",
      "tensor(1.5765, grad_fn=<SumBackward0>)\n",
      "tensor(1.5635, grad_fn=<SumBackward0>)\n",
      "tensor(1.5482, grad_fn=<SumBackward0>)\n",
      "tensor(1.5896, grad_fn=<SumBackward0>)\n",
      "tensor(1.5337, grad_fn=<SumBackward0>)\n",
      "tensor(1.5166, grad_fn=<SumBackward0>)\n",
      "tensor(1.6445, grad_fn=<SumBackward0>)\n",
      "tensor(1.5909, grad_fn=<SumBackward0>)\n",
      "tensor(1.5361, grad_fn=<SumBackward0>)\n",
      "tensor(1.5596, grad_fn=<SumBackward0>)\n",
      "tensor(1.5256, grad_fn=<SumBackward0>)\n",
      "tensor(1.5613, grad_fn=<SumBackward0>)\n",
      "tensor(1.5672, grad_fn=<SumBackward0>)\n",
      "tensor(1.5141, grad_fn=<SumBackward0>)\n",
      "tensor(1.5369, grad_fn=<SumBackward0>)\n",
      "tensor(1.5211, grad_fn=<SumBackward0>)\n",
      "tensor(1.5040, grad_fn=<SumBackward0>)\n",
      "tensor(1.5403, grad_fn=<SumBackward0>)\n",
      "tensor(1.5116, grad_fn=<SumBackward0>)\n",
      "tensor(1.5191, grad_fn=<SumBackward0>)\n",
      "tensor(1.5282, grad_fn=<SumBackward0>)\n",
      "tensor(1.5502, grad_fn=<SumBackward0>)\n",
      "tensor(1.6448, grad_fn=<SumBackward0>)\n",
      "tensor(1.5388, grad_fn=<SumBackward0>)\n",
      "tensor(1.5479, grad_fn=<SumBackward0>)\n",
      "tensor(1.5863, grad_fn=<SumBackward0>)\n",
      "tensor(1.8078, grad_fn=<SumBackward0>)\n",
      "tensor(1.5273, grad_fn=<SumBackward0>)\n",
      "tensor(1.5416, grad_fn=<SumBackward0>)\n",
      "tensor(1.5531, grad_fn=<SumBackward0>)\n",
      "tensor(1.5730, grad_fn=<SumBackward0>)\n",
      "tensor(1.5922, grad_fn=<SumBackward0>)\n",
      "tensor(1.5297, grad_fn=<SumBackward0>)\n",
      "tensor(1.5490, grad_fn=<SumBackward0>)\n",
      "tensor(1.5309, grad_fn=<SumBackward0>)\n",
      "tensor(1.5036, grad_fn=<SumBackward0>)\n",
      "tensor(1.5690, grad_fn=<SumBackward0>)\n",
      "tensor(1.6454, grad_fn=<SumBackward0>)\n",
      "tensor(1.5137, grad_fn=<SumBackward0>)\n",
      "tensor(1.5077, grad_fn=<SumBackward0>)\n",
      "tensor(1.5554, grad_fn=<SumBackward0>)\n",
      "tensor(1.4581, grad_fn=<SumBackward0>)\n",
      "tensor(1.4901, grad_fn=<SumBackward0>)\n",
      "tensor(1.5065, grad_fn=<SumBackward0>)\n",
      "tensor(1.5587, grad_fn=<SumBackward0>)\n",
      "tensor(1.5039, grad_fn=<SumBackward0>)\n",
      "tensor(1.4918, grad_fn=<SumBackward0>)\n",
      "tensor(1.5373, grad_fn=<SumBackward0>)\n",
      "tensor(1.4825, grad_fn=<SumBackward0>)\n",
      "tensor(1.5191, grad_fn=<SumBackward0>)\n",
      "tensor(1.5525, grad_fn=<SumBackward0>)\n",
      "tensor(1.5216, grad_fn=<SumBackward0>)\n",
      "tensor(1.5419, grad_fn=<SumBackward0>)\n",
      "tensor(1.6221, grad_fn=<SumBackward0>)\n",
      "tensor(1.5239, grad_fn=<SumBackward0>)\n",
      "tensor(1.5135, grad_fn=<SumBackward0>)\n",
      "tensor(1.4937, grad_fn=<SumBackward0>)\n",
      "tensor(1.5148, grad_fn=<SumBackward0>)\n",
      "tensor(1.5343, grad_fn=<SumBackward0>)\n",
      "tensor(1.5379, grad_fn=<SumBackward0>)\n"
     ]
    }
   ],
   "execution_count": 30
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-21T13:03:45.407107Z",
     "start_time": "2025-05-21T13:03:45.385653Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# predict\n",
    "engs = ['go .', \"i lost .\", 'he\\'s calm .', 'i\\'m home .']\n",
    "fras = ['va !', 'j\\'ai perdu .', 'il est calme .', 'je suis chez moi .']\n",
    "for src_sentence,tgt_sentence in zip(engs,fras):\n",
    "    src_tokens=[src_vocab[i] for i in src_sentence.split(' ')]+[src_vocab['<eos>']]\n",
    "    src_data=truncate_pad(src_tokens,10,1)\n",
    "    # 易错点 srcdata在生成完成后需要unsqueeze 因为原本是1维的需要增加一个批次维度\n",
    "    src_data=torch.tensor(src_data).unsqueeze(0)\n",
    "    # 易错点 需要加上这个批次的有效长度建议1维 或者无维度\n",
    "    enc_valid_len=torch.tensor([len(src_tokens)])\n",
    "    \n",
    "    enc_outputs=net.encoder(src_data,enc_valid_len)\n",
    "    state=net.decoder.init_state(enc_outputs,enc_valid_len)\n",
    "    # 易错点 这里必须得是long 因为embed层需要long输入 并且要unsequeeze 增加一个维度\n",
    "    dec_x=torch.tensor([tgt_vocab['<bos>']],dtype=torch.long).unsqueeze(0)\n",
    "\n",
    "    output_list=[]\n",
    "    for i in range(10):\n",
    "        output,state=net.decoder(dec_x,state)\n",
    "        # 易错点 需要用这一次的输出argmax之后 作为下一次的输入 因为输入必须得是long\n",
    "        dec_x=torch.argmax(output,dim=-1)\n",
    "\n",
    "        output_list.append(dec_x.squeeze(0).squeeze(0))\n",
    "        if tgt_vocab['<eos>']==torch.argmax(output,dim=-1).squeeze(0):\n",
    "            break\n",
    "    print([tgt_vocab.idx_to_token[i] for i in output_list])"
   ],
   "id": "117f5de5b833cc4b",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['va', '!', '<eos>']\n",
      "[\"j'ai\", 'perdu', '.', '<eos>']\n",
      "['il', 'est', 'bon', '.', '<eos>']\n",
      "['je', 'suis', 'chez', 'moi', '.', '<eos>']\n"
     ]
    }
   ],
   "execution_count": 31
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "46c437eb62e82ac1",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "987f7d7e19b8536c"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
