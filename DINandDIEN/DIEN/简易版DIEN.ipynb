{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-05-14T07:59:19.649721Z",
     "start_time": "2025-05-14T07:59:19.645420Z"
    }
   },
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from collections import defaultdict\n",
    "from tqdm import tqdm\n",
    "from torch.utils.data import Dataset, DataLoader"
   ],
   "outputs": [],
   "execution_count": 111
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-14T07:59:23.967220Z",
     "start_time": "2025-05-14T07:59:19.908577Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 加载数据\n",
    "ratings = pd.read_csv(r'D:\\code_file\\DINandDIEN\\ml-1m\\ratings.dat', sep='::', names=['user_id', 'movie_id', 'rating', 'timestamp'], engine='python')\n",
    "movies = pd.read_csv(r'D:\\code_file\\DINandDIEN\\ml-1m\\movies.dat', sep='::', names=['movie_id', 'title', 'genres'], engine='python', encoding='latin-1')\n",
    "users = pd.read_csv(r'D:\\code_file\\DINandDIEN\\ml-1m\\users.dat', sep='::', names=['user_id', 'gender', 'age', 'occupation', 'zipcode'], engine='python')"
   ],
   "id": "412c1fe440957999",
   "outputs": [],
   "execution_count": 112
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-14T07:59:25.335897Z",
     "start_time": "2025-05-14T07:59:23.968406Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 过滤正样本并生成序列\n",
    "positive_ratings=ratings[ratings['rating']>=4].reset_index(drop=True)\n",
    "user_sequences = defaultdict(list)\n",
    "for user_id, group in positive_ratings.groupby('user_id'):\n",
    "    sorted_group = group.sort_values('timestamp')\n",
    "    user_sequences[user_id] = sorted_group['movie_id'].tolist()"
   ],
   "id": "17248bfe93564f3d",
   "outputs": [],
   "execution_count": 113
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-14T07:59:43.651096Z",
     "start_time": "2025-05-14T07:59:25.336019Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 构建样本\n",
    "samples = []\n",
    "for user_id, seq in tqdm(user_sequences.items()):\n",
    "    if len(seq) < 2:\n",
    "        continue\n",
    "    for i in range(1, len(seq)):\n",
    "        hist = seq[:i]\n",
    "        target_pos = seq[i]\n",
    "        # 正样本\n",
    "        samples.append({'user_id': user_id, 'hist': hist, 'target': target_pos, 'label': 1})\n",
    "        # 负样本\n",
    "        all_movies = ratings['movie_id'].unique()\n",
    "        neg_movie = np.random.choice([m for m in all_movies if m not in seq])\n",
    "        samples.append({'user_id': user_id, 'hist': hist, 'target': neg_movie, 'label': 0})\n",
    "    \n",
    "    if user_id>10:\n",
    "        break\n",
    "        \n",
    "# 划分数据集\n",
    "train_df, test_df = train_test_split(pd.DataFrame(samples), test_size=0.2)\n",
    "# 索引映射 这一步的目的是使得所有的用户id和movieid 全部映射为连续的 便于embedding输入\n",
    "user_to_idx = {uid: i+1 for i, uid in enumerate(ratings['user_id'].unique())}\n",
    "movie_to_idx = {mid: i+1 for i, mid in enumerate(ratings['movie_id'].unique())}"
   ],
   "id": "855ed019b71a6666",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 10/6038 [00:18<3:03:38,  1.83s/it]\n"
     ]
    }
   ],
   "execution_count": 114
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-14T08:02:35.691744Z",
     "start_time": "2025-05-14T08:02:35.680971Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class MovieLensDataset(Dataset):\n",
    "    def __init__(self, df, max_seq_length):\n",
    "        self.df = df\n",
    "        self.max_seq_length = max_seq_length\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        row = self.df.iloc[idx]\n",
    "        user_idx = user_to_idx[row['user_id']]\n",
    "        hist = [movie_to_idx.get(m, 0) for m in row['hist']]\n",
    "        # 截断\n",
    "        hist=hist[:self.max_seq_length]\n",
    "        # 填充 如果超过最大值则最大值 否则填充\n",
    "        padded_hist = hist[:self.max_seq_length] + [0]*(self.max_seq_length - len(hist))\n",
    "        mask = [1]*len(hist) + [0]*(self.max_seq_length - len(hist))\n",
    "        return {\n",
    "            'user_id': torch.tensor(user_idx, dtype=torch.long),\n",
    "            'hist': torch.tensor(padded_hist, dtype=torch.long),\n",
    "            'mask': torch.tensor(mask, dtype=torch.float),\n",
    "            'target': torch.tensor(movie_to_idx.get(row['target'], 0), dtype=torch.long),\n",
    "            'label': torch.tensor(row['label'], dtype=torch.float)\n",
    "        }\n",
    "\n",
    "max_seq_length = 20\n",
    "train_dataset = MovieLensDataset(train_df, max_seq_length)\n",
    "train_loader = DataLoader(train_dataset, batch_size=256, shuffle=True)\n",
    "test_dataset = MovieLensDataset(test_df, max_seq_length)\n",
    "test_loader = DataLoader(test_dataset, batch_size=256, shuffle=True)"
   ],
   "id": "c0605a450eb2cc50",
   "outputs": [],
   "execution_count": 121
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "## AUGRU实现\n",
    "class AUGRUCell(nn.Module):\n",
    "    \"\"\"AUGRU cell for attention update\n",
    "       input_size是嵌入向量维度\n",
    "       hidden_size自定义\n",
    "    \"\"\"\n",
    "    def __init__(self, input_size, hidden_size, bias=True):\n",
    "        super().__init__()\n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.bias = bias\n",
    "        # (Wxr|Wxz|Wxh)\n",
    "        self.weight_xrzh = nn.Parameter(\n",
    "            torch.ones(input_size,3 * hidden_size,dtype=torch.float32))\n",
    "        # (Hxr|Hxz|Hxh)\n",
    "        self.weight_hrzh = nn.Parameter(\n",
    "            torch.ones(hidden_size,3 * hidden_size,dtype=torch.float32))\n",
    "        if bias:\n",
    "            # (b)\n",
    "            self.bias_r = nn.Parameter(torch.zeros(hidden_size))\n",
    "            self.bias_z = nn.Parameter(torch.zeros(hidden_size))\n",
    "            self.bias_h = nn.Parameter(torch.zeros(hidden_size))\n",
    "        else:\n",
    "            self.register_parameter('bias_r', None)\n",
    "            self.register_parameter('bias_z', None)\n",
    "            self.register_parameter('bias_h', None)\n",
    "        self.reset_parameters()\n",
    " \n",
    "    def reset_parameters(self):\n",
    "        stdv = 1.0 / self.hidden_size ** 0.5\n",
    "        for name, param in self.named_parameters():\n",
    "            if 'weight' in name:\n",
    "                nn.init.uniform_(param, -stdv, stdv)\n",
    "            elif 'bias' in name:\n",
    "                nn.init.zeros_(param)\n",
    "\n",
    "    # att_score 是 batch_size*1\n",
    "    # x是上一层gru的输出应该是batch_size,input_size\n",
    "    def forward(self, x, hidden_state, att_score):\n",
    "        W_xr,W_xz,W_xh = self.weight_xrzh.chunk(3, 1)\n",
    "        W_hr,W_hz,W_hh = self.weight_hrzh.chunk(3, 1)\n",
    " \n",
    "        reset_gate = torch.sigmoid(torch.matmul(x,W_xr) + torch.matmul(hidden_state,W_hr)+self.bias_r)\n",
    "        # batch_size *hidden_size\n",
    "        update_gate_pre = torch.sigmoid(torch.matmul(x,W_xz) +torch.matmul(hidden_state,W_hz) +self.bias_z)\n",
    "        update_gate = att_score.reshape(-1, 1) * update_gate_pre\n",
    "        hidden_gate = torch.tanh(torch.matmul(x,W_xh) + torch.matmul((reset_gate * hidden_state),W_hh) +self.bias_h)\n",
    "        hidden_state = (1-update_gate)*hidden_state +  update_gate*hidden_gate\n",
    "        return hidden_state"
   ],
   "id": "ccb51a97eb81f63f"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-14T08:05:27.886689Z",
     "start_time": "2025-05-14T08:05:27.872558Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class DIEN(nn.Module):\n",
    "    def __init__(self, user_num, movie_num, embed_dim, hidden_size):\n",
    "        \"\"\"\n",
    "        user_num 用户id去重数量用以生成embedding\n",
    "        movie_num 电影id去重数量用以生成embedding\n",
    "        embed_din 生成的嵌入向量维度\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        # 嵌入部分\n",
    "        self.user_embed = nn.Embedding(user_num, embed_dim)\n",
    "        self.movie_embed = nn.Embedding(movie_num, embed_dim)\n",
    "        # 第一层gru 兴趣抽取层\n",
    "        self.gru = nn.GRU(embed_dim, hidden_size, batch_first=True)\n",
    "        # 第二层 兴趣演化层\n",
    "        self.augru_cell = AUGRUCell(hidden_size, hidden_size)\n",
    "        # 注意力计算\n",
    "        self.attention = nn.Linear(hidden_size + embed_dim, 1)\n",
    "        # MLP部分\n",
    "        self.mlp = nn.Sequential(\n",
    "            nn.Linear(embed_dim * 2 + hidden_size, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 1),\n",
    "            nn.Sigmoid())\n",
    "\n",
    "    def forward(self, user_ids, hist, target, mask):\n",
    "        # 嵌入层\n",
    "        user_emb = self.user_embed(user_ids)  # (B, E)\n",
    "        hist_emb = self.movie_embed(hist)  # (B, L, E)\n",
    "        target_emb = self.movie_embed(target)  # (B, E)\n",
    "\n",
    "        # gru层\n",
    "        gru_out, _ = self.gru(hist_emb)  # (B, L, H)\n",
    "        \n",
    "        #注意力计算\n",
    "        target_expanded = target_emb.unsqueeze(1).expand(-1, gru_out.size(1), -1)  # (B, L, E)\n",
    "        att_input = torch.cat([gru_out, target_expanded], dim=-1)\n",
    "        att_scores = torch.softmax(self.attention(att_input).squeeze(-1).masked_fill(mask == 0, -1e9), dim=1)\n",
    "        \n",
    "        # augru层\n",
    "        h = torch.zeros(user_ids.size(0), gru_out.size(2)).to(user_ids.device)\n",
    "        for t in range(gru_out.size(1)):\n",
    "            h = self.augru_cell(gru_out[:, t, :], h, att_scores[:, t])\n",
    "        \n",
    "        combined = torch.cat([user_emb, target_emb, h], dim=1)\n",
    "        return self.mlp(combined).squeeze()"
   ],
   "id": "56a6690853c107d0",
   "outputs": [],
   "execution_count": 132
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-14T08:05:28.702599Z",
     "start_time": "2025-05-14T08:05:28.691052Z"
    }
   },
   "cell_type": "code",
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = DIEN(len(user_to_idx)+1, len(movie_to_idx)+1, 32, 64).to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "criterion = nn.BCELoss()"
   ],
   "id": "f3183956df31d17a",
   "outputs": [],
   "execution_count": 133
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-14T08:06:07.437380Z",
     "start_time": "2025-05-14T08:05:29.505110Z"
    }
   },
   "cell_type": "code",
   "source": [
    "for epoch in range(100):\n",
    "    model.train()\n",
    "    for batch in train_loader:\n",
    "        user_ids = batch['user_id'].to(device)\n",
    "        hist = batch['hist'].to(device)\n",
    "        mask = batch['mask'].to(device)\n",
    "        target = batch['target'].to(device)\n",
    "        labels = batch['label'].to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(user_ids, hist, target, mask)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    print(f'Epoch {epoch+1}, Loss: {loss.item():.4f}')"
   ],
   "id": "5b025d9f92e32844",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 0.7018\n",
      "Epoch 2, Loss: 0.6909\n",
      "Epoch 3, Loss: 0.6815\n",
      "Epoch 4, Loss: 0.6759\n",
      "Epoch 5, Loss: 0.6757\n",
      "Epoch 6, Loss: 0.6669\n",
      "Epoch 7, Loss: 0.6688\n",
      "Epoch 8, Loss: 0.6581\n",
      "Epoch 9, Loss: 0.6394\n",
      "Epoch 10, Loss: 0.6304\n",
      "Epoch 11, Loss: 0.6215\n",
      "Epoch 12, Loss: 0.6585\n",
      "Epoch 13, Loss: 0.5907\n",
      "Epoch 14, Loss: 0.6239\n",
      "Epoch 15, Loss: 0.5410\n",
      "Epoch 16, Loss: 0.6190\n",
      "Epoch 17, Loss: 0.5541\n",
      "Epoch 18, Loss: 0.5881\n",
      "Epoch 19, Loss: 0.5357\n",
      "Epoch 20, Loss: 0.5405\n",
      "Epoch 21, Loss: 0.6021\n",
      "Epoch 22, Loss: 0.5326\n",
      "Epoch 23, Loss: 0.4980\n",
      "Epoch 24, Loss: 0.4573\n",
      "Epoch 25, Loss: 0.4902\n",
      "Epoch 26, Loss: 0.4852\n",
      "Epoch 27, Loss: 0.4143\n",
      "Epoch 28, Loss: 0.4369\n",
      "Epoch 29, Loss: 0.4451\n",
      "Epoch 30, Loss: 0.3727\n",
      "Epoch 31, Loss: 0.3860\n",
      "Epoch 32, Loss: 0.3882\n",
      "Epoch 33, Loss: 0.3002\n",
      "Epoch 34, Loss: 0.3383\n",
      "Epoch 35, Loss: 0.3508\n",
      "Epoch 36, Loss: 0.3566\n",
      "Epoch 37, Loss: 0.3466\n",
      "Epoch 38, Loss: 0.3277\n",
      "Epoch 39, Loss: 0.2751\n",
      "Epoch 40, Loss: 0.2411\n",
      "Epoch 41, Loss: 0.2532\n",
      "Epoch 42, Loss: 0.2098\n",
      "Epoch 43, Loss: 0.2332\n",
      "Epoch 44, Loss: 0.2705\n",
      "Epoch 45, Loss: 0.2343\n",
      "Epoch 46, Loss: 0.2430\n",
      "Epoch 47, Loss: 0.2025\n",
      "Epoch 48, Loss: 0.2117\n",
      "Epoch 49, Loss: 0.1879\n",
      "Epoch 50, Loss: 0.1326\n",
      "Epoch 51, Loss: 0.1683\n",
      "Epoch 52, Loss: 0.1733\n",
      "Epoch 53, Loss: 0.1494\n",
      "Epoch 54, Loss: 0.0998\n",
      "Epoch 55, Loss: 0.1552\n",
      "Epoch 56, Loss: 0.1595\n",
      "Epoch 57, Loss: 0.1405\n",
      "Epoch 58, Loss: 0.1141\n",
      "Epoch 59, Loss: 0.1311\n",
      "Epoch 60, Loss: 0.1713\n",
      "Epoch 61, Loss: 0.1101\n",
      "Epoch 62, Loss: 0.1167\n",
      "Epoch 63, Loss: 0.0850\n",
      "Epoch 64, Loss: 0.0738\n",
      "Epoch 65, Loss: 0.0660\n",
      "Epoch 66, Loss: 0.0848\n",
      "Epoch 67, Loss: 0.0574\n",
      "Epoch 68, Loss: 0.0819\n",
      "Epoch 69, Loss: 0.0670\n",
      "Epoch 70, Loss: 0.0458\n",
      "Epoch 71, Loss: 0.0662\n",
      "Epoch 72, Loss: 0.0535\n",
      "Epoch 73, Loss: 0.0630\n",
      "Epoch 74, Loss: 0.0417\n",
      "Epoch 75, Loss: 0.0425\n",
      "Epoch 76, Loss: 0.0595\n",
      "Epoch 77, Loss: 0.0549\n",
      "Epoch 78, Loss: 0.0375\n",
      "Epoch 79, Loss: 0.0419\n",
      "Epoch 80, Loss: 0.0462\n",
      "Epoch 81, Loss: 0.0359\n",
      "Epoch 82, Loss: 0.0412\n",
      "Epoch 83, Loss: 0.0382\n",
      "Epoch 84, Loss: 0.0383\n",
      "Epoch 85, Loss: 0.0289\n",
      "Epoch 86, Loss: 0.0301\n",
      "Epoch 87, Loss: 0.0438\n",
      "Epoch 88, Loss: 0.0270\n",
      "Epoch 89, Loss: 0.0258\n",
      "Epoch 90, Loss: 0.0181\n",
      "Epoch 91, Loss: 0.0282\n",
      "Epoch 92, Loss: 0.0203\n",
      "Epoch 93, Loss: 0.0217\n",
      "Epoch 94, Loss: 0.0169\n",
      "Epoch 95, Loss: 0.0144\n",
      "Epoch 96, Loss: 0.0258\n",
      "Epoch 97, Loss: 0.0153\n",
      "Epoch 98, Loss: 0.0169\n",
      "Epoch 99, Loss: 0.0216\n",
      "Epoch 100, Loss: 0.0124\n"
     ]
    }
   ],
   "execution_count": 134
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-14T08:06:09.707769Z",
     "start_time": "2025-05-14T08:06:09.649210Z"
    }
   },
   "cell_type": "code",
   "source": [
    "model.eval()\n",
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for batch in test_loader:\n",
    "        user_ids = batch['user_id'].to(device)\n",
    "        hist = batch['hist'].to(device)\n",
    "        mask = batch['mask'].to(device)\n",
    "        target = batch['target'].to(device)\n",
    "        labels = batch['label'].to(device)\n",
    "        outputs = model(user_ids, hist, target, mask)\n",
    "        predicted = (outputs >= 0.5).float()\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "print(f'Accuracy: {correct / total:.4f}')"
   ],
   "id": "4ff556d5e66274cc",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6283\n"
     ]
    }
   ],
   "execution_count": 135
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "fd5d870732fdca01"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
