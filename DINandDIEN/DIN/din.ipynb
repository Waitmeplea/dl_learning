{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-05-14T05:37:55.919076Z",
     "start_time": "2025-05-14T05:37:53.484858Z"
    }
   },
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split"
   ],
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-14T05:38:43.780955Z",
     "start_time": "2025-05-14T05:38:39.952003Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 数据预处理\n",
    "# 读取数据\n",
    "ratings = pd.read_csv(r'D:\\code_file\\DINandDIEN\\ml-1m\\ratings.dat', sep='::', names=['UserID', 'MovieID', 'Rating', 'Timestamp'], engine='python')\n",
    "movies = pd.read_csv(r'D:\\code_file\\DINandDIEN\\ml-1m\\movies.dat', sep='::', names=['MovieID', 'Title', 'Genres'], engine='python', encoding='latin-1')\n",
    "users = pd.read_csv(r'D:\\code_file\\DINandDIEN\\ml-1m\\users.dat', sep='::', names=['UserID', 'Gender', 'Age', 'Occupation', 'Zip-code'], engine='python')"
   ],
   "id": "e5fdd0efdf0d1fff",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-14T05:57:47.552130Z",
     "start_time": "2025-05-14T05:57:47.505947Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 处理电影类型\n",
    "all_genres = set()\n",
    "for row in movies['Genres']:\n",
    "    for genre in row.split('|'):\n",
    "        all_genres.add(genre)\n",
    "genre_to_idx = {genre: idx for idx, genre in enumerate(all_genres)}\n",
    "num_genres = len(all_genres)\n",
    "movies['genre_multi_hot'] = movies['Genres'].apply(lambda x: [1 if genre in x.split('|') else 0 for genre in all_genres])\n",
    "genre_multi_hot = np.stack(movies['genre_multi_hot'].values)\n",
    "movie_id_to_genre = dict(zip(movies['MovieID'], genre_multi_hot))"
   ],
   "id": "546503622ebe855b",
   "outputs": [],
   "execution_count": 49
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-14T05:58:39.170650Z",
     "start_time": "2025-05-14T05:58:39.147879Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 处理用户数据\n",
    "gender_to_idx = {'F':0, 'M':1}\n",
    "users['Gender'] = users['Gender'].map(gender_to_idx)\n",
    "users['Age'] = users['Age'] - 1  # 原始年龄为1-7\n",
    "user_dict = users.set_index('UserID').to_dict('index')\n"
   ],
   "id": "dc4ff0f8ccd36ad1",
   "outputs": [],
   "execution_count": 53
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-14T06:02:39.625525Z",
     "start_time": "2025-05-14T06:02:39.619053Z"
    }
   },
   "cell_type": "code",
   "source": "ratings",
   "id": "d35add5b3539fddf",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "         UserID  MovieID  Rating  Timestamp\n",
       "0             1     1193       5  978300760\n",
       "1             1      661       3  978302109\n",
       "2             1      914       3  978301968\n",
       "3             1     3408       4  978300275\n",
       "4             1     2355       5  978824291\n",
       "...         ...      ...     ...        ...\n",
       "1000204    6040     1091       1  956716541\n",
       "1000205    6040     1094       5  956704887\n",
       "1000206    6040      562       5  956704746\n",
       "1000207    6040     1096       4  956715648\n",
       "1000208    6040     1097       4  956715569\n",
       "\n",
       "[1000209 rows x 4 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>UserID</th>\n",
       "      <th>MovieID</th>\n",
       "      <th>Rating</th>\n",
       "      <th>Timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1193</td>\n",
       "      <td>5</td>\n",
       "      <td>978300760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>661</td>\n",
       "      <td>3</td>\n",
       "      <td>978302109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>914</td>\n",
       "      <td>3</td>\n",
       "      <td>978301968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>3408</td>\n",
       "      <td>4</td>\n",
       "      <td>978300275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>2355</td>\n",
       "      <td>5</td>\n",
       "      <td>978824291</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1000204</th>\n",
       "      <td>6040</td>\n",
       "      <td>1091</td>\n",
       "      <td>1</td>\n",
       "      <td>956716541</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1000205</th>\n",
       "      <td>6040</td>\n",
       "      <td>1094</td>\n",
       "      <td>5</td>\n",
       "      <td>956704887</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1000206</th>\n",
       "      <td>6040</td>\n",
       "      <td>562</td>\n",
       "      <td>5</td>\n",
       "      <td>956704746</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1000207</th>\n",
       "      <td>6040</td>\n",
       "      <td>1096</td>\n",
       "      <td>4</td>\n",
       "      <td>956715648</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1000208</th>\n",
       "      <td>6040</td>\n",
       "      <td>1097</td>\n",
       "      <td>4</td>\n",
       "      <td>956715569</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000209 rows × 4 columns</p>\n",
       "</div>"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 60
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-14T06:04:24.881998Z",
     "start_time": "2025-05-14T06:04:23.468601Z"
    }
   },
   "cell_type": "code",
   "source": "(ratings.groupby('UserID').apply(lambda x: x.sort_values('Timestamp')))[1]",
   "id": "56bc1dec04eb805b",
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "1",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyError\u001B[0m                                  Traceback (most recent call last)",
      "File \u001B[1;32mD:\\work softwar\\python\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3653\u001B[0m, in \u001B[0;36mIndex.get_loc\u001B[1;34m(self, key)\u001B[0m\n\u001B[0;32m   3652\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m-> 3653\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_engine\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget_loc\u001B[49m\u001B[43m(\u001B[49m\u001B[43mcasted_key\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   3654\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mKeyError\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m err:\n",
      "File \u001B[1;32mD:\\work softwar\\python\\Lib\\site-packages\\pandas\\_libs\\index.pyx:147\u001B[0m, in \u001B[0;36mpandas._libs.index.IndexEngine.get_loc\u001B[1;34m()\u001B[0m\n",
      "File \u001B[1;32mD:\\work softwar\\python\\Lib\\site-packages\\pandas\\_libs\\index.pyx:176\u001B[0m, in \u001B[0;36mpandas._libs.index.IndexEngine.get_loc\u001B[1;34m()\u001B[0m\n",
      "File \u001B[1;32mpandas\\_libs\\hashtable_class_helper.pxi:7080\u001B[0m, in \u001B[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001B[1;34m()\u001B[0m\n",
      "File \u001B[1;32mpandas\\_libs\\hashtable_class_helper.pxi:7088\u001B[0m, in \u001B[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001B[1;34m()\u001B[0m\n",
      "\u001B[1;31mKeyError\u001B[0m: 1",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001B[1;31mKeyError\u001B[0m                                  Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[64], line 1\u001B[0m\n\u001B[1;32m----> 1\u001B[0m \u001B[43m(\u001B[49m\u001B[43mratings\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mgroupby\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mUserID\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mapply\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43;01mlambda\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mx\u001B[49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mx\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msort_values\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mTimestamp\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;241;43m1\u001B[39;49m\u001B[43m]\u001B[49m\n",
      "File \u001B[1;32mD:\\work softwar\\python\\Lib\\site-packages\\pandas\\core\\frame.py:3761\u001B[0m, in \u001B[0;36mDataFrame.__getitem__\u001B[1;34m(self, key)\u001B[0m\n\u001B[0;32m   3759\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcolumns\u001B[38;5;241m.\u001B[39mnlevels \u001B[38;5;241m>\u001B[39m \u001B[38;5;241m1\u001B[39m:\n\u001B[0;32m   3760\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_getitem_multilevel(key)\n\u001B[1;32m-> 3761\u001B[0m indexer \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcolumns\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget_loc\u001B[49m\u001B[43m(\u001B[49m\u001B[43mkey\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   3762\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m is_integer(indexer):\n\u001B[0;32m   3763\u001B[0m     indexer \u001B[38;5;241m=\u001B[39m [indexer]\n",
      "File \u001B[1;32mD:\\work softwar\\python\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3655\u001B[0m, in \u001B[0;36mIndex.get_loc\u001B[1;34m(self, key)\u001B[0m\n\u001B[0;32m   3653\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_engine\u001B[38;5;241m.\u001B[39mget_loc(casted_key)\n\u001B[0;32m   3654\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mKeyError\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m err:\n\u001B[1;32m-> 3655\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mKeyError\u001B[39;00m(key) \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01merr\u001B[39;00m\n\u001B[0;32m   3656\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mTypeError\u001B[39;00m:\n\u001B[0;32m   3657\u001B[0m     \u001B[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001B[39;00m\n\u001B[0;32m   3658\u001B[0m     \u001B[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001B[39;00m\n\u001B[0;32m   3659\u001B[0m     \u001B[38;5;66;03m#  the TypeError.\u001B[39;00m\n\u001B[0;32m   3660\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_check_indexing_error(key)\n",
      "\u001B[1;31mKeyError\u001B[0m: 1"
     ]
    }
   ],
   "execution_count": 64
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-14T06:01:16.460143Z",
     "start_time": "2025-05-14T06:01:14.709300Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 生成样本\n",
    "max_len = 50\n",
    "samples = []\n",
    "for user_id, group in ratings.groupby('UserID').apply(lambda x: x.sort_values('Timestamp')):\n",
    "    user_data = user_dict[user_id]\n",
    "    gender = user_data['Gender']\n",
    "    age = user_data['Age']\n",
    "    occupation = user_data['Occupation']\n",
    "    history = []\n",
    "    for idx, row in group.iterrows():\n",
    "        movie_id = row['MovieID']\n",
    "        label = 1 if row['Rating'] >= 4 else 0\n",
    "        current_history = history[-max_len:]\n",
    "        padded_history = current_history + [0]*(max_len - len(current_history))\n",
    "        mask = [1]*len(current_history) + [0]*(max_len - len(current_history))\n",
    "        candidate_genre = movie_id_to_genre.get(movie_id, np.zeros(num_genres))\n",
    "        history_genres = []\n",
    "        for hist_id in padded_history:\n",
    "            if hist_id == 0:\n",
    "                history_genres.append(np.zeros(num_genres))\n",
    "            else:\n",
    "                history_genres.append(movie_id_to_genre.get(hist_id, np.zeros(num_genres)))\n",
    "        samples.append({\n",
    "            'user_gender': gender,\n",
    "            'user_age': age,\n",
    "            'user_occupation': occupation,\n",
    "            'candidate_movie_id': movie_id,\n",
    "            'candidate_genre': candidate_genre,\n",
    "            'history_movie_ids': padded_history,\n",
    "            'history_genres': np.array(history_genres),\n",
    "            'history_mask': mask,\n",
    "            'label': label\n",
    "        })\n",
    "        history.append(movie_id)\n",
    "        history = history[-max_len:]\n",
    "\n",
    "samples_df = pd.DataFrame(samples)"
   ],
   "id": "ed71d1ae8d4fc63",
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "too many values to unpack (expected 2)",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[56], line 4\u001B[0m\n\u001B[0;32m      2\u001B[0m max_len \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m50\u001B[39m\n\u001B[0;32m      3\u001B[0m samples \u001B[38;5;241m=\u001B[39m []\n\u001B[1;32m----> 4\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m user_id, group \u001B[38;5;129;01min\u001B[39;00m ratings\u001B[38;5;241m.\u001B[39mgroupby(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mUserID\u001B[39m\u001B[38;5;124m'\u001B[39m)\u001B[38;5;241m.\u001B[39mapply(\u001B[38;5;28;01mlambda\u001B[39;00m x: x\u001B[38;5;241m.\u001B[39msort_values(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mTimestamp\u001B[39m\u001B[38;5;124m'\u001B[39m)):\n\u001B[0;32m      5\u001B[0m     user_data \u001B[38;5;241m=\u001B[39m user_dict[user_id]\n\u001B[0;32m      6\u001B[0m     gender \u001B[38;5;241m=\u001B[39m user_data[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mGender\u001B[39m\u001B[38;5;124m'\u001B[39m]\n",
      "\u001B[1;31mValueError\u001B[0m: too many values to unpack (expected 2)"
     ]
    }
   ],
   "execution_count": 56
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-14T05:46:17.696042Z",
     "start_time": "2025-05-14T05:46:16.024797Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "2a9fff81b4991ed5",
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "too many values to unpack (expected 2)",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[15], line 22\u001B[0m\n\u001B[0;32m     19\u001B[0m max_len \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m50\u001B[39m\n\u001B[0;32m     20\u001B[0m samples \u001B[38;5;241m=\u001B[39m []\n\u001B[1;32m---> 22\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m user_id, group \u001B[38;5;129;01min\u001B[39;00m ratings\u001B[38;5;241m.\u001B[39mgroupby(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mUserID\u001B[39m\u001B[38;5;124m'\u001B[39m)\u001B[38;5;241m.\u001B[39mapply(\u001B[38;5;28;01mlambda\u001B[39;00m x: x\u001B[38;5;241m.\u001B[39msort_values(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mTimestamp\u001B[39m\u001B[38;5;124m'\u001B[39m)):\n\u001B[0;32m     23\u001B[0m     user_data \u001B[38;5;241m=\u001B[39m user_dict[user_id]\n\u001B[0;32m     24\u001B[0m     gender \u001B[38;5;241m=\u001B[39m user_data[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mGender\u001B[39m\u001B[38;5;124m'\u001B[39m]\n",
      "\u001B[1;31mValueError\u001B[0m: too many values to unpack (expected 2)"
     ]
    }
   ],
   "execution_count": 15
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# 数据集划分\n",
    "train_df, test_df = train_test_split(samples_df, test_size=0.2, random_state=42)\n",
    "\n",
    "# 自定义Dataset\n",
    "class MovieLensDataset(Dataset):\n",
    "    def __init__(self, df):\n",
    "        self.df = df\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        row = self.df.iloc[idx]\n",
    "        return {\n",
    "            'user_gender': torch.tensor(row['user_gender'], dtype=torch.long),\n",
    "            'user_age': torch.tensor(row['user_age'], dtype=torch.long),\n",
    "            'user_occupation': torch.tensor(row['user_occupation'], dtype=torch.long),\n",
    "            'candidate_movie_id': torch.tensor(row['candidate_movie_id'], dtype=torch.long),\n",
    "            'candidate_genre': torch.tensor(row['candidate_genre'], dtype=torch.float32),\n",
    "            'history_movie_ids': torch.tensor(row['history_movie_ids'], dtype=torch.long),\n",
    "            'history_genres': torch.tensor(row['history_genres'], dtype=torch.float32),\n",
    "            'history_mask': torch.tensor(row['history_mask'], dtype=torch.float32),\n",
    "            'label': torch.tensor(row['label'], dtype=torch.float32)\n",
    "        }\n",
    "\n",
    "train_dataset = MovieLensDataset(train_df)\n",
    "test_dataset = MovieLensDataset(test_df)\n",
    "\n",
    "# 模型定义\n",
    "class UserEncoder(nn.Module):\n",
    "    def __init__(self, gender_size=2, age_size=7, occupation_size=21, embed_dim=16):\n",
    "        super().__init__()\n",
    "        self.gender_embed = nn.Embedding(gender_size, embed_dim)\n",
    "        self.age_embed = nn.Embedding(age_size, embed_dim)\n",
    "        self.occupation_embed = nn.Embedding(occupation_size, embed_dim)\n",
    "    \n",
    "    def forward(self, gender, age, occupation):\n",
    "        return torch.cat([\n",
    "            self.gender_embed(gender),\n",
    "            self.age_embed(age),\n",
    "            self.occupation_embed(occupation)\n",
    "        ], dim=1)\n",
    "\n",
    "class MovieEncoder(nn.Module):\n",
    "    def __init__(self, movie_size=3953, genre_size=18, embed_dim=32):\n",
    "        super().__init__()\n",
    "        self.movie_embed = nn.Embedding(movie_size, embed_dim)\n",
    "        self.genre_fc = nn.Linear(genre_size, embed_dim)\n",
    "    \n",
    "    def forward(self, movie_id, genre):\n",
    "        return torch.cat([\n",
    "            self.movie_embed(movie_id),\n",
    "            self.genre_fc(genre)\n",
    "        ], dim=1)\n",
    "\n",
    "class DIN(nn.Module):\n",
    "    def __init__(self, user_encoder, movie_encoder, hidden_dim=128):\n",
    "        super().__init__()\n",
    "        self.user_encoder = user_encoder\n",
    "        self.movie_encoder = movie_encoder\n",
    "        self.attention = nn.Sequential(\n",
    "            nn.Linear(3*64, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, 1)\n",
    "        )\n",
    "        self.mlp = nn.Sequential(\n",
    "            nn.Linear(64*2 + 48, 256),  # 64*2来自用户兴趣和候选物品，48来自用户特征\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(256, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(128, 1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "    \n",
    "    def forward(self, user_gender, user_age, user_occupation, candidate_movie, candidate_genre, history_movies, history_genres, mask):\n",
    "        # 用户特征\n",
    "        user_feat = self.user_encoder(user_gender, user_age, user_occupation)\n",
    "        \n",
    "        # 候选物品\n",
    "        candidate_feat = self.movie_encoder(candidate_movie, candidate_genre)\n",
    "        \n",
    "        # 历史行为\n",
    "        batch_size, seq_len = history_movies.size()\n",
    "        history_feat = self.movie_encoder(\n",
    "            history_movies.view(-1),\n",
    "            history_genres.view(-1, history_genres.size(-1))\n",
    "        ).view(batch_size, seq_len, -1)\n",
    "        \n",
    "        # 注意力机制\n",
    "        candidate_expanded = candidate_feat.unsqueeze(1).expand_as(history_feat)\n",
    "        interaction = history_feat * candidate_expanded\n",
    "        attention_input = torch.cat([history_feat, candidate_expanded, interaction], dim=-1)\n",
    "        attention_scores = self.attention(attention_input).squeeze(-1)\n",
    "        attention_scores = attention_scores.masked_fill(mask == 0, -1e9)\n",
    "        attention_weights = F.softmax(attention_scores, dim=1)\n",
    "        \n",
    "        # 用户兴趣表示\n",
    "        user_interest = torch.bmm(attention_weights.unsqueeze(1), history_feat).squeeze(1)\n",
    "        \n",
    "        # 最终预测\n",
    "        concat = torch.cat([user_interest, candidate_feat, user_feat], dim=1)\n",
    "        return self.mlp(concat)\n",
    "\n",
    "# 初始化模型\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "user_encoder = UserEncoder()\n",
    "movie_encoder = MovieEncoder()\n",
    "model = DIN(user_encoder, movie_encoder).to(device)\n",
    "criterion = nn.BCELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# 训练循环\n",
    "def train(model, dataloader, criterion, optimizer):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for batch in dataloader:\n",
    "        optimizer.zero_grad()\n",
    "        inputs = {k: v.to(device).unsqueeze(1) if k in ['user_gender', 'user_age', 'user_occupation'] \n",
    "                 else v.to(device) for k, v in batch.items()}\n",
    "        outputs = model(\n",
    "            inputs['user_gender'],\n",
    "            inputs['user_age'],\n",
    "            inputs['user_occupation'],\n",
    "            inputs['candidate_movie_id'],\n",
    "            inputs['candidate_genre'],\n",
    "            inputs['history_movie_ids'],\n",
    "            inputs['history_genres'],\n",
    "            inputs['history_mask']\n",
    "        )\n",
    "        loss = criterion(outputs.squeeze(), inputs['label'])\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item() * len(batch)\n",
    "    return total_loss / len(dataloader.dataset)\n",
    "\n",
    "# 测试循环\n",
    "def evaluate(model, dataloader):\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for batch in dataloader:\n",
    "            inputs = {k: v.to(device).unsqueeze(1) if k in ['user_gender', 'user_age', 'user_occupation'] \n",
    "                     else v.to(device) for k, v in batch.items()}\n",
    "            outputs = model(**inputs)\n",
    "            loss = criterion(outputs.squeeze(), inputs['label'])\n",
    "            total_loss += loss.item() * len(batch)\n",
    "            preds = (outputs > 0.5).float()\n",
    "            correct += (preds == inputs['label']).sum().item()\n",
    "    return total_loss / len(dataloader.dataset), correct / len(dataloader.dataset)\n",
    "\n",
    "# 数据加载\n",
    "batch_size = 256\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "# 训练过程\n",
    "for epoch in range(10):\n",
    "    train_loss = train(model, train_loader, criterion, optimizer)\n",
    "    test_loss, test_acc = evaluate(model, test_loader)\n",
    "    print(f'Epoch {epoch+1:02}')\n",
    "    print(f'Train Loss: {train_loss:.4f} | Test Loss: {test_loss:.4f} | Test Acc: {test_acc:.4f}')"
   ],
   "id": "5d64b878e022ce2d"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
