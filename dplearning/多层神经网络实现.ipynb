{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-03-13T04:29:40.147692Z",
     "start_time": "2025-03-13T04:29:40.009543Z"
    }
   },
   "source": "import numpy as np",
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-13T09:28:50.314269Z",
     "start_time": "2025-03-13T09:28:50.310184Z"
    }
   },
   "cell_type": "code",
   "source": [
    "##wb是模型本身的参数因此放在构造函数中无需手动进行更改 其他则由输入的x决定\n",
    "class Affine:\n",
    "    def __init__(self,w,b):\n",
    "        self.w=w\n",
    "        self.b=b\n",
    "        self.x=None\n",
    "        self.dw=None\n",
    "        self.db=None\n",
    "        self.dx=None\n",
    "    def forward(self,x):\n",
    "        if x.dim==1:\n",
    "            self.x = x.reshape(1,-1)\n",
    "        output=np.dot(self.x, self.w)+self.b\n",
    "        return output\n",
    "    def backward(self,dout):\n",
    "        self.dx=np.dot(dout,self.w.T)\n",
    "        self.dw=np.dot(self.x.T,dout)\n",
    "        self.db=np.sum(dout,axis=0)\n",
    "\n",
    "class Relu:\n",
    "    def __init__(self):\n",
    "        self.mask=None\n",
    "    def forward(self,x):\n",
    "        self.mask=x>0\n",
    "        out=self.mask*self.x\n",
    "        return out\n",
    "    def backward(self,dout):\n",
    "        dx=self.mask*dout\n",
    "        return dx\n",
    "    \n",
    "class Softmaxwithloss:\n",
    "    def __init__(self,t):\n",
    "        self.t=t\n",
    "    def forward(self,x):\n",
    "        out=np.exp(x-7)/np.sum(np.exp(x-7))\n",
    "        return out\n",
    "    def loss(self,x):\n",
    "        out=self.forward(x)\n",
    "        return -self.t*np.log(out+1e-7)/x.size\n",
    "        "
   ],
   "id": "66f91ef2e2a40104",
   "outputs": [],
   "execution_count": 9
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "class MultiLayersNetwork:\n",
    "    def __init__(self, input_size, output_size, hidden_size_list=None):\n",
    "        if hidden_size_list is None:\n",
    "            self.hidden_size_list = [100, 100, 100]\n",
    "        self.input_size = input_size\n",
    "        self.hidden_size_list = hidden_size_list\n",
    "        self.output_size = output_size\n",
    "        self.params=dict()\n",
    "        self.sourcedata=None\n",
    "        self.layers= dict()\n",
    "        #生成层\n",
    "        parameter_size_list=self.hidden_size_list.insert(0,self.input_size)\n",
    "        parameter_size_list.append(self.output_size)\n",
    "        \n",
    "        ##倒数第二层之前全部用relu\n",
    "        for i in range(len(parameter_size_list)-2):\n",
    "            self.params['W'+str(i)]=np.random.rand(parameter_size_list[i],parameter_size_list[i+1])\n",
    "            self.params['b'+str(i)]=np.random.rand(parameter_size_list[i],parameter_size_list[i+1])\n",
    "            #每一层就自己层的权重和偏置\n",
    "            self.layers['affine'+str(i)]=Affine(self.params['W'+str(i)],self.params['b'+str(i)])\n",
    "            self.layers['Activation_function']=\n",
    "        \n",
    "\n",
    "    def forward(self, x):\n",
    "        for j in range(len(self.params)//2):\n",
    "            layer_name='layer'+str(j)\n",
    "            self.layers[layer_name]=Affine(x=x,w=self.,b=)\n",
    "            "
   ],
   "id": "1fcb75450a7fc1a4"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "891d28bdf7a2561a"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
