{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-03-15T12:18:05.743136Z",
     "start_time": "2025-03-15T12:18:05.652142Z"
    }
   },
   "source": [
    "import numpy as np\n",
    "import sys\n",
    "sys.path.append('./book_material')\n",
    "from dataset.mnist import *\n",
    "(x_train, t_train), (x_test, t_test) = load_mnist(normalize=True, one_hot_label = True)"
   ],
   "outputs": [],
   "execution_count": 160
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-15T12:57:31.592366Z",
     "start_time": "2025-03-15T12:57:31.583407Z"
    }
   },
   "cell_type": "code",
   "source": [
    "##wb是模型本身的参数因此放在构造函数中无需手动进行更改 其他则由输入的x决定\n",
    "class Affine:\n",
    "    def __init__(self,w,b):\n",
    "        self.w=w\n",
    "        self.b=b\n",
    "        self.x=None\n",
    "        self.dw=None\n",
    "        self.db=None\n",
    "        self.dx=None\n",
    "    def forward(self,x):\n",
    "        if x.ndim==1:\n",
    "            x = x.reshape(1,-1)\n",
    "        self.x=x\n",
    "        output=np.dot(self.x, self.w)+self.b\n",
    "        return output\n",
    "    def backward(self,d_out):\n",
    "        self.dx=np.dot(d_out,self.w.T)\n",
    "        self.dw=np.dot(self.x.T,d_out)\n",
    "        self.db=np.sum(d_out,axis=0)\n",
    "        return self.dx\n",
    "\n",
    "class Relu:\n",
    "    def __init__(self):\n",
    "        self.mask=None\n",
    "    def forward(self,x):\n",
    "        self.mask=x>0\n",
    "        out=self.mask*x\n",
    "        return out\n",
    "    def backward(self,d_out):\n",
    "        dx=self.mask*d_out\n",
    "        return dx\n",
    "\n",
    "\n",
    "\n",
    "class Softmaxwithloss:\n",
    "    def __init__(self):\n",
    "        self.t=None\n",
    "        self.x=None\n",
    "        self.y=None\n",
    "        self.dx=None\n",
    "        self.batch_size = None\n",
    "    def forward(self,x):\n",
    "        if x.ndim==1:\n",
    "            x = x.reshape(1,-1)\n",
    "        self.x=x-np.max(x,axis=-1,keepdims=True)\n",
    "        self.batch_size = x.shape[0]\n",
    "        self.y=np.exp(self.x)/np.sum(np.exp(self.x),axis=-1,keepdims=True)\n",
    "        return self.y\n",
    "    def loss(self,x,t):\n",
    "\n",
    "        out=self.forward(x)\n",
    "        self.t=t\n",
    "        if t.ndim!=1:\n",
    "            loss_rate=np.sum(-self.t*np.log(out+1e-7))/self.batch_size\n",
    "        else:\n",
    "            loss_rate=-np.sum(np.log(out[np.arange(len(t)),t]+1e-7))/self.batch_size\n",
    "        return  loss_rate\n",
    "    \n",
    "    def backward(self,d_out=1,t=None):\n",
    "        self.t=t\n",
    "        if self.t.ndim!=1:\n",
    "            dx = (self.y - self.t) / self.batch_size\n",
    "        else:\n",
    "            y_c=self.y.copy()\n",
    "            # dx=(y_c[np.arange(len(self.t)),self.t]-1)/self.batch_size 这里错了\n",
    "            y_c[np.arange(len(self.t)),self.t] -=1\n",
    "            dx=y_c/self.batch_size\n",
    "        self.dx=dx\n",
    "        return self.dx\n",
    "\n",
    "class MultiLayersNetwork:\n",
    "    def __init__(self, input_size, output_size, hidden_size_list=None):\n",
    "        if hidden_size_list is None:\n",
    "            self.hidden_size_list = [100, 100, 100]\n",
    "        else:\n",
    "            self.hidden_size_list = hidden_size_list\n",
    "        self.input_size = input_size\n",
    "\n",
    "        self.output_size = output_size\n",
    "        self.params=dict()\n",
    "        self.sourcedata=None\n",
    "        self.layers= dict()\n",
    "        #生成层\n",
    "        parameter_size_list=self.hidden_size_list\n",
    "        parameter_size_list.insert(0,input_size)\n",
    "        parameter_size_list.append(self.output_size)\n",
    "        self.hidden_size_list=parameter_size_list\n",
    "\n",
    "        # for i in range(len(parameter_size_list) - 1): # 遍历所有 Affine 层\n",
    "        #     scale = np.sqrt(1.0 / parameter_size_list[i])\n",
    "        #     self.params['W' + str(i)] = np.random.randn(parameter_size_list[i], parameter_size_list[i + 1]) * scale # 使用 randn 初始化\n",
    "        #     self.params['b' + str(i)] = np.zeros(parameter_size_list[i + 1]) # 偏置初始化为 0\n",
    "        #     self.layers['affine' + str(i)] = Affine(self.params['W' + str(i)], self.params['b' + str(i)])\n",
    "        #\n",
    "        #     if i < len(parameter_size_list) - 2: # 除了最后一层 Affine，都添加 Relu\n",
    "        #         self.layers['relu' + str(i)] = Relu()\n",
    "        #     else: # 最后一层 Affine 之后添加 Softmaxwithloss\n",
    "        #         self.layers['Activation_function'] = Softmaxwithloss()\n",
    "\n",
    "\n",
    "        #倒数第二层之前全部用relu\n",
    "        for i in range(len(parameter_size_list)-2):\n",
    "            scale = np.sqrt(1.0 / parameter_size_list[i])\n",
    "            self.params['W'+str(i)]=np.random.randn(parameter_size_list[i],parameter_size_list[i+1])*scale\n",
    "            self.params['b'+str(i)]=np.zeros(parameter_size_list[i+1])\n",
    "            #每一层就自己层的权重和偏置\n",
    "            self.layers['affine'+str(i)]=Affine(self.params['W'+str(i)],self.params['b'+str(i)])\n",
    "            self.layers['relu'+str(i)]=Relu()\n",
    "\n",
    "        if i==len(parameter_size_list)-3:\n",
    "            i+=1\n",
    "            scale = np.sqrt(1.0 / parameter_size_list[i])\n",
    "            self.params['W'+str(i)]=np.random.randn(parameter_size_list[i],parameter_size_list[i+1])*scale\n",
    "            self.params['b'+str(i)]=np.zeros(parameter_size_list[i+1])\n",
    "            self.layers['affine'+str(i)]=Affine(self.params['W'+str(i)],self.params['b'+str(i)])\n",
    "            self.layers['Activation_function']=Softmaxwithloss()\n",
    "\n",
    "\n",
    "    def predict(self, x):\n",
    "        inputs=x\n",
    "        for key,func in self.layers.items():\n",
    "            inputs=func.forward(inputs)\n",
    "        return inputs\n",
    "\n",
    "    def backward(self,t,d_out=1):\n",
    "\n",
    "        back_list=list(self.layers.keys())\n",
    "        back_list.reverse()\n",
    "        d_out=d_out\n",
    "        for key in back_list:\n",
    "            if key=='Activation_function':\n",
    "                d_out=self.layers[key].backward(d_out,t=t)\n",
    "            else:\n",
    "                d_out=self.layers[key].backward(d_out)\n",
    "\n",
    "    def gradient(self,t):\n",
    "\n",
    "        self.backward(d_out=1,t=t)\n",
    "        grads=dict()\n",
    "        for idx in range(len(self.hidden_size_list)-1):\n",
    "            grads['W'+str(idx)]=self.layers['affine'+str(idx)].dw\n",
    "            grads['b'+str(idx)]=self.layers['affine'+str(idx)].db\n",
    "        return grads\n",
    "    def accuracy(self,x,t):\n",
    "        if t.ndim!=1: t=np.argmax(t,axis=1)\n",
    "        y=np.argmax(self.predict(x),axis=1)\n",
    "        return np.sum(y==t)/y.shape[0]"
   ],
   "id": "66f91ef2e2a40104",
   "outputs": [],
   "execution_count": 257
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-15T13:03:16.595204Z",
     "start_time": "2025-03-15T13:03:16.545824Z"
    }
   },
   "cell_type": "code",
   "source": [
    "mln=MultiLayersNetwork(input_size=784,output_size=10,hidden_size_list=[100,100])\n",
    "mln.accuracy(x_test,t_test)"
   ],
   "id": "427e8975999cf43d",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(0.0788)"
      ]
     },
     "execution_count": 261,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 261
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-15T13:05:34.514513Z",
     "start_time": "2025-03-15T13:03:18.107607Z"
    }
   },
   "cell_type": "code",
   "source": [
    "for i in range(200):\n",
    "    mln.predict(x_train)\n",
    "    grads=mln.gradient(t=t_train)\n",
    "    for key in grads.keys():\n",
    "        mln.params[key] -=0.1*grads[key]"
   ],
   "id": "940dc3ff15f2034f",
   "outputs": [],
   "execution_count": 262
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-15T13:05:50.530294Z",
     "start_time": "2025-03-15T13:05:50.476436Z"
    }
   },
   "cell_type": "code",
   "source": "mln.accuracy(x_test,t_test)",
   "id": "f1eeea610a837402",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(0.9072)"
      ]
     },
     "execution_count": 263,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 263
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "e9cd58aafdb88431"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
