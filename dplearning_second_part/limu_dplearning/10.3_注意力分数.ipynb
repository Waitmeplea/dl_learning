{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-05-09T07:35:29.270020Z",
     "start_time": "2025-05-09T07:35:28.524708Z"
    }
   },
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from utils.useful_func import *"
   ],
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-09T07:54:26.285410Z",
     "start_time": "2025-05-09T07:54:26.278113Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def masked_softmax(X, valid_lens):\n",
    "    \"\"\"通过在最后一个轴上掩蔽元素来执行softmax操作\"\"\"\n",
    "    # X为3D batch_size*x*y valid_len 最后一个轴的有效长度\n",
    "    # 如果valid_len是1d 则len必须等于X最外围的长度\n",
    "    # 如果valid_len是2d 则 reshape后必须等于 x的0层 *1层长度\n",
    "    if valid_lens is None:\n",
    "        return F.softmax(X, dim=-1)\n",
    "    else:\n",
    "        shape=X.shape\n",
    "        if valid_lens.ndim==1:\n",
    "            ## valid_lens是最后一个轴的长度 因此要扩展以匹配X维度\n",
    "            valid_lens = torch.repeat_interleave(valid_lens, shape[1])\n",
    "        else:\n",
    "            valid_lens = valid_lens.reshape(-1)\n",
    "    X=sequence_mask(X.reshape(-1, shape[-1]), valid_lens,value=-1e6)\n",
    "    return F.softmax(X, dim=-1)\n",
    "        "
   ],
   "id": "ef40f342e507797c",
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-09T07:55:25.015244Z",
     "start_time": "2025-05-09T07:55:25.005541Z"
    }
   },
   "cell_type": "code",
   "source": "x=torch.rand([2,3,5])",
   "id": "233f5a2ccb4ec3af",
   "outputs": [],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-09T07:56:37.459784Z",
     "start_time": "2025-05-09T07:56:37.450692Z"
    }
   },
   "cell_type": "code",
   "source": "masked_softmax(x,valid_lens=torch.tensor([3,2]))",
   "id": "b1b036ab1d3ddbc2",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.2861, 0.3829, 0.3310, 0.0000, 0.0000],\n",
       "        [0.2443, 0.4275, 0.3282, 0.0000, 0.0000],\n",
       "        [0.3074, 0.3590, 0.3336, 0.0000, 0.0000],\n",
       "        [0.3905, 0.6095, 0.0000, 0.0000, 0.0000],\n",
       "        [0.3660, 0.6340, 0.0000, 0.0000, 0.0000],\n",
       "        [0.4616, 0.5384, 0.0000, 0.0000, 0.0000]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 14
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-09T07:57:53.932306Z",
     "start_time": "2025-05-09T07:57:53.923526Z"
    }
   },
   "cell_type": "code",
   "source": "masked_softmax(torch.rand(2, 2, 4), torch.tensor([[1, 3], [2, 4]]))",
   "id": "535fbe8dee785017",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.0000, 0.0000, 0.0000, 0.0000],\n",
       "        [0.2686, 0.2477, 0.4837, 0.0000],\n",
       "        [0.5050, 0.4950, 0.0000, 0.0000],\n",
       "        [0.3359, 0.2150, 0.2300, 0.2191]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 15
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# 1、加性注意力",
   "id": "a954170bb8809b54"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "class AdditiveAttention(nn.Module):\n",
    "    \"\"\"加性注意力\"\"\"\n",
    "    def __init__(self,key_size,query_size,num_hiddens,dropout,**kwargs):\n",
    "        super(AdditiveAttention,self).__init__()\n",
    "        self.W_k = nn.Linear(key_size,num_hiddens,bias=False)\n",
    "        self.W_q = nn.Linear(query_size,num_hiddens,bias=False)\n",
    "        self.W_v = nn.Linear(num_hiddens,1,bias=False)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "    # queries 维度应该是 batch_size * 要查询的数量 * q_size向量长度\n",
    "    # keys 维度是 batch_size * keys的数量（key-value)键值对 * key向量长度\n",
    "    # values与key相等 value_size可以不一样\n",
    "    def forward(self, queries, keys, values, valid_lens): ## valid_len从输入来的 屏蔽掉填充部分\n",
    "        queries,keys=self.W_q(queries),self.W_k(keys)\n",
    "        queries=queries.unsqueeze(2)\n",
    "        keys=keys.unsqueeze(1)\n",
    "        features = queries + keys\n",
    "        features = torch.tanh(features)\n",
    "        scores = self.w_v(features).squeeze(-1)\n",
    "        self.attention_weights = masked_softmax(scores, valid_lens)\n",
    "        return torch.bmm(self.dropout(self.attention_weights), values)"
   ],
   "id": "ad2ce16f668ac41"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-09T08:59:55.228740Z",
     "start_time": "2025-05-09T08:59:55.222541Z"
    }
   },
   "cell_type": "code",
   "source": [
    "x=torch.ones([2,3,5])\n",
    "y=torch.ones([3,5])"
   ],
   "id": "ff24d3ef1926ba8a",
   "outputs": [],
   "execution_count": 25
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-09T08:59:55.479171Z",
     "start_time": "2025-05-09T08:59:55.471778Z"
    }
   },
   "cell_type": "code",
   "source": "x+y",
   "id": "8567fb4b9ed32ce1",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[2., 2., 2., 2., 2.],\n",
       "         [2., 2., 2., 2., 2.],\n",
       "         [2., 2., 2., 2., 2.]],\n",
       "\n",
       "        [[2., 2., 2., 2., 2.],\n",
       "         [2., 2., 2., 2., 2.],\n",
       "         [2., 2., 2., 2., 2.]]])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 26
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "ad0757af861032f1"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
