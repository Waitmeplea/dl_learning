{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-06-03T01:16:25.745139Z",
     "start_time": "2025-06-03T01:16:22.513711Z"
    }
   },
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from dplearning_second_part.limu_dplearning.utils.useful_func import masked_softmax"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-03T01:16:25.765057Z",
     "start_time": "2025-06-03T01:16:25.747141Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import math\n",
    "# 从0实现一个Encoderblock\n",
    "#1、点积注意力\n",
    "class DotProductAttention(nn.Module):\n",
    "    def __init__(self, dropout=0.1,**kwargs):\n",
    "        super(DotProductAttention, self).__init__(**kwargs)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "    def forward(self, q, k, v, valid_lens=None):\n",
    "        #q.shape[-1]是静态维度值（整数）将其包装为张量是冗余操作\n",
    "        # d_lens=torch.tensor(q.shape[-1],device=q.device)\n",
    "        d_lens=q.shape[-1]\n",
    "        #对于标量值，PyTorch会自动处理设备兼容性 所以不用显示todevice\n",
    "        attention_scores=torch.matmul(q,k.transpose(-1,-2)) / math.sqrt(d_lens)\n",
    "        self.attention_weights=masked_softmax(attention_scores, valid_lens)\n",
    "        return torch.matmul(self.dropout(self.attention_weights),v)\n",
    "\n",
    "class MultiHeadAttention(nn.Module):\n",
    "    def __init__(self,key_size,query_size,value_size,hidden_size,num_heads,dropout=0.1,bias=False,**kwargs):\n",
    "        super(MultiHeadAttention, self).__init__(**kwargs)\n",
    "        assert hidden_size%num_heads==0,'整除条件不满足！'\n",
    "        # 三个调整size的 全连接\n",
    "        # 易错点 这里的全连接层都是没有偏置项 因为后续会有layer_normal 即使添加偏置项后续也会在减均值的过程中被吸收掉\n",
    "        #         一个更广义的规则：\n",
    "        # 如果一个线性层（或卷积层）的输出紧接着一个归一化层（Batch Norm, Layer Norm, Instance Norm, Group Norm），那么这个线性层/卷积层中的偏置项就是冗余的，通常会将其设置为 False。\n",
    "        self.W_q=nn.Linear(query_size,hidden_size,bias=bias)\n",
    "        self.W_k=nn.Linear(key_size,hidden_size,bias=bias)\n",
    "        self.W_v=nn.Linear(value_size,hidden_size,bias=bias)\n",
    "        # 最终输出用的全连接\n",
    "        self.W_o=nn.Linear(hidden_size,hidden_size,bias=bias)\n",
    "        # 注意力函数\n",
    "        self.attention=DotProductAttention(dropout=dropout)\n",
    "        # 头数\n",
    "        self.num_heads=num_heads\n",
    "        # 隐藏层数\n",
    "        self.hidden_size=hidden_size\n",
    "\n",
    "\n",
    "    def forward(self,q,k,v,valid_lens=None):\n",
    "        #调整qkv最后一层\n",
    "        # reshape出头数 并放在第二各维度 避免影响遮掩的softmax\n",
    "        # 错了一个地方 self.hidden_size/self.num_heads结果默认是浮点即使结果是整数 reshape无法接受浮点 因此要用//\n",
    "        # q_temp=self.W_q(q).reshape(q.shape[0],q.shape[1],self.num_heads,self.hidden_size/self.num_heads).permute(0,2,1,3)\n",
    "        q_temp=self.W_q(q).reshape(q.shape[0],q.shape[1],self.num_heads,self.hidden_size//self.num_heads).permute(0,2,1,3)\n",
    "        k_temp=self.W_k(k).reshape(k.shape[0],k.shape[1],self.num_heads,self.hidden_size//self.num_heads).permute(0,2,1,3)\n",
    "        v_temp=self.W_v(v).reshape(v.shape[0],v.shape[1],self.num_heads,self.hidden_size//self.num_heads).permute(0,2,1,3)\n",
    "\n",
    "        # 转为三维 将 1 2维度合并\n",
    "        q_temp=q_temp.reshape(-1,q.shape[1],self.hidden_size//self.num_heads)\n",
    "        k_temp=k_temp.reshape(-1,k.shape[1],self.hidden_size//self.num_heads)\n",
    "        v_temp=v_temp.reshape(-1,v.shape[1],self.hidden_size//self.num_heads)\n",
    "\n",
    "        if valid_lens is not None:\n",
    "        # 这里很重要有一个知识点 看上面 其实是在batch_size 后增加了一个维度num_head 然后又reshape成batch_size*num_heads\n",
    "        # 这跟torch和numpy的存储方式有关系 contiguous (行主序)  当然也正是这种存储方式才使得我们要把num_heads 挪到第二维\n",
    "        # 由于每一个batch下增加的多个num_heads 其实都是归属在这个样本下的不同的注意力头的结果 对于这个样本其实他的valid_lens是不变的 也需要重复num_heads次\n",
    "        # 所以对于valid_lens 最简单的做法就是复制num_head次就行 所以使用repeat_interleave\n",
    "        # 当valid_lens 为2d明显要在batch_size维度进行复制，dim=0\n",
    "        # 当valid_lens为1维时，维度大小=batch_size 这跟我们实现的masked_softmax函数有关 显然也是在batch_size维度复制 所以无论valid_lens为多少维度 都是在dim=0维复制\n",
    "            valid_lens=valid_lens.repeat_interleave(self.num_heads,dim=0)\n",
    "\n",
    "\n",
    "        attention_result_total=self.attention(q_temp,k_temp,v_temp,valid_lens)\n",
    "        outputs=attention_result_total.reshape(q.shape[0],self.num_heads,q.shape[1],-1).permute(0,2,1,3).reshape(q.shape[0],q.shape[1],-1)\n",
    "        return self.W_o(outputs)\n",
    "\n",
    "class PositionalEncoding(nn.Module):\n",
    "    def __init__(self,max_len,hidden_size,dropout=0.1,**kwargs):\n",
    "        super(PositionalEncoding, self).__init__(**kwargs)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.P=torch.zeros(1,max_len,hidden_size)\n",
    "        # 易错点这里建议不用除法， 直接 ：：2 否则少一个\n",
    "        self.temp=torch.arange(1,max_len+1).unsqueeze(1)/(torch.pow(10000,torch.arange(0,hidden_size,2)/hidden_size))\n",
    "        #1,2 用 1位置  如果一共只有3个 那就是 只有\n",
    "        self.P[:,:,0::2]=torch.sin(self.temp)\n",
    "        self.P[:,:,1::2]=torch.cos(self.temp)\n",
    "\n",
    "    def forward(self,x):\n",
    "        # 注意p和x在第二个维度不一定一样,device也不一定一样\n",
    "        x = x + self.P[:,:x.shape[1],:].to(x.device)\n",
    "        return self.dropout(x)\n",
    "\n",
    "class AddNorm(nn.Module):\n",
    "    def __init__(self,norm_shape,dropout=0.1,**kwargs):\n",
    "        super(AddNorm, self).__init__(**kwargs)\n",
    "        self.norm=nn.LayerNorm(norm_shape)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "    def forward(self,x,y):\n",
    "        return self.norm(x+self.dropout(y))\n",
    "\n",
    "class PositionWiseFFN(nn.Module):\n",
    "    def __init__(self,ffninput_size,ffnhidden_size,ffnoutput_size,**kwargs):\n",
    "        super(PositionWiseFFN, self).__init__(**kwargs)\n",
    "        self.dense1 = nn.Linear(ffninput_size,ffnhidden_size)\n",
    "        self.relu=nn.ReLU()\n",
    "        self.dense2=nn.Linear(ffnhidden_size,ffnoutput_size)\n",
    "    def forward(self,x):\n",
    "        x_temp = self.relu(self.dense1(x))\n",
    "        return self.dense2(x_temp)\n",
    "\n",
    "class EncoderBlock(nn.Module):\n",
    "    def __init__(self,key_size,query_size,value_size,hidden_size,num_heads,norm_shape,ffninput_size,ffnhidden_size,dropout=0.1,bias=False,**kwargs):\n",
    "        super(EncoderBlock, self).__init__(**kwargs)\n",
    "        # 位置编码 max=1000 hidden_size 和query的size一样 不是在块里完成的\n",
    "        # self.position_enc = PositionalEncoding(1000,query_size,dropout=dropout)\n",
    "        # 多头自注意力key_size,query_size,value_size,hidden_size这四个应该是全都相等\n",
    "        self.attention=MultiHeadAttention(key_size,query_size,value_size,hidden_size,num_heads,dropout=dropout,bias=bias)\n",
    "        #位置前馈 ffninput_size=ffnoutput_size=hidden_size\n",
    "        self.position_ffn=PositionWiseFFN(ffninput_size,ffnhidden_size,hidden_size,**kwargs)\n",
    "        # norm_shape = (l,hidden_size)\n",
    "        self.add_norm=AddNorm(norm_shape,dropout=dropout)\n",
    "\n",
    "    def forward(self,x_position,valid_lens=None):\n",
    "        y_attention=self.attention(x_position,x_position,x_position,valid_lens=valid_lens)\n",
    "        x_first=self.add_norm(x_position,y_attention)\n",
    "        return self.add_norm(x_first,self.position_ffn(x_first))\n"
   ],
   "id": "ec21eeaa92ac51a1",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-03T01:16:25.776467Z",
     "start_time": "2025-06-03T01:16:25.766089Z"
    }
   },
   "cell_type": "code",
   "source": [
    "x=torch.ones((2,100,24))\n",
    "valid_lens=torch.tensor([3,2])"
   ],
   "id": "139505ce5e9fa36d",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-03T01:16:25.820790Z",
     "start_time": "2025-06-03T01:16:25.777467Z"
    }
   },
   "cell_type": "code",
   "source": [
    "encoder_blk=EncoderBlock(key_size=24,query_size=24,value_size=24,hidden_size=24,num_heads=8,norm_shape=[100,24],ffninput_size=24,ffnhidden_size=48,dropout=0.5)\n",
    "encoder_blk.eval()\n",
    "encoder_blk(x,valid_lens)"
   ],
   "id": "d6476f69ae0c5b82",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-0.1752, -0.7221, -1.1955,  ..., -0.2713,  0.0357, -0.8350],\n",
       "         [-0.1752, -0.7221, -1.1955,  ..., -0.2713,  0.0357, -0.8350],\n",
       "         [-0.1752, -0.7221, -1.1955,  ..., -0.2713,  0.0357, -0.8350],\n",
       "         ...,\n",
       "         [-0.1752, -0.7221, -1.1955,  ..., -0.2713,  0.0357, -0.8350],\n",
       "         [-0.1752, -0.7221, -1.1955,  ..., -0.2713,  0.0357, -0.8350],\n",
       "         [-0.1752, -0.7221, -1.1955,  ..., -0.2713,  0.0357, -0.8350]],\n",
       "\n",
       "        [[-0.1752, -0.7221, -1.1955,  ..., -0.2713,  0.0357, -0.8350],\n",
       "         [-0.1752, -0.7221, -1.1955,  ..., -0.2713,  0.0357, -0.8350],\n",
       "         [-0.1752, -0.7221, -1.1955,  ..., -0.2713,  0.0357, -0.8350],\n",
       "         ...,\n",
       "         [-0.1752, -0.7221, -1.1955,  ..., -0.2713,  0.0357, -0.8350],\n",
       "         [-0.1752, -0.7221, -1.1955,  ..., -0.2713,  0.0357, -0.8350],\n",
       "         [-0.1752, -0.7221, -1.1955,  ..., -0.2713,  0.0357, -0.8350]]],\n",
       "       grad_fn=<NativeLayerNormBackward0>)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-03T01:16:25.830187Z",
     "start_time": "2025-06-03T01:16:25.821789Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class TransformerEncoder(nn.Module):\n",
    "    def __init__(self,vocab_size,key_size,query_size,value_size,hidden_size,num_head,norm_shape,\n",
    "                 num_layers,ffninput_size,ffnhidden_size,dropout=0.1,bias=False,*args):\n",
    "        super(TransformerEncoder, self).__init__(*args)\n",
    "        self.hidden_size=hidden_size\n",
    "        self.embedding = nn.Embedding(vocab_size,hidden_size)\n",
    "        self.position_embedding = PositionalEncoding(1000,hidden_size,dropout=dropout)\n",
    "        self.blks=nn.Sequential()\n",
    "        for i in range(num_layers):\n",
    "            self.blks.add_module(f'{i}'+'blk'\n",
    "                                 ,EncoderBlock(hidden_size,hidden_size,hidden_size,hidden_size,num_head,norm_shape,ffninput_size,ffnhidden_size,dropout=dropout,bias=bias))\n",
    "    def forward(self,x,valid_lens=None):\n",
    "        x = self.embedding(x)\n",
    "        # torch.sqrt的输入必须是tensor\n",
    "        # 当一个 torch.Tensor 与一个 Python 标量进行算术运算（如加、减、乘、除）时，PyTorch 会自动将该标量广播 (broadcast) 到张量的所有元素上，并进行操作。\n",
    "        x_position=self.position_embedding(x*torch.sqrt(torch.tensor(self.hidden_size)))\n",
    "        self.attention_weights=[None]*len(self.blks)\n",
    "        # 易错点 这个地方不能这么写因为 X valid_lens是两个参数 sequential只支持一个参数传递\n",
    "        # return self.blks(x_position,valid_lens)\n",
    "        for num,module in enumerate(self.blks):\n",
    "            x_position=module(x_position,valid_lens=valid_lens)\n",
    "            self.attention_weights[num]=module.attention.attention.attention_weights\n",
    "        return x_position"
   ],
   "id": "ed5555a64640855d",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-03T01:16:25.854139Z",
     "start_time": "2025-06-03T01:16:25.831186Z"
    }
   },
   "cell_type": "code",
   "source": [
    "encoder = TransformerEncoder(\n",
    "    200, 24, 24, 24, 24,2, [100, 24],4, 24, 48, 0.5)\n",
    "encoder.eval()\n",
    "encoder(torch.ones((2, 100), dtype=torch.long), valid_lens).shape"
   ],
   "id": "7dd3de3c5b063dca",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 100, 24])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-03T01:16:25.869043Z",
     "start_time": "2025-06-03T01:16:25.861224Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class BERTEncoder(nn.Module):\n",
    "    \"\"\"BERT编码器\"\"\"\n",
    "    def __init__(self,vocab_size,hidden_size,num_head,norm_shape,ffninput_size\n",
    "                 ,ffnhidden_size,num_layers,dropout=0.1,bias=False,max_lens=1000,key_size=768,query_size=768,value_size=768,**kwargs):\n",
    "        super(BERTEncoder, self).__init__(**kwargs)\n",
    "        self.hidden_size=hidden_size\n",
    "        self.token_embedding = nn.Embedding(vocab_size,hidden_size)\n",
    "        self.segment_embedding = nn.Embedding(2,hidden_size)\n",
    "        self.blks=nn.ModuleList()\n",
    "        for i in range(num_layers):\n",
    "            self.blks.add_module(f'{i}'+'blk',EncoderBlock(key_size,query_size,value_size\n",
    "                    ,hidden_size,num_head,norm_shape,ffninput_size,ffnhidden_size,dropout=dropout,bias=bias))\n",
    "        # 可学习的位置参数\n",
    "        # 在BERT中，位置嵌入是可学习的，因此我们创建一个足够长的位置嵌入参数\n",
    "        self.position_embedding = nn.Parameter(torch.randn(1,max_lens,hidden_size))\n",
    "    def forward(self,tokens,segments,valid_lens=None):\n",
    "        tokens,segments=self.token_embedding(tokens),self.segment_embedding(segments)\n",
    "        x=tokens+segments+self.position_embedding.repeat(tokens.shape[0],1,1)[:,:tokens.shape[1],:]\n",
    "        for i,blk in enumerate(self.blks):\n",
    "            x=blk(x,valid_lens=valid_lens)\n",
    "        return x"
   ],
   "id": "57f16d3620c2a44c",
   "outputs": [],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-03T01:16:26.012315Z",
     "start_time": "2025-06-03T01:16:25.870043Z"
    }
   },
   "cell_type": "code",
   "source": [
    "vocab_size, hidden_size, ffnhidden_size, num_heads = 10000, 768, 1024, 4\n",
    "norm_shape, ffninput_size, num_layers, dropout = [768], 768, 2, 0.2\n",
    "encoder = BERTEncoder(vocab_size, hidden_size, num_heads, norm_shape, ffninput_size,\n",
    "                      ffnhidden_size, num_layers, dropout)"
   ],
   "id": "ca6b3a4d62f8c9d",
   "outputs": [],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-03T01:16:26.030186Z",
     "start_time": "2025-06-03T01:16:26.013687Z"
    }
   },
   "cell_type": "code",
   "source": [
    "tokens = torch.randint(0, vocab_size, (2, 8))\n",
    "segments = torch.tensor([[0, 0, 0, 0, 1, 1, 1, 1], [0, 0, 0, 1, 1, 1, 1, 1]])\n",
    "encoded_X = encoder(tokens, segments, None)\n",
    "encoded_X.shape"
   ],
   "id": "ace233bd493de7cc",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 8, 768])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-03T01:42:02.975934Z",
     "start_time": "2025-06-03T01:42:02.968275Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class MaskLM(nn.Module):\n",
    "    \"\"\"BERT的掩蔽语言模型任务\"\"\"\n",
    "    def __init__(self,vocab_size,hidden_size,inputs_size=768,**kwargs):\n",
    "        super(MaskLM, self).__init__(**kwargs)\n",
    "        self.mlp=nn.Sequential(nn.Linear(inputs_size,hidden_size),\n",
    "                               nn.ReLU(),\n",
    "                               nn.LayerNorm(hidden_size),\n",
    "                               nn.Linear(hidden_size,vocab_size),\n",
    "                               )\n",
    "    def forward(self, X, pred_positions):\n",
    "        # 每个样本要预测的个数\n",
    "        num_pred_positions = pred_positions.shape[1]\n",
    "        \n",
    "        # 把idx展平 以便作为第二维度\n",
    "        pred_positions = pred_positions.reshape(-1)\n",
    "        \n",
    "        # 获取第一个维度\n",
    "        batch_size = X.shape[0]\n",
    "        batch_idx = torch.arange(batch_size)\n",
    "        # 要给每个pred_postion索引配一个batch_size索引 这样二维索引可以筛选出所有的mask位置\n",
    "        batch_idx=batch_idx.repeat_interleave(num_pred_positions)\n",
    "        masked_X =X[batch_idx,pred_positions]\n",
    "        masked_X=masked_X.reshape(batch_size,num_pred_positions,-1)\n",
    "        mlm_Y_hat = self.mlp(masked_X)\n",
    "        return mlm_Y_hat"
   ],
   "id": "e3ab485479ce9682",
   "outputs": [],
   "execution_count": 31
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-03T01:43:00.254228Z",
     "start_time": "2025-06-03T01:43:00.203833Z"
    }
   },
   "cell_type": "code",
   "source": [
    "mlm = MaskLM(vocab_size, hidden_size)\n",
    "mlm_positions = torch.tensor([[1, 5, 2], [6, 1, 5]])\n",
    "mlm_Y_hat = mlm(encoded_X, mlm_positions)\n",
    "mlm_Y_hat.shape"
   ],
   "id": "69a0b48b86fab472",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 3, 10000])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 35
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-03T01:42:18.620693Z",
     "start_time": "2025-06-03T01:42:18.617475Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class NextSentencePred(nn.Module):\n",
    "    \"\"\"bert的下一句预测任务\"\"\"\n",
    "    def __init__(self,num_inputs,**kwargs):\n",
    "        super(NextSentencePred,self).__init__(**kwargs)\n",
    "        self.out=nn.Linear(num_inputs,2)\n",
    "    def forward(self,x):\n",
    "        # X的形状：(batchsize,num_hiddens)\n",
    "        return self.out(x)"
   ],
   "id": "bd3252d63d283438",
   "outputs": [],
   "execution_count": 33
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-03T01:36:49.810732Z",
     "start_time": "2025-06-03T01:36:49.805521Z"
    }
   },
   "cell_type": "code",
   "source": "mask_x=x[[1,1,0,1],[1,2,2,1]]",
   "id": "4cb0b036fbb1a79f",
   "outputs": [],
   "execution_count": 27
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-03T01:36:50.408088Z",
     "start_time": "2025-06-03T01:36:50.403671Z"
    }
   },
   "cell_type": "code",
   "source": "mask_x",
   "id": "4628e59a0f9a7f69",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0.3522, -0.3542,  1.7753,  0.3522])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 28
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# 数据集",
   "id": "b4230e032e483ed5"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-03T03:10:26.224644Z",
     "start_time": "2025-06-03T03:10:26.220796Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os\n",
    "import random\n",
    "import torch\n",
    "import requests\n",
    "import pandas as pd\n",
    "from d2l import torch as d2l\n",
    "train_file=r'D:\\code_file\\dplearning_second_part\\data\\wikitext2\\train-00000-of-00001.parquet'"
   ],
   "id": "f038a07bdcaf3de0",
   "outputs": [],
   "execution_count": 64
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-03T03:10:28.664629Z",
     "start_time": "2025-06-03T03:10:28.661781Z"
    }
   },
   "cell_type": "code",
   "source": "data_dir=train_file",
   "id": "99d10272874cdfa6",
   "outputs": [],
   "execution_count": 65
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-03T07:45:37.047189Z",
     "start_time": "2025-06-03T07:45:36.840354Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def _read_wiki(data_dir):\n",
    "    file_name=data_dir\n",
    "    lines=pd.read_parquet(file_name).to_numpy().tolist()\n",
    "    paragraphs = [line[0].strip().lower().split('.') for line in lines if len(line[0].split('.'))>=2]\n",
    "    random.shuffle(paragraphs)\n",
    "    return paragraphs\n",
    "d=_read_wiki(data_dir)"
   ],
   "id": "7eb01b0bbb97b625",
   "outputs": [],
   "execution_count": 85
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def get_tokens_and_segments(tokens_a,tokens_b=None):\n",
    "    tokens=['<cls>']+tokens_a+['<sep>']\n",
    "    segments=[0]*len(tokens)\n",
    "    if tokens_b is not None:\n",
    "        tokens=tokens+tokens_b+['<sep>']\n",
    "        segments=segments+[1]*(len(tokens_b)+1)\n",
    "    return tokens,segments\n",
    "get_tokens_and_segments(tokens_a=['a'])\n",
    "\n",
    "# 生成下一句预测任务的\n",
    "def _get_next_sentence(sentence,next_sentence,paragraphs):\n",
    "    if random.random()<0.5:\n",
    "        is_next=True\n",
    "    else:\n",
    "        # paragraph 三种列表嵌套\n",
    "        next_sentence=random.choice(random.choice(paragraphs))\n",
    "        is_next=False\n",
    "    return sentence,next_sentence,is_next\n",
    "\n",
    "def _get_nsp_data_from_paragraph(paragraph,paragraphs,vocab,max_len):\n",
    "    nsp_data_from_paragraph=[]\n",
    "    for i in range(len(paragraph)-1):\n",
    "        tokens_a, tokens_b, is_next = _get_next_sentence(paragraph[i], paragraph[i + 1], paragraphs)\n",
    "        if len(tokens_a)+len(tokens_b)>max_len:\n",
    "            continue\n",
    "        tokens,segments = get_tokens_and_segments(tokens_a,tokens_b)\n",
    "        nsp_data_from_paragraph.append((tokens,segments,is_next))\n",
    "    return nsp_data_from_paragraph\n",
    "        "
   ],
   "id": "fd088f5f403e7449"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-03T07:47:38.155666Z",
     "start_time": "2025-06-03T07:47:38.148324Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def _replace_mlm_tokens(tokens,candidate_pred_positions,num_mlm_preds,vocab):\n",
    "    # 为遮蔽语言模型的输入创建新的词元副本，其中输入可能包含替换的<mask> 或随机词元\n",
    "    mlm_"
   ],
   "id": "9c899bef8cad770e",
   "outputs": [],
   "execution_count": 87
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-03T07:45:43.205345Z",
     "start_time": "2025-06-03T07:45:43.201134Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "f99b345734202728",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['the band \\'s set list was similar to that of most shows on the popmart tour , but with \" sunday bloody sunday \" in place of the edge \\'s karaoke segment and the addition of \" miss sarajevo \" in the second encore ',\n",
       " ' the night was a celebration of the end of the war , with bono setting the tone by shouting out \" viva sarajevo ! <unk> the past , kiss the future ! \" at the beginning of \" even better than the real thing \" ',\n",
       " ' bono had struggled with his voice throughout the tour , and the morning of the concert he <unk> up \" without a voice \" ',\n",
       " ' there was no intent to cancel , and the show went ahead as planned ',\n",
       " ' though bono had few difficulties through the opening quartet of \" <unk> \" , \" i will follow \" , \" gone \" , and \" even better than the real thing \" , his voice gave out during \" last night on earth \" ',\n",
       " ' in 2006 , the edge suggested that bono \\'s vocal troubles had been caused by <unk> or by the stress of the previous few months of touring , though he later remarked that \" it didn \\'t really matter that our lead singer was under the weather because every member of the audience seemed to join in on every song ',\n",
       " ' there was a mass chorus for the whole concert ',\n",
       " ' \"']"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 86
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "ceb648d2f9480156"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "de90599366c93f6"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
