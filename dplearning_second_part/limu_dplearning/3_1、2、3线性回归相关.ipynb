{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    ""
   ]
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-04T03:53:59.846627Z",
     "start_time": "2025-04-04T03:53:59.842251Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from dplearning_first_part.dplearning_yushu.book_material.ch06.optimizer_compare_naive import optimizer, params\n",
    "#%matplotlib inline 是 Jupyter Notebook/Jupyter Lab 环境中使用的 IPython 魔法命令，\n",
    "# 主要作用是将 Matplotlib 绘制的图形直接嵌入到 Notebook 界面中（而不是弹出独立窗口显示）。\n",
    "%matplotlib inline\n",
    "import math\n",
    "import time\n",
    "import numpy as np\n",
    "import torch\n",
    "import sys\n",
    "sys.path.append(\"./utils\")\n",
    "from defined_functions import Timer"
   ],
   "id": "8b56d0d705a672b6",
   "outputs": [],
   "execution_count": 32
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 矢量化加速",
   "id": "c13ea118dec6de91"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-04T03:54:00.727144Z",
     "start_time": "2025-04-04T03:54:00.660279Z"
    }
   },
   "cell_type": "code",
   "source": [
    "n = 10000\n",
    "a = torch.ones([n])\n",
    "b = torch.ones([n])\n",
    "c = torch.zeros(n)\n",
    "timer = Timer()\n",
    "for i in range(n):\n",
    "    c[i] = a[i] + b[i]\n",
    "f'{timer.stop():.5f} sec'"
   ],
   "id": "142d53290a515def",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0.06371 sec'"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 33
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-04T03:54:00.847720Z",
     "start_time": "2025-04-04T03:54:00.844433Z"
    }
   },
   "cell_type": "code",
   "source": [
    "timer.start()\n",
    "d = a + b\n",
    "f'{timer.stop():.5f} sec'"
   ],
   "id": "411b77e067b60eef",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0.00021 sec'"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 34
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 从零实现线性回归",
   "id": "38a258480a34e433"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-04T10:28:53.078304Z",
     "start_time": "2025-04-04T10:28:52.778784Z"
    }
   },
   "cell_type": "code",
   "source": [
    "%matplotlib inline\n",
    "import random\n",
    "import torch"
   ],
   "id": "ad6a1d059bd57f51",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "torch.matmul(x,y)  \n",
    "用途：支持更高维度张量和广播机制，适用于多种场景：  \n",
    "二维矩阵相乘（等价于 torch.mm）。  \n",
    "矩阵与向量相乘（等价于 torch.mv）。  \n",
    "批量矩阵相乘（如处理三维张量时）。  \n",
    "自动处理维度扩展（广播）。  \n",
    "输入要求：  \n",
    "输入可以是任意维度，但最后两维需符合矩 阵乘法规则。 注意最后两位需要满足矩阵乘法规则"
   ],
   "id": "bf6e429aa957eabd"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-04T10:28:53.122140Z",
     "start_time": "2025-04-04T10:28:53.105623Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "x=torch.randn([2,3,2])\n",
    "y=torch.randn([1,2,2])\n",
    "torch.matmul(x,y)"
   ],
   "id": "24df9b12da928808",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.0987,  0.4689],\n",
       "         [-0.9510, -2.7583],\n",
       "         [-0.1594, -0.6459]],\n",
       "\n",
       "        [[ 2.1192,  6.1775],\n",
       "         [ 0.7655,  1.8190],\n",
       "         [-0.5874, -1.4433]]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "从0实现线性回归",
   "id": "4e76f4b696f5d06c"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-04T10:28:53.409161Z",
     "start_time": "2025-04-04T10:28:53.406863Z"
    }
   },
   "cell_type": "code",
   "source": "import torch",
   "id": "f928134037b0aeae",
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-04T10:28:53.590765Z",
     "start_time": "2025-04-04T10:28:53.587419Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def synthetic_data(w, b, num_examples):  #@save\n",
    "    \"\"\"生成y=Xw+b+噪声\"\"\"\n",
    "# PyTorch 的隐式规则：一维向量在矩阵乘法中根据位置被隐式视为列向量（右乘时）或行向量（左乘时），但结果会被压缩为一维。\n",
    "# 数学一致性：这种行为与数学中矩阵乘法的列向量约定一致。\n",
    "# 推荐实践：在涉及多维运算时，显式管理维度（如使用 unsqueeze 或 reshape）可以提高代码可读性并避免错误\n",
    "    X = torch.normal(0, 1, (num_examples, len(w)))\n",
    "    y = torch.matmul(X, w) + b\n",
    "\n",
    "    y += torch.normal(0, 0.01, y.shape)\n",
    "    return X, y.reshape((-1, 1))\n",
    "\n",
    "def data_iter(batch_size, features, labels):\n",
    "    num_examples = len(features)\n",
    "    indices = list(range(num_examples))\n",
    "    random.shuffle(indices)\n",
    "    for i in range(0, num_examples, batch_size):\n",
    "        batch_indices= indices[i: min(i + batch_size, num_examples)]\n",
    "        yield features[batch_indices], labels[batch_indices]\n",
    "\n",
    "##Python 中的 yield 关键字用于定义生成器函数（generator），\n",
    "# 它的核心作用是暂停函数的执行并保留当前状态，使得函数可以逐步产生（生成）一系列值，\n",
    "# 而不是一次性返回所有结果。这种“惰性计算”特性让生成器在处理大数据、流式处理或无限序列时非常高效。"
   ],
   "id": "9d9a561ce4fc899b",
   "outputs": [],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-04T10:28:53.759552Z",
     "start_time": "2025-04-04T10:28:53.756768Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "###定义模型\n",
    "def linear(x,w,b):\n",
    "    return torch.matmul(x,w) + b\n",
    "\n",
    "##损失函数\n",
    "def square_loss(y_hat,y):\n",
    "    return (y_hat-y.reshape(y_hat.shape))**2/2\n",
    "\n",
    "\n",
    "def sgd(params, lr, batch_size):\n",
    "    with torch.no_grad():\n",
    "        for param in params:\n",
    "            param -=lr*param.grad/batch_size\n",
    "            param.grad.zero_()"
   ],
   "id": "ba8fead7b51414a8",
   "outputs": [],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-04T10:28:53.956658Z",
     "start_time": "2025-04-04T10:28:53.926295Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#初始化权重\n",
    "w=torch.normal(0,0.01,size=(2,1),requires_grad=True)\n",
    "b=torch.zeros(1,requires_grad=True)\n",
    "lr = 0.03\n",
    "num_epochs = 3\n",
    "net = linear\n",
    "loss = square_loss\n",
    "batch_size=10\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    for x,y in data_iter(batch_size, features, labels):\n",
    "        test_x=net(x,w,b)\n",
    "        test_y=y\n",
    "        l = loss(net(x,w,b), y)\n",
    "        l.sum().backward()\n",
    "        sgd([w,b],lr,batch_size)\n",
    "    with torch.no_grad():\n",
    "        tran_l = loss(net(features,w,b), labels)\n",
    "        print(f'{epoch},loss{tran_l.mean()}')"
   ],
   "id": "876c9a8f0b073275",
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'batch_size' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[10], line 10\u001B[0m\n\u001B[0;32m      7\u001B[0m loss \u001B[38;5;241m=\u001B[39m square_loss\n\u001B[0;32m      9\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m epoch \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(num_epochs):\n\u001B[1;32m---> 10\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m x,y \u001B[38;5;129;01min\u001B[39;00m data_iter(\u001B[43mbatch_size\u001B[49m, features, labels):\n\u001B[0;32m     11\u001B[0m         test_x\u001B[38;5;241m=\u001B[39mnet(x,w,b)\n\u001B[0;32m     12\u001B[0m         test_y\u001B[38;5;241m=\u001B[39my\n",
      "\u001B[1;31mNameError\u001B[0m: name 'batch_size' is not defined"
     ]
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "线性回归 pytorch简洁实现",
   "id": "5673ce9f26abdb07"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-04T10:29:28.988358Z",
     "start_time": "2025-04-04T10:29:28.982023Z"
    }
   },
   "cell_type": "code",
   "source": [
    "x=torch.ones([2,3])\n",
    "w=torch.ones([3])\n",
    "y=torch.matmul(x, w)\n",
    "\n",
    "true_w = torch.tensor([2, -3.4])\n",
    "true_b = 4.2\n",
    "features, labels = synthetic_data(true_w, true_b, 1000)"
   ],
   "id": "8fbddc110570cc4f",
   "outputs": [],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-04T10:29:35.399098Z",
     "start_time": "2025-04-04T10:29:35.392034Z"
    }
   },
   "cell_type": "code",
   "source": "from torch.utils import data",
   "id": "59d555437d3b1e55",
   "outputs": [],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-04T10:47:44.295998Z",
     "start_time": "2025-04-04T10:47:44.293364Z"
    }
   },
   "cell_type": "code",
   "source": [
    "##data.TensorDataset是dataset子类 一个快速把特征标签，针对特定场景（张量数据）做了简化封装\n",
    "def load_array(data_arrays,batch_size,is_train=True):\n",
    "    dataset=data.TensorDataset(*data_arrays)\n",
    "    return data.DataLoader(dataset=dataset,batch_size=batch_size,shuffle=is_train)\n",
    "\n",
    "batch_size=10\n",
    "data_iter=load_array((features,labels),batch_size)"
   ],
   "id": "671fdec8c498f0df",
   "outputs": [],
   "execution_count": 25
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-04T11:01:47.926242Z",
     "start_time": "2025-04-04T11:01:47.924023Z"
    }
   },
   "cell_type": "code",
   "source": [
    "###定义模型\n",
    "from torch import nn"
   ],
   "id": "99755ebd5e1e2bab",
   "outputs": [],
   "execution_count": 38
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-04T11:22:59.742793Z",
     "start_time": "2025-04-04T11:22:59.739773Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# nn.MSELoss 初始化参数\n",
    "# 参数列表（PyTorch 1.10+ 版本）\n",
    "# 参数名\t类型\t默认值\t描述\n",
    "# reduction\tstr\t'mean'\t指定损失的计算方式，可选 'none'、'mean' 或 'sum'。\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.sequential=nn.Sequential(\n",
    "            nn.Linear(2,1)\n",
    "        )\n",
    "        self.loss_function = nn.MSELoss()\n",
    "    def forward(self, x):\n",
    "        return self.sequential(x)\n",
    "    def loss(self,x,y):\n",
    "        x=self.forward(x)\n",
    "        return self.loss_function(x,y)\n",
    "    def optim(self,lr):\n",
    "        return torch.optim.SGD(self.parameters(),lr=lr)"
   ],
   "id": "e1ab39aa2456c978",
   "outputs": [],
   "execution_count": 57
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-04T11:23:01.460771Z",
     "start_time": "2025-04-04T11:23:01.456868Z"
    }
   },
   "cell_type": "code",
   "source": [
    "net=Net()\n",
    "###参数初始化，使用sequential访问图层，然后weight.data和bias.data方法访问参数\n",
    "## 可以使用替换方法normal_和fill_来重写参数值。\n",
    "net.sequential[0].weight.data.normal_(0,0.01)\n",
    "net.sequential[0].bias.data.fill_(0)"
   ],
   "id": "b70071e39983fbda",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.])"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 58
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-04T11:30:56.844006Z",
     "start_time": "2025-04-04T11:30:56.763632Z"
    }
   },
   "cell_type": "code",
   "source": [
    "epoch=3\n",
    "for i in range(epoch):\n",
    "    for x,y in data_iter:\n",
    "        net.optim(lr=0.03).zero_grad()\n",
    "        l=net.loss(x,y)\n",
    "        l.backward()\n",
    "        net.optim(lr=0.03).step()\n",
    "    with torch.no_grad():\n",
    "        l=net.loss(features,labels).mean()\n",
    "        print(f'{i},loss{l.item()}')"
   ],
   "id": "5f3a09783c2fa6fc",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0,loss0.00010285895405104384\n",
      "1,loss0.00010266688332194462\n",
      "2,loss0.00010257143730996177\n"
     ]
    }
   ],
   "execution_count": 65
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-04T11:23:39.976990Z",
     "start_time": "2025-04-04T11:23:39.973408Z"
    }
   },
   "cell_type": "code",
   "source": [
    "for i in net.parameters():\n",
    "    print(i)"
   ],
   "id": "c2511af12a63554e",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([[ 1.9944, -3.3877]], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([4.1873], requires_grad=True)\n"
     ]
    }
   ],
   "execution_count": 63
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "c60c60c879bf29dd"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
