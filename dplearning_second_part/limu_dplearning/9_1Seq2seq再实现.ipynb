{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-16T01:09:22.404953Z",
     "start_time": "2025-05-16T01:09:22.401187Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from utils.useful_func import *\n",
    "\n",
    "\n",
    "# pack_padded_sequence打包需要mask的方法\n",
    "# import torch\n",
    "# from torch.nn.utils.rnn import pack_padded_sequence\n",
    "# \n",
    "# # 输入数据：批次大小 3，序列最大长度 5，词向量维度 2\n",
    "# padded_sequences = torch.randn(5, 3, 2)  # shape (seq_len, batch_size, input_size)\n",
    "# lengths = torch.tensor([5, 3, 2], dtype=torch.long)  # 实际长度（已降序排列）\n",
    "# \n",
    "# # 打包序列\n",
    "# packed = pack_padded_sequence(\n",
    "#     input=padded_sequences,\n",
    "#     lengths=lengths,\n",
    "#     batch_first=False,\n",
    "#     enforce_sorted=True\n",
    "# )"
   ],
   "id": "39d2e720c0ce90fb",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-16T01:45:56.664103Z",
     "start_time": "2025-05-16T01:45:44.631555Z"
    }
   },
   "cell_type": "code",
   "source": [
    "src, tgt = tokenize_nmt(preprocess_nmt(read_data_nmt()))\n",
    "src_vocab = Vocal(src, min_feq=2,\n",
    "                  reserved_tokens=['<pad>', '<bos>', '<eos>'])\n",
    "tgt_vocab = Vocal(tgt, min_feq=2,\n",
    "                  reserved_tokens=['<pad>', '<bos>', '<eos>'])\n",
    "src_data, src_valid = build_array_nmt(src, src_vocab, 10)\n",
    "tgt_data, tgt_valid = build_array_nmt(tgt, tgt_vocab, 10)\n",
    "dataset = torch.utils.data.TensorDataset(src_data, src_valid, tgt_data, tgt_valid)\n",
    "## 训练数据\n",
    "train_data = torch.utils.data.DataLoader(dataset=dataset, batch_size=32, shuffle=True)"
   ],
   "id": "a1df2f5b5dd34aba",
   "outputs": [],
   "execution_count": 39
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-16T01:45:27.102565Z",
     "start_time": "2025-05-16T01:45:27.095442Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        super(Encoder, self).__init__()\n",
    "        pass\n",
    "\n",
    "    def forward(self, X, *args, **kwargs):\n",
    "        raise NotImplementedError\n",
    "\n",
    "\n",
    "class Decoder(nn.Module):\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        super(Decoder, self).__init__()\n",
    "        pass\n",
    "\n",
    "    def init_state(self, enc_outputs, *args, **kwargs):\n",
    "        raise NotImplementedError\n",
    "\n",
    "    def forward(self, X, state, *args, **kwargs):\n",
    "        raise NotImplementedError\n",
    "\n",
    "\n",
    "class EncoderDecoder(nn.Module):\n",
    "    def __init__(self, encoder, decoder, *args, **kwargs):\n",
    "        super(EncoderDecoder, self).__init__(*args, **kwargs)\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "\n",
    "    def forward(self, enc_x, dec_x, *args, **kwargs):\n",
    "        enc_outputs = self.encoder(enc_x, *args, **kwargs)\n",
    "        dec_state = self.decoder.init_state(enc_outputs, *args, **kwargs)\n",
    "        return self.decoder(dec_x, dec_state, *args, **kwargs)\n"
   ],
   "id": "866057f72b1e6184",
   "outputs": [],
   "execution_count": 38
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-16T02:16:07.207590Z",
     "start_time": "2025-05-16T02:16:07.202553Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class Seq2SeqEncoder(Encoder):\n",
    "    \"\"\"输入一个x batch_size*num_steps或num_steps*batch_size \n",
    "    输出output batch_size num_steps \n",
    "    隐藏状态 numlayers * batch_size * hidden_size\"\"\"\n",
    "\n",
    "    def __init__(self, vocab_size, embed_size, hidden_size, dropout, *args, **kwargs):\n",
    "        super(Seq2SeqEncoder, self).__init__(*args, **kwargs)\n",
    "        self.vocab_size = vocab_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.embed = nn.Embedding(vocab_size, embed_size)\n",
    "        self.rnn = nn.GRU(embed_size, hidden_size, dropout=dropout, batch_first=True)\n",
    "\n",
    "    def forward(self, X, batchfirst=True, *args, **kwargs):\n",
    "        embed_x = self.embed(X)\n",
    "        if not batchfirst:\n",
    "            embed_x = embed_x.permute(1, 0, 2)\n",
    "\n",
    "        outputs, state = self.rnn(embed_x)\n",
    "        return outputs, state\n"
   ],
   "id": "3c6db4af13477edf",
   "outputs": [],
   "execution_count": 40
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "class Seq2SeqDecoder(Decoder):\n",
    "    def __init__(self, vocab_size, embed_size, hidden_size, dropout, *args, **kwargs):"
   ],
   "id": "3fb9e1303d3f3149"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
