{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-05-08T06:22:29.471150Z",
     "start_time": "2025-05-08T06:22:26.399919Z"
    }
   },
   "source": [
    "import os\n",
    "import torch\n",
    "import requests\n",
    "import matplotlib.pyplot as plt\n",
    "from torch import nn\n",
    "from utils.useful_func import *"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-08T06:22:29.475742Z",
     "start_time": "2025-05-08T06:22:29.472149Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def read_data_nmt():\n",
    "    with open(r'../data/fra-eng/fra.txt','r',encoding='utf-8') as f:\n",
    "        result=f.read()\n",
    "    return result"
   ],
   "id": "e8584bf9f8c87c92",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-08T06:22:29.481069Z",
     "start_time": "2025-05-08T06:22:29.475742Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#@save\n",
    "def preprocess_nmt(text):\n",
    "    \"\"\"预处理“英语－法语”数据集\"\"\"\n",
    "    def no_space(char, prev_char):\n",
    "        return char in set(',.!?') and prev_char != ' '\n",
    "\n",
    "    # 使用空格替换不间断空格\n",
    "    # 使用小写字母替换大写字母\n",
    "    text = text.replace('\\u202f', ' ').replace('\\xa0', ' ').lower()\n",
    "    # 在单词和标点符号之间插入空格\n",
    "    out = [' ' + char if i > 0 and no_space(char, text[i - 1]) else char\n",
    "           for i, char in enumerate(text)]\n",
    "    return ''.join(out)\n"
   ],
   "id": "be316cc948eefba1",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-08T06:22:29.486146Z",
     "start_time": "2025-05-08T06:22:29.481069Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def tokenize_nmt(text,num_examples=None):\n",
    "    source,target=[],[]\n",
    "    for i,line in enumerate(text.split('\\n')):\n",
    "        if num_examples and i>=num_examples:\n",
    "            break\n",
    "        parts=line.split('\\t')\n",
    "        ## 必须得有原始和目标值所以长度得为2\n",
    "        if len(parts)==2:\n",
    "            source.append(parts[0].split(' '))\n",
    "            target.append(parts[1].split(' '))\n",
    "    return source,target"
   ],
   "id": "8d956ae399db370f",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-08T06:22:29.491635Z",
     "start_time": "2025-05-08T06:22:29.487154Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#@save\n",
    "def truncate_pad(line, num_steps, padding_token):\n",
    "    \"\"\"截断或填充文本序列\"\"\"\n",
    "    if len(line) >= num_steps:\n",
    "        return line[:num_steps]\n",
    "    return line+[padding_token]*(num_steps-len(line))"
   ],
   "id": "c6b145523ac3ed13",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-08T06:22:29.496399Z",
     "start_time": "2025-05-08T06:22:29.492680Z"
    }
   },
   "cell_type": "code",
   "source": [
    "## 将文本数据作为批量数据，并且加入<eos>至末尾 同时统计有效字符 包含eos\n",
    "def build_array_nmt(lines, vocab, num_steps):\n",
    "    lines=[vocab[i] for i in lines]\n",
    "    lines=[i+[vocab['<eos>']] for i in lines]\n",
    "    array=torch.tensor([truncate_pad(i,num_steps,vocab['<pad>']) for i in lines])\n",
    "    valid_len =(array != vocab['<pad>']).type(torch.int32).sum(dim=1)\n",
    "    return array, valid_len"
   ],
   "id": "711acc7a42a43e0c",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-08T06:22:29.501564Z",
     "start_time": "2025-05-08T06:22:29.496399Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def load_data_nmt(batch_size, num_steps, num_examples=600):\n",
    "    ## 结果是原始列表 列表表长度 目标列表 目标列表长度\n",
    "    source, target = tokenize_nmt(preprocess_nmt(read_data_nmt()), num_examples)\n",
    "    src_vocab = Vocal(source, min_feq=2,\n",
    "                              reserved_tokens=['<pad>', '<bos>', '<eos>'])\n",
    "    tgt_vocab = Vocal(target, min_feq=2,\n",
    "                              reserved_tokens=['<pad>', '<bos>', '<eos>'])\n",
    "    \n",
    "    src_array, src_valid_len = build_array_nmt(source, src_vocab, num_steps)\n",
    "    tgt_array, tgt_valid_len = build_array_nmt(target, tgt_vocab, num_steps)\n",
    "    data_arrays = (src_array, src_valid_len, tgt_array, tgt_valid_len)\n",
    "    dataset = torch.utils.data.TensorDataset(*data_arrays)\n",
    "    return torch.utils.data.DataLoader(dataset, batch_size=batch_size,shuffle=True),src_vocab, tgt_vocab"
   ],
   "id": "7d8fcabe788475d2",
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-08T06:22:29.506776Z",
     "start_time": "2025-05-08T06:22:29.502604Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class Decoder(nn.Module):\n",
    "    \"\"\"编码器-解码器架构的基本解码器接口\"\"\"\n",
    "    def __init__(self,**kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "    \n",
    "    def init_state(self,enc_outputs,*args):\n",
    "        raise NotImplementedError\n",
    "    \n",
    "    def forward(self,X,state):\n",
    "        raise NotImplementedError"
   ],
   "id": "a31d3e796ebf702a",
   "outputs": [],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-08T06:22:29.512384Z",
     "start_time": "2025-05-08T06:22:29.508027Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class Encoder(nn.Module):\n",
    "    \"\"\"编码器—解码器架构的基本编码器接口\"\"\"\n",
    "    def __init__(self, **kwargs):\n",
    "        super(Encoder, self).__init__(**kwargs)\n",
    "    def forward(self, X,*args):\n",
    "        raise NotImplementedError\n",
    "\n",
    "class EncoderDecoder(nn.Module):\n",
    "    def __init__(self,encoder,decoder,**kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "    def forward(self, enc_X, dec_X, *args):\n",
    "        enc_outputs = self.encoder(enc_X)\n",
    "        dec_state=self.decoder.init_state(enc_outputs,*args)\n",
    "        return self.decoder(dec_X,dec_state)\n",
    "        "
   ],
   "id": "c12b2c8281935fbb",
   "outputs": [],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-08T06:22:32.316161Z",
     "start_time": "2025-05-08T06:22:29.513413Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import collections\n",
    "import math\n",
    "import torch\n",
    "from torch import nn\n",
    "from d2l import torch as d2l"
   ],
   "id": "b3a63b14d92ad739",
   "outputs": [],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-08T06:22:32.323483Z",
     "start_time": "2025-05-08T06:22:32.317165Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class Seq2SeqEncoder(Encoder):\n",
    "    def __init__(self,vocab_size,embed_size,num_hiddens,num_layers,dropout=0,**kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        # 嵌入层\n",
    "        self.embedding = nn.Embedding(vocab_size,embed_size)\n",
    "        self.rnn = nn.GRU(embed_size,num_hiddens,num_layers,dropout=dropout)\n",
    "        \n",
    "    def forward(self, X, *args):\n",
    "        # 输出'X'的形状：(batch_size,num_steps,embed_size)\n",
    "        X = self.embedding(X)\n",
    "        # 在循环神经网络模型中，第一个轴对应于时间步\n",
    "        X = X.permute(1, 0, 2)\n",
    "        ## 无初始状态则初始状态为0\n",
    "        output, state = self.rnn(X)\n",
    "        return output, state\n",
    "        \n",
    "\n",
    "class Seq2SeqDecoder(Decoder):\n",
    "    def __init__(self,vocab_size,embed_size,num_hiddens,num_layers,dropout=0,**kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.embedding = nn.Embedding(vocab_size,embed_size)\n",
    "        self.rnn=nn.GRU(embed_size + num_hiddens,num_hiddens,num_layers,dropout=dropout)\n",
    "        self.dense=nn.Linear(num_hiddens,vocab_size)\n",
    "        \n",
    "    def init_state(self,enc_outputs,*args):\n",
    "        return enc_outputs[1]\n",
    "    \n",
    "    def forward(self,X,dec_state):\n",
    "        # 传入的x是 batch_size 时间步 向量大小\n",
    "        X=(self.embedding(X))\n",
    "        X=X.permute(1, 0, 2)\n",
    "        # 广播context，使state最后时刻最后一层 具有与X相同的num_steps\n",
    "        context=dec_state[-1].repeat(X.shape[0],1,1)\n",
    "        X_and_context=torch.cat((X,context),dim=-1)\n",
    "        output,state=self.rnn(X_and_context,dec_state)\n",
    "        # output的形状:(batch_size,num_steps,vocab_size)\n",
    "        output=self.dense(output).permute(1,0,2)\n",
    "        # state的形状:(num_layers,batch_size,num_hiddens)\n",
    "        return output,state\n",
    "        "
   ],
   "id": "b792b46249d5a1fa",
   "outputs": [],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-08T06:22:32.334169Z",
     "start_time": "2025-05-08T06:22:32.324482Z"
    }
   },
   "cell_type": "code",
   "source": [
    "encoder=Seq2SeqEncoder(10,8,16,2)\n",
    "encoder.eval()\n",
    "X=torch.zeros((4,7),dtype=torch.long)\n",
    "output,state=encoder(X)\n",
    "## 7是时间步 4是batch_size, 16是隐藏层维度\n",
    "output.shape\n",
    "## 层数 batch_size 隐藏层维度\n",
    "# state.shape"
   ],
   "id": "10933595fc271f6f",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([7, 4, 16])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-08T06:22:32.343854Z",
     "start_time": "2025-05-08T06:22:32.335170Z"
    }
   },
   "cell_type": "code",
   "source": [
    "decoder = Seq2SeqDecoder(vocab_size=10, embed_size=8, num_hiddens=16,\n",
    "                         num_layers=2)\n",
    "\n",
    "dec_state=decoder.init_state(encoder(X))\n",
    "output,state=decoder.forward(X,dec_state)\n",
    "## 4，7，10 4是batch_size 最后一个维度是词表大小 进行softmax之后 就是4 7 7是约定的时间步大小但是实际需要的会比这个要小\n",
    "output.shape"
   ],
   "id": "e7a9fd508e298fbc",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 7, 10])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 13
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-08T06:22:32.351418Z",
     "start_time": "2025-05-08T06:22:32.346846Z"
    }
   },
   "cell_type": "code",
   "source": "state.shape",
   "id": "a61505e5d351ba56",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 4, 16])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 14
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "损失函数",
   "id": "aa5bf544589daf06"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-08T06:22:32.357862Z",
     "start_time": "2025-05-08T06:22:32.352421Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def sequence_mask(X,valid_len,value=0):\n",
    "    \"\"\"在序列中屏蔽不相关的项\"\"\"\n",
    "    # 首先x是二维的 最内层维度是句子长度 注意：是训练集所以才知道句子真实长度\n",
    "    # 拿出总的长度 得到长度\n",
    "    maxlen = X.shape[1]\n",
    "    # 然后用总长度生成一个1维的向量 使用函数扩展成2维以便与valid_len进行广播\n",
    "    mask=torch.unsqueeze(torch.arange(0, maxlen, dtype=torch.long),dim=0)\n",
    "    # mask在0维度扩充 valid在1维度扩充 因为每一个valid对应的是每一个x valid的数字其实是x的第二维向量\n",
    "    mask=(mask<torch.unsqueeze(valid_len,dim=1)) # 这里小于号就够了 因为<eos>所在位置的索引其实是valid_len-1\n",
    "    X[~mask]=value\n",
    "    return X"
   ],
   "id": "6de45bcca82396c2",
   "outputs": [],
   "execution_count": 15
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-08T06:22:32.364080Z",
     "start_time": "2025-05-08T06:22:32.359860Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 拓展的softmax因为对填充值进行softmax其实没有什么意义\n",
    "class MaskedSoftmaxCELoss(nn.CrossEntropyLoss):\n",
    "    def forward(self, pred, label,valid_len):\n",
    "        weights=torch.ones_like(label)\n",
    "        weights=sequence_mask(weights,valid_len)\n",
    "        self.reduction='none'\n",
    "        pred=pred.permute(0,2,1)\n",
    "        unweight_loss=super().forward(pred,label)\n",
    "        weights_loss=unweight_loss*weights\n",
    "        return weights_loss.mean(dim=1)\n",
    "        "
   ],
   "id": "468fbd458cb0a875",
   "outputs": [],
   "execution_count": 16
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# 训练",
   "id": "78132e8fcaba474d"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-08T06:22:32.374396Z",
     "start_time": "2025-05-08T06:22:32.365081Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def train_seq2seq(net, train_iter, lr, num_epochs, tgt_vocab, device):\n",
    "    def xavier_init_weights(m):\n",
    "        if type(m) == nn.Linear:\n",
    "            nn.init.xavier_uniform_(m.weight)\n",
    "        if type(m) == nn.GRU:\n",
    "            for param in m._flat_weights_names:\n",
    "                if \"weight\" in param:\n",
    "                    nn.init.xavier_uniform_(m._parameters[param])\n",
    "    net.apply(xavier_init_weights)\n",
    "    net.to(device)\n",
    "    optimizer=torch.optim.Adam(net.parameters(), lr=lr)\n",
    "    loss = MaskedSoftmaxCELoss()\n",
    "    # 进入训练模式\n",
    "    net.train()\n",
    "    animator = Animator(xlabel='epoch', ylabel='loss',\n",
    "                         xlim=[10, num_epochs])\n",
    "    for epoch in range(num_epochs):\n",
    "        timer=Timer()\n",
    "        metric=Accumulator(2)\n",
    "        for batch in train_iter:\n",
    "            optimizer.zero_grad()\n",
    "            X, X_valid_len, Y, Y_valid_len = [x.to(device) for x in batch]\n",
    "            bos=torch.tensor([tgt_vocab['<bos>']]*Y.shape[0],device=device).reshape(-1,1)\n",
    "            dec_input=torch.cat([bos,Y[:,:-1]],dim=1)\n",
    "            y_hat,_=net(X,dec_input,X_valid_len)\n",
    "            l = loss(y_hat,Y,Y_valid_len)\n",
    "            l.sum().backward()\n",
    "            grad_clipping(net,1)\n",
    "            optimizer.step()\n",
    "            num_tokens=Y_valid_len.sum()\n",
    "            with torch.no_grad():\n",
    "                metric.add(l.sum(), num_tokens)\n",
    "        if (epoch + 1) % 10 == 0:\n",
    "            animator.add(epoch + 1, (metric[0] / metric[1],))\n",
    "    print(f'loss {metric[0] / metric[1]:.3f}, {metric[1] / timer.stop():.1f} '\n",
    "        f'tokens/sec on {str(device)}')"
   ],
   "id": "dfcaebfda3257cf9",
   "outputs": [],
   "execution_count": 17
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "embed_size, num_hiddens, num_layers, dropout = 32, 32, 2, 0.1\n",
    "batch_size, num_steps = 64, 10\n",
    "lr, num_epochs, device = 0.005, 300, 'cpu'\n",
    "\n",
    "train_iter, src_vocab, tgt_vocab = load_data_nmt(batch_size, num_steps)\n",
    "encoder = Seq2SeqEncoder(len(src_vocab), embed_size, num_hiddens, num_layers,\n",
    "                        dropout)\n",
    "decoder = Seq2SeqDecoder(len(tgt_vocab), embed_size, num_hiddens, num_layers,\n",
    "                        dropout)\n",
    "net = EncoderDecoder(encoder, decoder)\n",
    "train_seq2seq(net, train_iter, lr, num_epochs, tgt_vocab, device)\n",
    "net.eval()"
   ],
   "id": "965f1c05eba68de4",
   "execution_count": 18,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss 0.019, 10445.5 tokens/sec on cpu\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "EncoderDecoder(\n",
       "  (encoder): Seq2SeqEncoder(\n",
       "    (embedding): Embedding(184, 32)\n",
       "    (rnn): GRU(32, 32, num_layers=2, dropout=0.1)\n",
       "  )\n",
       "  (decoder): Seq2SeqDecoder(\n",
       "    (embedding): Embedding(201, 32)\n",
       "    (rnn): GRU(64, 32, num_layers=2, dropout=0.1)\n",
       "    (dense): Linear(in_features=32, out_features=201, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 320x250 with 1 Axes>"
      ],
      "image/png": "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\n"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ]
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-08T06:27:36.617896Z",
     "start_time": "2025-05-08T06:27:36.615008Z"
    }
   },
   "cell_type": "code",
   "source": "# predict_seq2seq(net, eng, src_vocab, tgt_vocab, num_steps, device)",
   "id": "3988563f6d2a2831",
   "outputs": [],
   "execution_count": 20
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-08T06:27:36.951259Z",
     "start_time": "2025-05-08T06:27:36.924653Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#@save\n",
    "def predict_seq2seq(net, src_sentence, src_vocab, tgt_vocab, num_steps,\n",
    "                    device, save_attention_weights=False):\n",
    "    \"\"\"序列到序列模型的预测\"\"\"\n",
    "    # 在预测时将net设置为评估模式\n",
    "    net.eval()\n",
    "    src_tokens = src_vocab[src_sentence.lower().split(' ')] + [\n",
    "        src_vocab['<eos>']]\n",
    "    enc_valid_len = torch.tensor([len(src_tokens)], device=device)\n",
    "    src_tokens = d2l.truncate_pad(src_tokens, num_steps, src_vocab['<pad>'])\n",
    "    # 添加批量轴\n",
    "    enc_X = torch.unsqueeze(\n",
    "        torch.tensor(src_tokens, dtype=torch.long, device=device), dim=0)\n",
    "    enc_outputs = net.encoder(enc_X, enc_valid_len)\n",
    "    dec_state = net.decoder.init_state(enc_outputs, enc_valid_len)\n",
    "    # 添加批量轴\n",
    "    dec_X = torch.unsqueeze(torch.tensor(\n",
    "        [tgt_vocab['<bos>']], dtype=torch.long, device=device), dim=0)\n",
    "    output_seq, attention_weight_seq = [], []\n",
    "    for _ in range(num_steps):\n",
    "        Y, dec_state = net.decoder(dec_X, dec_state)\n",
    "        # 我们使用具有预测最高可能性的词元，作为解码器在下一时间步的输入\n",
    "        dec_X = Y.argmax(dim=2)\n",
    "        pred = dec_X.squeeze(dim=0).type(torch.int32).item()\n",
    "        # 保存注意力权重（稍后讨论）\n",
    "        if save_attention_weights:\n",
    "            attention_weight_seq.append(net.decoder.attention_weights)\n",
    "        # 一旦序列结束词元被预测，输出序列的生成就完成了\n",
    "        if pred == tgt_vocab['<eos>']:\n",
    "            break\n",
    "        output_seq.append(pred)\n",
    "    return ' '.join(tgt_vocab.to_tokens(output_seq)), attention_weight_seq\n",
    "\n",
    "engs = ['go .', \"i lost .\", 'he\\'s calm .', 'i\\'m home .']\n",
    "fras = ['va !', 'j\\'ai perdu .', 'il est calme .', 'je suis chez moi .']\n",
    "for eng, fra in zip(engs, fras):\n",
    "    translation, attention_weight_seq = predict_seq2seq(\n",
    "        net, eng, src_vocab, tgt_vocab, num_steps, device)\n",
    "    print(f'{eng} => {translation}')"
   ],
   "id": "f98bca60835bd1b3",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "go . => va au feu !\n",
      "i lost . => j'ai perdu .\n",
      "he's calm . => il court .\n",
      "i'm home . => je suis chez moi qui qui mort ?\n"
     ]
    }
   ],
   "execution_count": 21
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-08T07:02:34.434500Z",
     "start_time": "2025-05-08T07:02:34.430427Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def bleu(pred_seq, label_seq, k):  #@save\n",
    "    \"\"\"计算BLEU\"\"\"\n",
    "    pred_tokens, label_tokens = pred_seq.split(' '), label_seq.split(' ')\n",
    "    len_pred, len_label = len(pred_tokens), len(label_tokens)\n",
    "    score = math.exp(min(0, 1 - len_label / len_pred))\n",
    "    for n in range(1, k + 1):\n",
    "        num_matches, label_subs = 0, collections.defaultdict(int)\n",
    "        for i in range(len_label - n + 1):\n",
    "            label_subs[' '.join(label_tokens[i: i + n])] += 1\n",
    "        for i in range(len_pred - n + 1):\n",
    "            if label_subs[' '.join(pred_tokens[i: i + n])] > 0:\n",
    "                num_matches += 1\n",
    "                label_subs[' '.join(pred_tokens[i: i + n])] -= 1\n",
    "        score *= math.pow(num_matches / (len_pred - n + 1), math.pow(0.5, n))\n",
    "    return score"
   ],
   "id": "f9e363063c8f6271",
   "outputs": [],
   "execution_count": 37
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-08T07:02:40.676464Z",
     "start_time": "2025-05-08T07:02:40.650513Z"
    }
   },
   "cell_type": "code",
   "source": [
    "engs = ['go .', \"i lost .\", 'he\\'s calm .', 'i\\'m home .']\n",
    "fras = ['va !', 'j\\'ai perdu .', 'il est calme .', 'je suis chez moi .']\n",
    "for eng, fra in zip(engs, fras):\n",
    "    translation, attention_weight_seq = predict_seq2seq(\n",
    "        net, eng, src_vocab, tgt_vocab, num_steps, device)\n",
    "    print(f'{eng} => {translation}, bleu {bleu(translation, fra, k=2):.3f}')"
   ],
   "id": "b088dc4cd3461ad6",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "go . => va au feu !, bleu 0.000\n",
      "i lost . => j'ai perdu ., bleu 1.000\n",
      "he's calm . => il court ., bleu 0.000\n",
      "i'm home . => je suis chez moi qui qui mort ?, bleu 0.572\n"
     ]
    }
   ],
   "execution_count": 38
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "8d8ded94fa781781"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
