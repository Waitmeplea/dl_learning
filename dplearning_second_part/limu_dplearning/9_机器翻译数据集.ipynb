{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-05-07T03:00:03.588420Z",
     "start_time": "2025-05-07T03:00:03.582349Z"
    }
   },
   "source": [
    "import os\n",
    "import torch\n",
    "import requests\n",
    "import matplotlib.pyplot as plt\n",
    "from torch import nn\n",
    "from utils.useful_func import *"
   ],
   "outputs": [],
   "execution_count": 106
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-07T02:13:56.516068Z",
     "start_time": "2025-05-07T02:13:56.510813Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def read_data_nmt():\n",
    "    with open(r'../data/fra-eng/fra.txt','r',encoding='utf-8') as f:\n",
    "        result=f.read()\n",
    "    return result"
   ],
   "id": "e8584bf9f8c87c92",
   "outputs": [],
   "execution_count": 71
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-07T01:24:24.052420Z",
     "start_time": "2025-05-07T01:24:21.122732Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#@save\n",
    "def preprocess_nmt(text):\n",
    "    \"\"\"预处理“英语－法语”数据集\"\"\"\n",
    "    def no_space(char, prev_char):\n",
    "        return char in set(',.!?') and prev_char != ' '\n",
    "\n",
    "    # 使用空格替换不间断空格\n",
    "    # 使用小写字母替换大写字母\n",
    "    text = text.replace('\\u202f', ' ').replace('\\xa0', ' ').lower()\n",
    "    # 在单词和标点符号之间插入空格\n",
    "    out = [' ' + char if i > 0 and no_space(char, text[i - 1]) else char\n",
    "           for i, char in enumerate(text)]\n",
    "    return ''.join(out)\n",
    "\n",
    "text = preprocess_nmt(result)"
   ],
   "id": "be316cc948eefba1",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-07T02:16:52.109583Z",
     "start_time": "2025-05-07T02:16:52.105250Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def tokenize_nmt(text,num_examples=None):\n",
    "    source,target=[],[]\n",
    "    for i,line in enumerate(text.split('\\n')):\n",
    "        if num_examples and i>=num_examples:\n",
    "            break\n",
    "        parts=line.split('\\t')\n",
    "        ## 必须得有原始和目标值所以长度得为2\n",
    "        if len(parts)==2:\n",
    "            source.append(parts[0].split(' '))\n",
    "            target.append(parts[1].split(' '))\n",
    "    return source,target"
   ],
   "id": "8d956ae399db370f",
   "outputs": [],
   "execution_count": 77
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-07T02:16:56.903509Z",
     "start_time": "2025-05-07T02:16:56.899138Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#@save\n",
    "def truncate_pad(line, num_steps, padding_token):\n",
    "    \"\"\"截断或填充文本序列\"\"\"\n",
    "    if len(line) >= num_steps:\n",
    "        return line[:num_steps]\n",
    "    return line+[padding_token]*(num_steps-len(line))"
   ],
   "id": "c6b145523ac3ed13",
   "outputs": [],
   "execution_count": 78
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-07T02:17:00.340106Z",
     "start_time": "2025-05-07T02:17:00.332573Z"
    }
   },
   "cell_type": "code",
   "source": [
    "## 将文本数据作为批量数据，并且加入<eos>至末尾 同时统计有效字符 包含eos\n",
    "def build_array_nmt(lines, vocab, num_steps):\n",
    "    lines=[src_vocab[i] for i in lines]\n",
    "    lines=[i+[vocab['<eos>']] for i in lines]\n",
    "    array=torch.tensor([truncate_pad(i,num_steps,vocab['<pad>']) for i in lines])\n",
    "    valid_len =(array != vocab['<pad>']).type(torch.int32).sum(dim=1)\n",
    "    return array, valid_len"
   ],
   "id": "711acc7a42a43e0c",
   "outputs": [],
   "execution_count": 79
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-07T02:29:21.543438Z",
     "start_time": "2025-05-07T02:29:21.538233Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def load_data_nmt(batch_size, num_steps, num_examples=600):\n",
    "    ## 结果是原始列表 列表表长度 目标列表 目标列表长度\n",
    "    source, target = tokenize_nmt(text, num_examples)\n",
    "    src_vocab = Vocal(source, min_feq=2,\n",
    "                              reserved_tokens=['<pad>', '<bos>', '<eos>'])\n",
    "    tgt_vocab = Vocal(target, min_feq=2,\n",
    "                              reserved_tokens=['<pad>', '<bos>', '<eos>'])\n",
    "    \n",
    "    src_array, src_valid_len = build_array_nmt(source, src_vocab, num_steps)\n",
    "    tgt_array, tgt_valid_len = build_array_nmt(target, tgt_vocab, num_steps)\n",
    "    data_arrays = (src_array, src_valid_len, tgt_array, tgt_valid_len)\n",
    "    dataset = torch.utils.data.TensorDataset(*data_arrays)\n",
    "    return torch.utils.data.DataLoader(dataset, batch_size=batch_size,shuffle=True),src_vocab, tgt_vocab"
   ],
   "id": "7d8fcabe788475d2",
   "outputs": [],
   "execution_count": 103
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-07T02:29:26.006635Z",
     "start_time": "2025-05-07T02:29:25.964540Z"
    }
   },
   "cell_type": "code",
   "source": "train_iter, src_vocab, tgt_vocab = load_data_nmt(batch_size=2, num_steps=8)",
   "id": "1b48f846a6d9d802",
   "outputs": [],
   "execution_count": 104
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-07T02:29:40.836424Z",
     "start_time": "2025-05-07T02:29:40.828549Z"
    }
   },
   "cell_type": "code",
   "source": [
    "for X, X_valid_len, Y, Y_valid_len in train_iter:\n",
    "    print('X:', X.type(torch.int32))\n",
    "    print('X的有效长度:', X_valid_len)\n",
    "    print('Y:', Y.type(torch.int32))\n",
    "    print('Y的有效长度:', Y_valid_len)\n",
    "    break"
   ],
   "id": "cc0e70254fc137c1",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X: tensor([[2944,    4,    3,    1,    1,    1,    1,    1],\n",
      "        [  12,  189,    4,    3,    1,    1,    1,    1]], dtype=torch.int32)\n",
      "X的有效长度: tensor([3, 4])\n",
      "Y: tensor([[  0, 126,   3,   1,   1,   1,   1,   1],\n",
      "        [ 12,   0,   0,   4,   3,   1,   1,   1]], dtype=torch.int32)\n",
      "Y的有效长度: tensor([3, 5])\n"
     ]
    }
   ],
   "execution_count": 105
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-07T07:17:27.992294Z",
     "start_time": "2025-05-07T07:17:27.982523Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class Decoder(nn.Module):\n",
    "    \"\"\"编码器-解码器架构的基本解码器接口\"\"\"\n",
    "    def __init__(self,**kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "    \n",
    "    def init_state(self,enc_outputs,*args):\n",
    "        raise NotImplementedError\n",
    "    \n",
    "    def forward(self,X,state):\n",
    "        raise NotImplementedError"
   ],
   "id": "a31d3e796ebf702a",
   "outputs": [],
   "execution_count": 138
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-07T07:17:34.340197Z",
     "start_time": "2025-05-07T07:17:34.334504Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class Encoder(nn.Module):\n",
    "    \"\"\"编码器—解码器架构的基本编码器接口\"\"\"\n",
    "    def __init__(self, **kwargs):\n",
    "        super(Encoder, self).__init__(**kwargs)\n",
    "    def forward(self, X,*args):\n",
    "        raise NotImplementedError\n",
    "\n",
    "class EncoderDecoder(nn.Module):\n",
    "    def __init__(self,encoder,decoder,**kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "    def forward(self, enc_X, dec_X, *args):\n",
    "        enc_outputs = self.encoder(enc_X)\n",
    "        dec_state=self.decoder.init(enc_outputs,*args)\n",
    "        return self.decoder(dec_X,dec_state)\n",
    "        "
   ],
   "id": "c12b2c8281935fbb",
   "outputs": [],
   "execution_count": 139
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-07T07:17:35.758258Z",
     "start_time": "2025-05-07T07:17:35.751462Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import collections\n",
    "import math\n",
    "import torch\n",
    "from torch import nn\n",
    "from d2l import torch as d2l"
   ],
   "id": "b3a63b14d92ad739",
   "outputs": [],
   "execution_count": 140
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-07T08:45:41.188062Z",
     "start_time": "2025-05-07T08:45:41.173849Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class Seq2SeqEncoder(Encoder):\n",
    "    def __init__(self,vocab_size,embed_size,num_hiddens,num_layers,dropout=0,**kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        # 嵌入层\n",
    "        self.embedding = nn.Embedding(vocab_size,embed_size)\n",
    "        self.rnn = nn.GRU(embed_size,num_hiddens,num_layers,dropout=dropout)\n",
    "        \n",
    "    def forward(self, X, *args):\n",
    "        # 输出'X'的形状：(batch_size,num_steps,embed_size)\n",
    "        X = self.embedding(X)\n",
    "        # 在循环神经网络模型中，第一个轴对应于时间步\n",
    "        X = X.permute(1, 0, 2)\n",
    "        ## 无初始状态则初始状态为0\n",
    "        output, state = self.rnn(X)\n",
    "        return output, state\n",
    "        \n",
    "\n",
    "class Seq2SeqDecoder(Decoder):\n",
    "    def __init__(self,vocab_size,embed_size,num_hiddens,num_layers,dropout=0,**kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.embedding = nn.Embedding(vocab_size,embed_size)\n",
    "        self.rnn=nn.GRU(embed_size + num_hiddens,num_hiddens,num_layers,dropout=dropout)\n",
    "        self.dense=nn.Linear(num_hiddens,vocab_size)\n",
    "        \n",
    "    def init_state(self,enc_outputs,*args):\n",
    "        return enc_outputs[1]\n",
    "    \n",
    "    def forward(self,X,dec_state):\n",
    "        X=self.embedding(X).permute(1, 0, 2)\n",
    "        # 广播context，使state最后时刻最后一层 具有与X相同的num_steps\n",
    "        context=dec_state[-1].repeat(X.shape[0],1,1)\n",
    "        X_and_context=torch.cat((X,context),dim=-1)\n",
    "        output,state=self.rnn(X_and_context,dec_state)\n",
    "        # output的形状:(batch_size,num_steps,vocab_size)\n",
    "        output=self.dense(output).permute(1,0,2)\n",
    "        # state的形状:(num_layers,batch_size,num_hiddens)\n",
    "        return output,state\n",
    "        "
   ],
   "id": "b792b46249d5a1fa",
   "outputs": [],
   "execution_count": 194
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-07T08:45:41.832810Z",
     "start_time": "2025-05-07T08:45:41.824038Z"
    }
   },
   "cell_type": "code",
   "source": [
    "encoder=Seq2SeqEncoder(10,8,16,2)\n",
    "encoder.eval()\n",
    "X=torch.zeros((4,7),dtype=torch.long)\n",
    "output,state=encoder(X)\n",
    "## 7是时间步 4是batch_size, 16是隐藏层维度\n",
    "output.shape\n",
    "## 层数 batch_size 隐藏层维度\n",
    "state.shape"
   ],
   "id": "10933595fc271f6f",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 4, 16])"
      ]
     },
     "execution_count": 195,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 195
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-07T08:45:42.153241Z",
     "start_time": "2025-05-07T08:45:42.136944Z"
    }
   },
   "cell_type": "code",
   "source": [
    "decoder = Seq2SeqDecoder(vocab_size=10, embed_size=8, num_hiddens=16,\n",
    "                         num_layers=2)"
   ],
   "id": "e7a9fd508e298fbc",
   "outputs": [],
   "execution_count": 196
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-07T08:46:48.017859Z",
     "start_time": "2025-05-07T08:46:48.012035Z"
    }
   },
   "cell_type": "code",
   "source": "dec_state=decoder.init_state(encoder(X))",
   "id": "a61505e5d351ba56",
   "outputs": [],
   "execution_count": 197
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-07T09:18:25.767078Z",
     "start_time": "2025-05-07T09:18:25.761930Z"
    }
   },
   "cell_type": "code",
   "source": "output,state=decoder.forward(X,dec_state)",
   "id": "83ab13e59168aa0e",
   "outputs": [],
   "execution_count": 199
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-07T09:18:32.766941Z",
     "start_time": "2025-05-07T09:18:32.750995Z"
    }
   },
   "cell_type": "code",
   "source": "output.shape",
   "id": "98fc2b7c3d8c4459",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 7, 10])"
      ]
     },
     "execution_count": 201,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 201
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-07T09:18:37.045724Z",
     "start_time": "2025-05-07T09:18:37.040887Z"
    }
   },
   "cell_type": "code",
   "source": "state.shape",
   "id": "d9718294c9b38791",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 4, 16])"
      ]
     },
     "execution_count": 202,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 202
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "损失函数",
   "id": "aa5bf544589daf06"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def sequence_mask(X,valid_len,value=0):\n",
    "    \"\"\"在序列中屏蔽不相关的项\"\"\"\n",
    "    maxlen = X.shape[0]"
   ],
   "id": "6de45bcca82396c2"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
