{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-05-13T07:23:39.236131Z",
     "start_time": "2025-05-13T07:23:35.559940Z"
    }
   },
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "from utils.useful_func import *"
   ],
   "outputs": [],
   "execution_count": 23
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Bahdanau 注意力 只需要修改decoder部分",
   "id": "f5129c8ec1ef9a57"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-12T13:15:08.987948Z",
     "start_time": "2025-05-12T13:15:08.985266Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class AttentionDecoder(Decoder):\n",
    "    \"\"\"带有注意力机制解码器的基本接口\"\"\"\n",
    "    def __init__(self,**kwargs):\n",
    "        super(AttentionDecoder, self).__init__(**kwargs)\n",
    "    @property\n",
    "    def attention_weight(self):\n",
    "        raise NotImplementedError"
   ],
   "id": "900b715e6539cc60",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-12T13:15:09.732345Z",
     "start_time": "2025-05-12T13:15:09.729121Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class Seq2SeqAttentionDecoder(AttentionDecoder):\n",
    "    \"\"\"通过encoder传来的原始序列的编码信息 进行解码翻译\"\"\"\n",
    "    def __init__(self,vocab_size,embed_size,num_hiddens,num_layers,dropout=0,**kwargs):\n",
    "        super(Seq2SeqAttentionDecoder, self).__init__(**kwargs)\n",
    "        self.attention=AdditiveAttention(num_hiddens,num_hiddens,num_hiddens,dropout=dropout)\n",
    "        self.embedding=nn.Embedding(vocab_size,embed_size)\n",
    "        self.rnn=nn.GRU(embed_size+num_hiddens,num_hiddens,num_layers,dropout=dropout)\n",
    "        self.dense=nn.Linear(num_hiddens,vocab_size)\n",
    "\n",
    "    def init_state(self,encoder_out,enc_valid_lens,*args):\n",
    "\n",
    "        outputs,hidden_state=encoder_out\n",
    "        return outputs.permute(1,0,2),hidden_state,enc_valid_lens\n",
    "\n",
    "    def forward(self,X,state):\n",
    "        #ouputs batch_size,num_steps,num_hiddens\n",
    "        outputs, hidden_state, enc_valid_lens = state\n",
    "        X=self.embedding(X).permute(1,0,2)\n",
    "        dec_outputs, self._attention_weights = [], []\n",
    "        for x in X:\n",
    "            #，unsqueeze(1) 这一步的目的就是为了给 Decoder 的顶层隐藏状态显式地添加一个维度，用来表示 Query 的数量 (在这个时间步是 1)，\n",
    "            # 从而使其形状符合 Attention 模块期望的 (batch_size, num_queries, feature_size) 输入格式，使得 Attention 模块可以正确地进行批处理和内部计算。\n",
    "            # query的形状为(batch_size,1,num_hiddens)\n",
    "            query=hidden_state[-1].unsqueeze(1)\n",
    "            # qkv 和q的有效长度\n",
    "            # query batch_size,1,num_hiddens\n",
    "            # outputs batch_size,num_steps,num_hiddens\n",
    "            context=self.attention(query,outputs,outputs,enc_valid_lens)\n",
    "            # x为batch_size,1,embed+hidden_size\n",
    "            x=torch.cat((context,x.unsqueeze(1)),dim=-1)\n",
    "            out,hidden_state=self.rnn(x.permute(1,0,2),hidden_state)\n",
    "            dec_outputs.append(out)\n",
    "            self._attention_weights.append(self.attention.attention_weights)\n",
    "            dec_outputs = self.dense(torch.cat(dec_outputs, dim=0))\n",
    "            return outputs.permute(1, 0, 2), [outputs, hidden_state,\n",
    "                                          enc_valid_lens]\n",
    "    @property\n",
    "    def attention_weights(self):\n",
    "        return self._attention_weights"
   ],
   "id": "40a1b347a1b82404",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-14T02:03:29.908523Z",
     "start_time": "2025-05-14T02:03:29.897937Z"
    }
   },
   "cell_type": "code",
   "source": "torch.bmm(torch.randn(1,2,3),torch.randn(1,3,2))",
   "id": "e994399f22422ad0",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-2.5753, -1.5549],\n",
       "         [-2.1453, -0.8174]]])"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 73
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-14T02:03:22.391101Z",
     "start_time": "2025-05-14T02:03:22.384618Z"
    }
   },
   "cell_type": "code",
   "source": "torch.randn(1,2,3).shape",
   "id": "6a4f14706677601e",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 2, 3])"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 72
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-14T01:01:15.455379Z",
     "start_time": "2025-05-14T01:01:15.448244Z"
    }
   },
   "cell_type": "code",
   "source": "gru=nn.GRU(5,10)",
   "id": "201bb996381ef809",
   "outputs": [],
   "execution_count": 61
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-14T01:01:15.940608Z",
     "start_time": "2025-05-14T01:01:15.935099Z"
    }
   },
   "cell_type": "code",
   "source": "x=torch.randn(20,10,5)",
   "id": "85eb47d6fd268581",
   "outputs": [],
   "execution_count": 62
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-14T01:30:50.248301Z",
     "start_time": "2025-05-14T01:30:50.241877Z"
    }
   },
   "cell_type": "code",
   "source": [
    "out,hidden=gru(x)\n",
    "out.shape\n"
   ],
   "id": "7affda899a7f6a33",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([20, 10, 10])"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 68
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
