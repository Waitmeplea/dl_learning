{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-05-02T01:25:57.508134Z",
     "start_time": "2025-05-02T01:25:55.143332Z"
    }
   },
   "source": [
    "\n",
    "import random\n",
    "import collections\n",
    "import re\n",
    "import requests\n",
    "import random \n",
    "from torch.nn import functional as F\n",
    "%matplotlib inline\n",
    "import math\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "import sys\n",
    "sys.path.append('../')\n",
    "from utils.useful_func import *\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import functional as F"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-02T01:26:32.704127Z",
     "start_time": "2025-05-02T01:26:32.689508Z"
    }
   },
   "cell_type": "code",
   "source": [
    "with open('../data/time_machine.txt','r') as f:\n",
    "    content=f.readlines()\n",
    "##读取文章\n",
    "def read_time_machine():\n",
    "    with open('../data/time_machine.txt','r') as f:\n",
    "        content=f.readlines()\n",
    "    return [ re.sub('[^A-Za-z]', ' ', i.replace('\\n','')).strip().lower() for i in content ]\n",
    "\n",
    "## 定义一个拆分词元的函数 结果是词元组成的list\n",
    "def tokenize(content,token='word'):\n",
    "    if token=='word':\n",
    "        token_list=[token.lower() for i in content for token in i.split(' ')]\n",
    "    else:\n",
    "        token_list=[token.lower() for i in content for token in i]\n",
    "    return token_list\n",
    "\n",
    "##定义一个统计频率的函数 可以处理1d2d\n",
    "def count_corpus(token_list):\n",
    "    if isinstance(token_list[0], list):\n",
    "      tokens=[token for i in token_list for token in i ]\n",
    "    tokens_count=collections.Counter(token_list)\n",
    "    return tokens_count\n",
    "\n",
    "class Vocal():\n",
    "    def __init__(self,token_list=None,min_feq=0,reserved_tokens=None):\n",
    "        self.token_list=token_list\n",
    "        if token_list is None:\n",
    "            self.token_list=[]\n",
    "        if reserved_tokens is None:\n",
    "            reserved_tokens=[]\n",
    "        counter_info=count_corpus(token_list)\n",
    "        self._token_feq=[]\n",
    "        ##只接受符合条件的词\n",
    "        for items in sorted(counter_info.items(),key=lambda x:x[1],reverse=True):\n",
    "            if items[1]<=min_feq:\n",
    "                break\n",
    "            else:\n",
    "                self._token_feq.append(items)\n",
    "\n",
    "        ##\n",
    "        if '<unk>' in reserved_tokens:\n",
    "            self.idx_to_token=reserved_tokens\n",
    "        else:\n",
    "            self.idx_to_token=['unk']+reserved_tokens\n",
    "\n",
    "        self.token_to_idx={token:i for i,token in enumerate(self.idx_to_token)}\n",
    "        for token,_ in self._token_feq:\n",
    "            self.idx_to_token.append(token)\n",
    "            self.token_to_idx[token]=len(self.token_to_idx)\n",
    "    def __len__(self):\n",
    "        return len(self.token_to_idx)\n",
    "    ##实现一个索引方法 但是传入的索引是token 返回是idx,保证未知token显示0值\n",
    "    def __getitem__(self,tokens):\n",
    "        if not isinstance(tokens,(tuple,list)):\n",
    "            return self.token_to_idx.get(tokens,0)\n",
    "        return [self.__getitem__(i) for i in tokens]\n",
    "\n",
    "    @property\n",
    "    def unk(self):\n",
    "        return 0\n",
    "\n",
    "    @property\n",
    "    def tokens_freq(self):\n",
    "        return self._token_feq\n",
    "\n",
    "def load_corpus_time_machine(max_tokens=-1):  #@save\n",
    "    \"\"\"返回时光机器数据集的词元索引列表和词表\"\"\"\n",
    "    tokens=tokenize(read_time_machine(),'char')\n",
    "    vocal=Vocal(tokens)\n",
    "\n",
    "    # 因为时光机器数据集中的每个文本行不一定是一个句子或一个段落，\n",
    "    # 所以将所有文本行展平到一个列表中\n",
    "    corpus = [vocal[token] for line in tokens for token in line]\n",
    "    if max_tokens > 0:\n",
    "        corpus = corpus[:max_tokens]\n",
    "    return corpus, vocal\n",
    "\n",
    "##产生随机序列\n",
    "def seq_data_iter_random(corpus,batch_size,num_steps):\n",
    "    \"\"\"使用随机抽样生成一个小批量子序列\"\"\"\n",
    "    ##randint是左闭右闭 所以必须得减一不然0和numsteps实际上是重复的\n",
    "    corpus=corpus[random.randint(0,num_steps-1):]\n",
    "    ##因为y要比x多一位 一共可以有这么多子序列\n",
    "    num_subseqs=(len(corpus)-1)//num_steps\n",
    "\n",
    "    ## 然后找出每一个num seq的起始索引拿出来放到列表里 这里不能用corpus的长度 而是num_steps*num_subseqs\n",
    "    seq_start_index=[i for i in range(0,num_steps*num_subseqs,num_steps)]\n",
    "    ##打乱索引\n",
    "    random.shuffle(seq_start_index)\n",
    "\n",
    "    ## 再除以batchsize 有多少个batch\n",
    "    num_batch=num_subseqs//batch_size\n",
    "    ### 然后给每个batch找x和y 索引起始位置在seq_start_index里\n",
    "    for i in range(num_batch):\n",
    "        index_list=seq_start_index[i*batch_size:(i+1)*batch_size]\n",
    "        x=[]\n",
    "        y=[]\n",
    "        for _index in index_list:\n",
    "           x.append(corpus[_index:_index+num_steps])\n",
    "           y.append(corpus[_index+1:_index+1+num_steps])\n",
    "        yield torch.tensor(x),torch.tensor(y)\n",
    "        ##结果是2维的，dim=0 是batchsize dim=1是时间步\n",
    "\n",
    "# def seq_data_iter_sequential(corpus,batch_size,num_steps):\n",
    "#     random.seed(42)\n",
    "#     corpus=corpus[random.randint(0,num_steps):]\n",
    "#     batch_num=(len(corpus)-1)//(batch_size*num_steps)\n",
    "#     Xs=torch.tensor(corpus[:batch_num*batch_size*num_steps]).reshape(-1,batch_size,num_steps)\n",
    "#     Ys=torch.tensor(corpus[1:batch_num*batch_size*num_steps+1]).reshape(-1,batch_size,num_steps)\n",
    "#     for i in range(batch_num):\n",
    "#         yield Xs[i],Ys[i]\n",
    "# s1=seq_data_iter_sequential(corpus,batch_size,num_steps)\n",
    "# 这个方案是错的 连续要求在不同的batch上保持连续 而不是在一个batch的多个样本上保持连续 并且 batch_num=(len(corpus)-1)//(batch_size*num_steps) 这样也不太好\n",
    "#因为batch_num 计算方式耦合了 batch_size 和 num_steps，\n",
    "\n",
    "\n",
    "def seq_data_iter_sequential(corpus,batch_size,num_steps):\n",
    "    random.seed(0)\n",
    "    corpus=corpus[random.randint(0,num_steps):]\n",
    "    num_tokens=(len(corpus)-1)//batch_size*batch_size ## 保证是batch_size的倍数\n",
    "    ###batch_size需要放在最外维度：常规样本维度安排 外层是样本个数 也就是batch_size\n",
    "    Xs=torch.tensor(corpus[:num_tokens]).reshape(batch_size,-1)\n",
    "    Ys=torch.tensor(corpus[1:num_tokens+1]).reshape(batch_size,-1)\n",
    "    ##维度1是每个batchsize有多少token\n",
    "    batch_num=Xs.shape[1]//num_steps\n",
    "    for i in range(batch_num):\n",
    "        yield Xs[:,i*num_steps:(i+1)*num_steps],Ys[:,i*num_steps:(i+1)*num_steps]\n",
    "class SeqDataLoader:  #@save\n",
    "    def __init__(self,batch_size,num_steps,use_random_iter,max_token):\n",
    "        if use_random_iter:\n",
    "            self.data_iter_fn=seq_data_iter_random\n",
    "        else:\n",
    "            self.data_iter_fn=seq_data_iter_sequential\n",
    "        self.corpus,self.vocal=load_corpus_time_machine(max_token)\n",
    "        self.batch_size,self.num_steps = batch_size,num_steps\n",
    "\n",
    "    ##__iter__方法使得整个类变成可迭代的\n",
    "    def __iter__(self):\n",
    "        return self.data_iter_fn(self.corpus,self.batch_size,self.num_steps)\n",
    "\n",
    "def load_data_time_machine(batch_size,num_steps,use_random_iter=False,max_token=10000):\n",
    "    data_iter=SeqDataLoader(batch_size,num_steps,use_random_iter,max_token)\n",
    "    return data_iter,data_iter.vocal\n"
   ],
   "id": "d1cfddadd3d59ed8",
   "outputs": [],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-02T01:26:33.218734Z",
     "start_time": "2025-05-02T01:26:33.175340Z"
    }
   },
   "cell_type": "code",
   "source": [
    "batch_size, num_steps = 32, 35\n",
    "num_hidden=512\n",
    "train_iter, vocab = load_data_time_machine(batch_size, num_steps)"
   ],
   "id": "5e8a3e3f278e65f",
   "outputs": [],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-02T01:26:33.520119Z",
     "start_time": "2025-05-02T01:26:33.518380Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "2a8db4a2b9304c7c",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-02T01:26:33.880354Z",
     "start_time": "2025-05-02T01:26:33.874687Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "rnn_layer=nn.RNN(len(vocab),num_hidden)\n",
    "##定义循环神经网络\n",
    "class RNN(nn.Module):\n",
    "    def __init__(self,rnn_layer,vocab_size, **kwargs):\n",
    "        super(RNN,self).__init__(**kwargs)\n",
    "        self.rnn=rnn_layer\n",
    "        self.vocab_size=vocab_size\n",
    "        self.hidden_size=self.rnn.hidden_size\n",
    "        if not self.rnn.bidirectional:\n",
    "            self.num_directions = 1\n",
    "            self.linear=nn.Linear(self.hidden_size,self.vocab_size)\n",
    "        else:\n",
    "            self.num_directions = 2\n",
    "            self.linear = nn.Linear(self.num_hiddens * 2, self.vocab_size)\n",
    "    def forward(self,input,state):\n",
    "        X = F.one_hot(input.T.long(),self.vocab_size)\n",
    "        ##nn.RNN会自动预热\n",
    "        Y,state=self.rnn(X.to(dtype=torch.float32),state) ##输出维度是（x,num_steps,hiddens）\n",
    "        output=self.linear(Y.reshape(-1,Y.shape[-1]))\n",
    "        return output,state\n",
    "    ##初始化隐状态\n",
    "    def begin_state(self,device, batch_size=1):\n",
    "        if not isinstance(self.rnn, nn.LSTM):\n",
    "            # nn.GRU以张量作为隐状态\n",
    "            state=torch.zeros((self.num_directions * self.rnn.num_layers,batch_size,self.hidden_size),device=device)\n",
    "            return  state\n",
    "        else:\n",
    "            # nn.LSTM以元组作为隐状态\n",
    "            return (torch.zeros((\n",
    "                self.num_directions * self.rnn.num_layers,\n",
    "                batch_size, self.num_hiddens), device=device),\n",
    "                    torch.zeros((\n",
    "                        self.num_directions * self.rnn.num_layers,\n",
    "                        batch_size, self.num_hiddens), device=device))\n",
    "\n",
    "def predict_ch8(prefix, num_preds, net, vocab, device):  #@save\n",
    "    \"\"\"在prefix后面生成新字符\"\"\"\n",
    "    state = net.begin_state(batch_size=1, device=device)\n",
    "    ##outputs只有第一个字母\n",
    "    outputs = [vocab[prefix[0]]]\n",
    "    ## 定义一个获取最新output的函数\n",
    "    get_input = lambda: torch.tensor([outputs[-1]], device=device).reshape((1, 1))\n",
    "    for y in prefix[1:]:  # 预热期\n",
    "        ##get_input()每次只有一个值 作为输入 state为隐状态\n",
    "        _, state = net(get_input(), state)\n",
    "        outputs.append(vocab[y])\n",
    "    for _ in range(num_preds):  # 预测num_preds步\n",
    "        y, state = net(get_input(), state)\n",
    "        outputs.append(int(y.argmax(dim=1).reshape(1)))\n",
    "    return ''.join([vocab.idx_to_token[i] for i in outputs])\n",
    "\n",
    "def grad_clipping(net,theta):\n",
    "    if isinstance(net,nn.Module):\n",
    "        params = [p for p in net.parameters() if p.requires_grad]\n",
    "    else:\n",
    "        params = net.params\n",
    "    # norm = torch.sqrt(sum(torch.sum((p.grad ** 2)) for p in params))\n",
    "    norm=torch.sqrt(torch.sum(torch.tensor([torch.sum(p.grad**2) for p in params])))\n",
    "    if norm > theta:\n",
    "        for param in params:\n",
    "            param.grad[:] *= theta / norm\n",
    "\n",
    "\n",
    "def train_epoch_ch8(net, train_iter, loss, updater, device, use_random_iter):\n",
    "    state, timer = None, Timer()\n",
    "    metric = Accumulator(2)\n",
    "    for X, Y in train_iter:\n",
    "        if state is None or use_random_iter:\n",
    "            # 初始化状态\n",
    "            state = net.begin_state(batch_size=X.shape[0], device=device)\n",
    "        else:\n",
    "            # 非原地分离状态\n",
    "            if isinstance(net, nn.Module):\n",
    "                if isinstance(state, tuple):\n",
    "                    # LSTM状态：分离每个张量\n",
    "                    state = tuple(s.detach() for s in state)\n",
    "                else:\n",
    "                    # GRU状态：直接分离\n",
    "                    state = state.detach()\n",
    "            else:\n",
    "                # 自定义模型状态处理\n",
    "                state = (s.detach() for s in state)\n",
    "        y = Y.T.reshape(-1)\n",
    "        X, y = X.to(device), y.to(device)\n",
    "        y_hat, state = net(X, state)\n",
    "        l = loss(y_hat, y.long()).mean()\n",
    "        if isinstance(updater, torch.optim.Optimizer):\n",
    "            updater.zero_grad()\n",
    "            l.backward()\n",
    "            grad_clipping(net, 1)\n",
    "            updater.step()\n",
    "        else:\n",
    "            l.backward()\n",
    "            grad_clipping(net, 1)\n",
    "            updater(batch_size=1)\n",
    "        metric.add(l * y.numel(), y.numel())\n",
    "    return math.exp(metric[0] / metric[1]), metric[1] / timer.stop()\n",
    "\n",
    "#@save\n",
    "def train_ch8(net, train_iter, vocab, lr, num_epochs, device,\n",
    "              use_random_iter=False):\n",
    "    \"\"\"训练模型（定义见第8章）\"\"\"\n",
    "    loss = nn.CrossEntropyLoss()\n",
    "\n",
    "    # 初始化\n",
    "    if isinstance(net, nn.Module):\n",
    "        updater = torch.optim.SGD(net.parameters(), lr)\n",
    "    else:\n",
    "        updater = lambda batch_size: sgd(net.params, lr, batch_size)\n",
    "    predict = lambda prefix: predict_ch8(prefix, 50, net, vocab, device)\n",
    "    # 训练和预测\n",
    "    for epoch in range(num_epochs):\n",
    "        ppl, speed = train_epoch_ch8(\n",
    "            net, train_iter, loss, updater, device, use_random_iter)\n",
    "        if (epoch + 1) % 10 == 0:\n",
    "            print(predict('time traveller'))\n",
    "    print(f'困惑度 {ppl:.1f}, {speed:.1f} 词元/秒 {str(device)}')\n",
    "    print(predict('time traveller'))\n",
    "    print(predict('traveller'))\n"
   ],
   "id": "1789bd52fa52c4f",
   "outputs": [],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-02T01:26:34.268960Z",
     "start_time": "2025-05-02T01:26:34.262546Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "2f927eb0052f9089",
   "outputs": [],
   "execution_count": 13
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-02T01:26:34.862058Z",
     "start_time": "2025-05-02T01:26:34.855346Z"
    }
   },
   "cell_type": "code",
   "source": [
    "net=RNN(rnn_layer,len(vocab))\n",
    "net=net.to(torch.device('cuda:0'))"
   ],
   "id": "52004a3d25befdba",
   "outputs": [],
   "execution_count": 14
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-02T01:26:35.561968Z",
     "start_time": "2025-05-02T01:26:35.538448Z"
    }
   },
   "cell_type": "code",
   "source": "predict_ch8('time traveller', 10, net, vocab, 'cuda:0')",
   "id": "5185d931546a58a",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'time travellerzgzgzgzgzg'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 15
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-02T01:26:47.939365Z",
     "start_time": "2025-05-02T01:26:36.271615Z"
    }
   },
   "cell_type": "code",
   "source": [
    "num_epochs, lr = 500, 1\n",
    "train_ch8(net, train_iter, vocab, lr, num_epochs, 'cuda:0')"
   ],
   "id": "a785999009229f50",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time traveller  an  an  an  an  an  an  an  an  an  an  an  an  \n",
      "time traveller  and the  and the  and the  and the  and the  and\n",
      "time traveller  four  in the time traveller  four   and the  the\n",
      "time traveller  and the tre  the the the the the the the the the\n",
      "time traveller  mat  ally the time t an t an t an   ar and the t\n",
      "time traveller  wall  spanced me time tre  lan   and and and and\n",
      "time traveller ally ally there andion ancagoully ascentareedithe\n",
      "time traveller  and ther the timent on tor s an sour than tory t\n",
      "time traveller  you gand the paydon t fall the sime sime sacint \n",
      "time traveller  matind ve y on this tare  beens and the pacent s\n",
      "time traveller said the psoghthe pseif chith and sore that usera\n",
      "time traveller  mathe  berineto the s mans move about   soid the\n",
      "time traveller  tha   are ald he right   avely owey lople   ve i\n",
      "time travellery mone dime sion d mint an thertimint thertert med\n",
      "time traveller   for an wio  ouk and son t widthe pucknt t me in\n",
      "time travellere mitthree you   said the psochiles  ane at uin th\n",
      "time traveller  matir abl praclerand sainithe bs ofers on p come\n",
      "time traveller   fre ny orsereas all she thgan is  lathe hepaod \n",
      "time traveller  allar soft and fere ted has an the lespet eno  a\n",
      "time travellere mound we mon th ughatd deatly ohid thy anlath ho\n",
      "time travellery woc g  wavall oreell tho lioged th  foust  cingi\n",
      "time traveller  worle whi k mouldins of tha way oelthe bmile may\n",
      "time travellerts  lending thrse dimindion gont  oreant fiot soft\n",
      "time traveller  abter the paus teruited tor ghe paune tici ntint\n",
      "time traveller  mothe aghyou som  and the time traveller  mothe \n",
      "time traveller  motied wo buthedtime iot  is ingensenelexissthis\n",
      "time traveller   outheti wens boghit   said the medical manour a\n",
      "time traveller  with a slight accession ofihen fire tof coue man\n",
      "time traveller  abuti   suin the llycpe s in the wiperedis inlen\n",
      "time traveller smiled roung  theon hou naid fow y aloughean fise\n",
      "time traveller pefter the tals hopngimans  way urefre tad at sin\n",
      "time traveller smiled   are you sure  on th ont mo k anoll gha a\n",
      "time traveller  mothe  of hherov thetwore  byou bur worecot ench\n",
      "time traveller   ot ghad sone  the anofll  werchetor the tromght\n",
      "time traveller smile    ara you bu a and of smalle wale abreati \n",
      "time traveller smiled roung atdus  thin   haintered meefout y mo\n",
      "time traveller proceeded   anyreal body must havelester i  one s\n",
      "time traveller  mor so se whay sp che leot arm at   soid timi th\n",
      "time traveller smiled round at us  then  still smiling faintles \n",
      "time traveller proceeded   anyreal body must have extension in  \n",
      "time traveller  after the pausere ber messave  exbro nes  ane he\n",
      "time traveller  after the pauserequired for this mema abe pound \n",
      "time traveller  anted  ane allext on tha gsuer wemu ne sive li n\n",
      "time traveller  mith a slight accession ofcheerfulness   an us  \n",
      "time traveller smited  but yed ar vent  bed red man y of toe tim\n",
      "time traveller sofle nabr and an whs pt tre ic  ane ofiac war  l\n",
      "time traveller  after the pauserequired for the ofothersomol  an\n",
      "time traveller  abuthe wean   kar sadi ansulesthe three pimensio\n",
      "time traveller sume backeest erating o spef thet than sove than \n",
      "time traveller  abucins ing tir ateacte sholed son theck tas gca\n",
      "困惑度 1.2, 343675.9 词元/秒 cuda:0\n",
      "time traveller  abucins ing tir ateacte sholed son theck tas gca\n",
      "traveller  hith a slig teaccint  this fine we cavely pencic\n"
     ]
    }
   ],
   "execution_count": 16
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-02T04:09:51.242080Z",
     "start_time": "2025-05-02T04:09:51.239388Z"
    }
   },
   "cell_type": "code",
   "source": "net=nn.Linear(1,1)",
   "id": "fa28a4c56ce0d297",
   "outputs": [],
   "execution_count": 65
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-02T04:09:51.628643Z",
     "start_time": "2025-05-02T04:09:51.625604Z"
    }
   },
   "cell_type": "code",
   "source": "x1=torch.tensor(2)",
   "id": "32ddee6352a87102",
   "outputs": [],
   "execution_count": 66
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-02T04:09:51.971815Z",
     "start_time": "2025-05-02T04:09:51.968089Z"
    }
   },
   "cell_type": "code",
   "source": [
    "x=torch.ones(1,1)\n",
    "x.requires_grad=True\n",
    "y=x*x1\n",
    "y.backward()\n",
    "x.grad"
   ],
   "id": "e0be73cb955557cc",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[2.]])"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 67
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-02T04:09:53.029059Z",
     "start_time": "2025-05-02T04:09:53.026004Z"
    }
   },
   "cell_type": "code",
   "source": [
    "x.detach_()\n",
    "x.requires_grad"
   ],
   "id": "2e0e0cf226c0fe89",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 68
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-02T04:10:12.809117Z",
     "start_time": "2025-05-02T04:10:12.788935Z"
    }
   },
   "cell_type": "code",
   "source": [
    "x=net(x)\n",
    "x.requires_grad"
   ],
   "id": "8a2c2790a00f0f37",
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Linear.forward() takes 2 positional arguments but 3 were given",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mTypeError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[72], line 1\u001B[0m\n\u001B[1;32m----> 1\u001B[0m x\u001B[38;5;241m=\u001B[39m\u001B[43mnet\u001B[49m\u001B[43m(\u001B[49m\u001B[43mx\u001B[49m\u001B[43m,\u001B[49m\u001B[43mx1\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m      2\u001B[0m x\u001B[38;5;241m.\u001B[39mrequires_grad\n",
      "File \u001B[1;32mE:\\tech_software\\Python\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1739\u001B[0m, in \u001B[0;36mModule._wrapped_call_impl\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1737\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compiled_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[0;32m   1738\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m-> 1739\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call_impl\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32mE:\\tech_software\\Python\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1750\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1745\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[0;32m   1746\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[0;32m   1747\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[0;32m   1748\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[0;32m   1749\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[1;32m-> 1750\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1752\u001B[0m result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[0;32m   1753\u001B[0m called_always_called_hooks \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mset\u001B[39m()\n",
      "\u001B[1;31mTypeError\u001B[0m: Linear.forward() takes 2 positional arguments but 3 were given"
     ]
    }
   ],
   "execution_count": 72
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-02T03:58:13.486745Z",
     "start_time": "2025-05-02T03:58:13.481512Z"
    }
   },
   "cell_type": "code",
   "source": [
    "x=x*x1\n",
    "y_2=x*x1\n",
    "y_2.backward()\n",
    "x1.grad"
   ],
   "id": "fdecedeaaceeb534",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 60
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-02T03:46:11.666954Z",
     "start_time": "2025-05-02T03:46:11.664012Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "cf53d15c4dc80215",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[5.]])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 35
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "fbdb4cf65e4f3132"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
