{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-05-28T01:05:28.504258Z",
     "start_time": "2025-05-28T01:05:24.458477Z"
    }
   },
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from dplearning_second_part.limu_dplearning.utils.useful_func import tokenize_nmt, Vocal, build_array_nmt, \\\n",
    "    preprocess_nmt, read_data_nmt\n",
    "\n",
    "src, tgt = tokenize_nmt(preprocess_nmt(read_data_nmt()),num_examples=600)\n",
    "src_vocab = Vocal(src, min_feq=2,\n",
    "                  reserved_tokens=['<pad>', '<bos>', '<eos>'])\n",
    "tgt_vocab = Vocal(tgt, min_feq=2,\n",
    "                  reserved_tokens=['<pad>', '<bos>', '<eos>'])\n",
    "src_data, src_valid = build_array_nmt(src, src_vocab, 10)\n",
    "tgt_data, tgt_valid = build_array_nmt(tgt, tgt_vocab, 10)\n",
    "dataset = torch.utils.data.TensorDataset(src_data, src_valid, tgt_data, tgt_valid)\n",
    "## 训练数据\n",
    "train_data = torch.utils.data.DataLoader(dataset=dataset, batch_size=32, shuffle=False)"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-28T02:34:17.685407Z",
     "start_time": "2025-05-28T02:34:17.675601Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 掩蔽softmax实现\n",
    "def sequence_mask(X,valid_len, value=0):\n",
    "    \"\"\"X必须为2维batch_size* num_steps，valid_len必须为1维batch\n",
    "       意味着 第i个batch_size的序列有效长度为 valid_len[i]\n",
    "    \"\"\"\n",
    "    if X.dim() != 2 or valid_len.dim() != 1:\n",
    "        raise ValueError('Expect 2d tensor')\n",
    "    # 获取num_steps长度\n",
    "    maxlen = X.shape[1]\n",
    "    # 生成顺序序列，用于与valid_len比较\n",
    "    mask = torch.unsqueeze(torch.arange(0, maxlen, dtype=torch.long),dim=0)\n",
    "    # 判断需要掩码的部分，这里必须要保证mask和vilid_len形状相等 否则会出问题\n",
    "    mask = (mask<valid_len.unsqueeze(1).repeat(1, maxlen))\n",
    "    X[~mask] = value\n",
    "    return X\n",
    "\n",
    "def masked_softmax(X,valid_lens=None):\n",
    "    \"\"\"通过在最后一个轴上掩蔽元素来执行softmax操作\n",
    "    注意：X是三维的 一般是 B Q K-V数量\n",
    "     掩码的目的在于 避免Q关注到无关的或者禁止的K-V\n",
    "    \"\"\"\n",
    "    if valid_lens is None:\n",
    "        return F.softmax(X, dim=-1)\n",
    "    shape=X.shape\n",
    "    # valid_lens可以是1d或者2d 如果是1d则必须长为B 如果是2d则必须是B*Q\n",
    "    if valid_lens.dim() == 1:\n",
    "        # 如果是1d则扩展成2d 形状B Q \n",
    "        valid_lens = valid_lens.unsqueeze(1).repeat(1, shape[1])\n",
    "    # 因为sequence函数要求的X是2d valid_lens是1d\n",
    "    X=X.reshape(-1,shape[-1])\n",
    "    valid_lens=valid_lens.reshape(-1)\n",
    "    X_mask=sequence_mask(X, valid_lens,value=-1e6)\n",
    "    # 完事之后还要把输出的形状转为X原本的形状 \n",
    "    return F.softmax(X_mask, dim=-1).reshape(shape)"
   ],
   "id": "18e7b29624619a09",
   "outputs": [],
   "execution_count": 72
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-28T01:05:28.570376Z",
     "start_time": "2025-05-28T01:05:28.553008Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "# 位置编码\n",
    "class PositionalEncoding(nn.Module):\n",
    "    \"\"\"位置编码\"\"\"\n",
    "    def __init__(self, num_hiddens, dropout=0.1, max_len=1000):\n",
    "        super(PositionalEncoding, self).__init__()\n",
    "        # 创建一个足够长的P 长是指第2个维度 第一个维度应该是batch_size\n",
    "        # 每一个batch用的是一套位置编码 如果不用一套的话就无法学习到位置信息泛化能力极差\n",
    "        self.P=torch.zeros(1,max_len,num_hiddens)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        X=torch.arange(max_len,dtype=torch.float32).reshape(-1,1)/\\\n",
    "            torch.pow(10000,torch.arange(0,num_hiddens,2)/num_hiddens)\n",
    "        self.P[:,:,0::2]=torch.sin(X)\n",
    "        self.P[:,:,1::2]=torch.cos(X)\n",
    "    def forward(self, X):\n",
    "        X = X+self.P[:,:X.shape[1],:].to(X.device)\n",
    "        return self.dropout(X)\n",
    "\n",
    "\n",
    "# 先实现一个点积注意力\n",
    "class DotProductAttention(nn.Module):\n",
    "    def __init__(self, dropout=0.2):\n",
    "        super(DotProductAttention, self).__init__()\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.attention_weights = None\n",
    "    # q(b,step,embed_size)\n",
    "    # k(b,键值对个数,embed_size)\n",
    "    # v(b,键值对个数,embed_size)\n",
    "    def forward(self, q, k, v,valid_lens):\n",
    "        attn_weights = torch.bmm(q, k.transpose(1, 2))/torch.sqrt(torch.tensor(q.shape[-1]))\n",
    "        self.attention_weights=masked_softmax(attn_weights,valid_lens)\n",
    "        return torch.bmm(self.dropout(self.attention_weights), v)\n",
    "\n",
    "#@save\n",
    "class MultiHeadAttention(nn.Module):\n",
    "    \"\"\"多头注意力\"\"\"\n",
    "    # qkv各自的embed_size, 隐藏层大小 头数量\n",
    "    # 需要并行运算多个头 因此num_hiddens 必须能够整除以num_heads\n",
    "    def __init__(self,key_size,query_size,value_size,num_hiddens,num_heads,dropout,bias=False, **kwargs):\n",
    "        super(MultiHeadAttention, self).__init__(**kwargs)\n",
    "        self.num_heads = num_heads\n",
    "        self.attention = DotProductAttention(dropout)\n",
    "        self.W_q=nn.Linear(query_size,num_hiddens,bias=bias)\n",
    "        self.W_k=nn.Linear(key_size,num_hiddens,bias=bias)\n",
    "        self.W_v=nn.Linear(value_size,num_hiddens,bias=bias)\n",
    "        self.W_o=nn.Linear(num_hiddens,num_hiddens,bias=bias)\n",
    "\n",
    "    def forward(self, q, k, v,valid_lens=None):\n",
    "\n",
    "        queries=self.W_q(q)\n",
    "        keys=self.W_k(k)\n",
    "        values=self.W_v(v)\n",
    "\n",
    "        # 在这一步需要对qkv拆分为多头 并行计算attention\n",
    "        queries=queries.reshape(queries.shape[0],queries.shape[1],self.num_heads,-1).permute(0,2,1,3)\n",
    "        keys=keys.reshape(keys.shape[0],keys.shape[1],self.num_heads,-1).permute(0,2,1,3)\n",
    "        values=values.reshape(values.shape[0],values.shape[1],self.num_heads,-1).permute(0,2,1,3)\n",
    "\n",
    "        queries=queries.reshape(-1,queries.shape[2],queries.shape[3])\n",
    "        keys=keys.reshape(-1,keys.shape[2],keys.shape[3])\n",
    "        values=values.reshape(-1,values.shape[2],values.shape[3])\n",
    "\n",
    "        if valid_lens is not None:\n",
    "            # 在轴0，将第一项（标量或者矢量）复制num_heads次，\n",
    "            # 然后如此复制第二项，然后诸如此类。\n",
    "            valid_lens = torch.repeat_interleave(\n",
    "                valid_lens, repeats=self.num_heads, dim=0)\n",
    "\n",
    "        attn_weights=self.attention(queries,keys,values,valid_lens)\n",
    "        attn_weights=attn_weights.reshape(-1,self.num_heads,attn_weights.shape[1],attn_weights.shape[2])\n",
    "        attn_weights=attn_weights.permute(0,2,1,3)\n",
    "        attn_weights=attn_weights.reshape(attn_weights.shape[0],attn_weights.shape[1],-1)\n",
    "\n",
    "        return self.W_o(attn_weights)\n"
   ],
   "id": "d38ebef52929b469",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-28T01:05:28.576239Z",
     "start_time": "2025-05-28T01:05:28.570376Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class PositionWiseFFN(nn.Module):\n",
    "    \"\"\"基于位置的前馈网络\"\"\"\n",
    "    def __init__(self,ffn_num_input,ffn_num_hiddens,ffn_num_outputs,**kwargs):\n",
    "        super(PositionWiseFFN,self).__init__(**kwargs)\n",
    "        self.dense1=nn.Linear(ffn_num_input,ffn_num_hiddens)\n",
    "        self.relu=nn.ReLU()\n",
    "        self.dense2=nn.Linear(ffn_num_hiddens,ffn_num_outputs)\n",
    "    def forward(self,x):\n",
    "        return self.dense2(self.relu(self.dense1(x)))"
   ],
   "id": "5564bf4d2e4464d8",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-28T01:05:28.590305Z",
     "start_time": "2025-05-28T01:05:28.576239Z"
    }
   },
   "cell_type": "code",
   "source": [
    "ffn=PositionWiseFFN(ffn_num_input=4,ffn_num_hiddens=4,ffn_num_outputs=8)\n",
    "ffn.eval()\n",
    "ffn(torch.ones((2,3,4))).shape"
   ],
   "id": "1204f7b63ecc1632",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 3, 8])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-28T01:05:28.594672Z",
     "start_time": "2025-05-28T01:05:28.590305Z"
    }
   },
   "cell_type": "code",
   "source": "# 残差连接和层规范化",
   "id": "fc174191f0bf2b8b",
   "outputs": [],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-28T01:05:28.601364Z",
     "start_time": "2025-05-28T01:05:28.594672Z"
    }
   },
   "cell_type": "code",
   "source": [
    "ln = nn.LayerNorm(2)\n",
    "bn = nn.BatchNorm1d(2)"
   ],
   "id": "7bd318b369af9d76",
   "outputs": [],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-28T01:05:28.609593Z",
     "start_time": "2025-05-28T01:05:28.601364Z"
    }
   },
   "cell_type": "code",
   "source": [
    "x=torch.tensor([[1,2],[2,3]],dtype=torch.float32)\n",
    "x,x.shape"
   ],
   "id": "ad278bb0ac7ab58d",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[1., 2.],\n",
       "         [2., 3.]]),\n",
       " torch.Size([2, 2]))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-28T01:05:28.614972Z",
     "start_time": "2025-05-28T01:05:28.609593Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 残差连接和层规范化\n",
    "class AddNorm(nn.Module):\n",
    "    def __init__(self,normalized_shape,dropout,**kwargs):\n",
    "        super(AddNorm,self).__init__()\n",
    "        self.dropout=nn.Dropout(dropout)\n",
    "        self.ln=nn.LayerNorm(normalized_shape)\n",
    "        \n",
    "    def forward(self,X,Y):\n",
    "        return self.ln(self.dropout(Y) + X)"
   ],
   "id": "d879ec795cb9e9c6",
   "outputs": [],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-28T01:05:28.622013Z",
     "start_time": "2025-05-28T01:05:28.614972Z"
    }
   },
   "cell_type": "code",
   "source": [
    "add_norm = AddNorm([3, 4], 0.5)\n",
    "add_norm.eval()"
   ],
   "id": "a66677e2919f8b59",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AddNorm(\n",
       "  (dropout): Dropout(p=0.5, inplace=False)\n",
       "  (ln): LayerNorm((3, 4), eps=1e-05, elementwise_affine=True)\n",
       ")"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-28T01:05:28.629109Z",
     "start_time": "2025-05-28T01:05:28.622013Z"
    }
   },
   "cell_type": "code",
   "source": "add_norm(torch.ones((2, 3, 4)), torch.ones((2, 3, 4))).shape",
   "id": "acc33c8074dfc490",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 3, 4])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 13
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-28T01:05:28.636691Z",
     "start_time": "2025-05-28T01:05:28.629109Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class EncoderBlock(nn.Module):\n",
    "    def __init__(self,key_size,query_size,value_size,num_hiddens,norm_shape\n",
    "                 ,ffn_num_input,ffn_num_hiddens,num_heads,dropout,use_bias=False,**kwargs):\n",
    "        super(EncoderBlock,self).__init__()\n",
    "        self.attention = MultiHeadAttention(key_size,query_size,value_size,num_hiddens,num_heads,dropout,bias=use_bias)\n",
    "        self.addnorm1=AddNorm(norm_shape, dropout)\n",
    "        self.ffn = PositionWiseFFN(ffn_num_input,ffn_num_hiddens,num_hiddens,**kwargs)\n",
    "        self.addnorm2=AddNorm(norm_shape, dropout)\n",
    "        \n",
    "    def forward(self,X,valid_lens):\n",
    "        Y=self.addnorm1(X,self.attention(X,X,X,valid_lens))\n",
    "        return self.addnorm2(Y,self.ffn(Y))"
   ],
   "id": "d7cc7bfcb9c9e3e9",
   "outputs": [],
   "execution_count": 14
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-28T06:28:06.020831Z",
     "start_time": "2025-05-28T06:28:06.014188Z"
    }
   },
   "cell_type": "code",
   "source": [
    "x=torch.ones((2,100,24))\n",
    "valid_lens=torch.tensor([3,2])\n",
    "encoder_blk=EncoderBlock(key_size=24,query_size=24,value_size=24,num_hiddens=24,norm_shape=[100,24],ffn_num_input=24,ffn_num_hiddens=48,num_heads=8,dropout=0.5)\n",
    "encoder_blk.eval()"
   ],
   "id": "b00281a03e505be3",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "EncoderBlock(\n",
       "  (attention): MultiHeadAttention(\n",
       "    (attention): DotProductAttention(\n",
       "      (dropout): Dropout(p=0.5, inplace=False)\n",
       "    )\n",
       "    (W_q): Linear(in_features=24, out_features=24, bias=False)\n",
       "    (W_k): Linear(in_features=24, out_features=24, bias=False)\n",
       "    (W_v): Linear(in_features=24, out_features=24, bias=False)\n",
       "    (W_o): Linear(in_features=24, out_features=24, bias=False)\n",
       "  )\n",
       "  (addnorm1): AddNorm(\n",
       "    (dropout): Dropout(p=0.5, inplace=False)\n",
       "    (ln): LayerNorm((100, 24), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       "  (ffn): PositionWiseFFN(\n",
       "    (dense1): Linear(in_features=24, out_features=48, bias=True)\n",
       "    (relu): ReLU()\n",
       "    (dense2): Linear(in_features=48, out_features=24, bias=True)\n",
       "  )\n",
       "  (addnorm2): AddNorm(\n",
       "    (dropout): Dropout(p=0.5, inplace=False)\n",
       "    (ln): LayerNorm((100, 24), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 86
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-28T01:05:28.659071Z",
     "start_time": "2025-05-28T01:05:28.646355Z"
    }
   },
   "cell_type": "code",
   "source": "encoder_blk(x,valid_lens).shape",
   "id": "1ca9657b5a63e5bc",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 100, 24])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 16
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-28T01:05:28.670620Z",
     "start_time": "2025-05-28T01:05:28.659071Z"
    }
   },
   "cell_type": "code",
   "source": "encoder_blk.attention.attention.attention_weights",
   "id": "e8ed2966391c7a71",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0.3333, 0.3333, 0.3333,  ..., 0.0000, 0.0000, 0.0000],\n",
       "         [0.3333, 0.3333, 0.3333,  ..., 0.0000, 0.0000, 0.0000],\n",
       "         [0.3333, 0.3333, 0.3333,  ..., 0.0000, 0.0000, 0.0000],\n",
       "         ...,\n",
       "         [0.3333, 0.3333, 0.3333,  ..., 0.0000, 0.0000, 0.0000],\n",
       "         [0.3333, 0.3333, 0.3333,  ..., 0.0000, 0.0000, 0.0000],\n",
       "         [0.3333, 0.3333, 0.3333,  ..., 0.0000, 0.0000, 0.0000]],\n",
       "\n",
       "        [[0.3333, 0.3333, 0.3333,  ..., 0.0000, 0.0000, 0.0000],\n",
       "         [0.3333, 0.3333, 0.3333,  ..., 0.0000, 0.0000, 0.0000],\n",
       "         [0.3333, 0.3333, 0.3333,  ..., 0.0000, 0.0000, 0.0000],\n",
       "         ...,\n",
       "         [0.3333, 0.3333, 0.3333,  ..., 0.0000, 0.0000, 0.0000],\n",
       "         [0.3333, 0.3333, 0.3333,  ..., 0.0000, 0.0000, 0.0000],\n",
       "         [0.3333, 0.3333, 0.3333,  ..., 0.0000, 0.0000, 0.0000]],\n",
       "\n",
       "        [[0.3333, 0.3333, 0.3333,  ..., 0.0000, 0.0000, 0.0000],\n",
       "         [0.3333, 0.3333, 0.3333,  ..., 0.0000, 0.0000, 0.0000],\n",
       "         [0.3333, 0.3333, 0.3333,  ..., 0.0000, 0.0000, 0.0000],\n",
       "         ...,\n",
       "         [0.3333, 0.3333, 0.3333,  ..., 0.0000, 0.0000, 0.0000],\n",
       "         [0.3333, 0.3333, 0.3333,  ..., 0.0000, 0.0000, 0.0000],\n",
       "         [0.3333, 0.3333, 0.3333,  ..., 0.0000, 0.0000, 0.0000]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[0.5000, 0.5000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "         [0.5000, 0.5000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "         [0.5000, 0.5000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "         ...,\n",
       "         [0.5000, 0.5000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "         [0.5000, 0.5000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "         [0.5000, 0.5000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]],\n",
       "\n",
       "        [[0.5000, 0.5000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "         [0.5000, 0.5000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "         [0.5000, 0.5000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "         ...,\n",
       "         [0.5000, 0.5000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "         [0.5000, 0.5000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "         [0.5000, 0.5000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]],\n",
       "\n",
       "        [[0.5000, 0.5000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "         [0.5000, 0.5000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "         [0.5000, 0.5000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "         ...,\n",
       "         [0.5000, 0.5000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "         [0.5000, 0.5000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "         [0.5000, 0.5000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]]],\n",
       "       grad_fn=<SoftmaxBackward0>)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 17
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-28T01:05:28.678846Z",
     "start_time": "2025-05-28T01:05:28.670620Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class TransformerEncoder(nn.Module):\n",
    "    def __init__(self, vocab_size, key_size, query_size, value_size,\n",
    "                 num_hiddens, norm_shape, ffn_num_input, ffn_num_hiddens,\n",
    "                 num_heads, num_layers, dropout, use_bias=False, **kwargs):\n",
    "        super(TransformerEncoder,self).__init__()\n",
    "        self.num_hiddens = num_hiddens\n",
    "        self.embedding = nn.Embedding(vocab_size,num_hiddens)\n",
    "        self.pos_encoding=PositionalEncoding(num_hiddens,dropout)\n",
    "        self.blks=nn.Sequential()\n",
    "        for i in range(num_layers):\n",
    "            self.blks.add_module('block'+str(i)\n",
    "                                 ,EncoderBlock(key_size,query_size,value_size,num_hiddens\n",
    "                                               ,norm_shape,ffn_num_input,ffn_num_hiddens\n",
    "                                               ,num_heads,dropout,use_bias))\n",
    "    def forward(self,X,valid_lens,*args):\n",
    "        # 因为位置编码值在-1和1之间，\n",
    "        # 因此嵌入值乘以嵌入维度的平方根进行缩放， 因为嵌入层会把整个层的元素都压缩在均值为0方差为1的分布中 \n",
    "        # 因此当num_hiddens越大单个值会越小所以这么乘 保证每个元素也是在-1 1之间\n",
    "        # 然后再与位置编码相加。\n",
    "        X=self.pos_encoding(self.embedding(X)*torch.sqrt(torch.tensor(self.num_hiddens)))\n",
    "        self.attention_weights = [None] * len(self.blks)\n",
    "        for i, blk in enumerate(self.blks):\n",
    "            X = blk(X, valid_lens)\n",
    "            self.attention_weights[\n",
    "                i] = blk.attention.attention.attention_weights\n",
    "        return X"
   ],
   "id": "5e5c0f360463c19c",
   "outputs": [],
   "execution_count": 18
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-28T01:05:28.695486Z",
     "start_time": "2025-05-28T01:05:28.678846Z"
    }
   },
   "cell_type": "code",
   "source": [
    "encoder = TransformerEncoder(\n",
    "    200, 24, 24, 24, 24, [100, 24], 24, 48, 8, 2, 0.5)\n",
    "encoder.eval()\n",
    "encoder(torch.ones((2, 100), dtype=torch.long), valid_lens).shape"
   ],
   "id": "ac16a9590078dc5b",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 100, 24])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 19
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-28T06:30:39.021336Z",
     "start_time": "2025-05-28T06:30:39.012717Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class DecoderBlock(nn.Module):\n",
    "    \"\"\"解码器中的第i个块\"\"\"\n",
    "    def __init__(self,key_size,query_size,value_size,num_hiddens,norm_shape\n",
    "                 ,ffn_num_input,ffn_num_hiddens,num_heads,dropout,i,**kwargs):\n",
    "        super(DecoderBlock,self).__init__()\n",
    "        self.i=i\n",
    "        self.attention1=MultiHeadAttention(key_size,query_size,value_size,num_hiddens,num_heads,dropout)\n",
    "        self.addnorm1=AddNorm(norm_shape, dropout)\n",
    "        self.attention2=MultiHeadAttention(key_size,query_size,value_size,num_hiddens,num_heads,dropout)\n",
    "        self.addnorm2=AddNorm(norm_shape,dropout)\n",
    "        self.ffn=PositionWiseFFN(ffn_num_input,ffn_num_hiddens,num_hiddens,**kwargs)\n",
    "        self.addnorm3=AddNorm(norm_shape, dropout)\n",
    "    def forward(self,X,state):\n",
    "        \"\"\"X每次的输入 可能是初始输入也可能是上次的输出 形状B L H\n",
    "            state: 一个包含解码器运行状态的列表。\n",
    "            state[0]: enc_outputs - 编码器的最终输出。这个在整个解码过程中都是固定的。形状： (batch_size, enc_num_steps, num_hiddens)。\n",
    "            state[1]: enc_valid_lens - 编码器输入的有效长度。用于对编码器输出进行填充掩码。形状： (batch_size,)。\n",
    "            state[2]: 一个列表，用于存储每个解码器块在自注意力层中积累的键值对历史。这对于高效的**序列生成（推理）**至关重要。\n",
    "            \"\"\"\n",
    "        enc_outputs,enc_valid_lens=state[0],state[1]\n",
    "        if state[2][self.i] is None:\n",
    "            key_values=X\n",
    "        else:# 其实这里主要是推理时发挥作用 因为训练时传入的是一个完成的X 直接复制给key_values\n",
    "            # 这个key_values每次都会叠加 叠加的是本次的X\n",
    "            key_values=torch.cat((state[2][self.i],X),dim=1)\n",
    "        state[2][self.i]=key_values\n",
    "        if self.training:\n",
    "            batch_size,num_steps,_=X.shape\n",
    "            # dec_valid_lens的开头:(batch_size,num_steps),其中每一行是[1,2,...,num_steps] 处理后就变成 batch_size*num_steps的矩阵了\n",
    "            # 基于这个valid_lens矩阵，训练状态下会生成一个解码有效长度目的是最后得到一个下三角矩阵 保证每一步x只能关注到当前之前步的编码\n",
    "            dec_valid_lens=torch.arange(1,num_steps+1,device=X.device).repeat(batch_size,1)\n",
    "        else:\n",
    "            dec_valid_lens=None\n",
    "\n",
    "        # 自注意力\n",
    "        X2 = self.attention1(X,key_values,key_values,dec_valid_lens)\n",
    "        Y = self.addnorm1(X,X2)\n",
    "        # 编码器-解码器注意力\n",
    "        # enc_outputs 形状（batch_size,num_steps,num_hiddens）\n",
    "        Y2 = self.attention2(Y,enc_outputs,enc_outputs,enc_valid_lens)\n",
    "        Z = self.addnorm2(Y,Y2)\n",
    "        return self.addnorm3(Z,self.ffn(Z)),state\n"
   ],
   "id": "ea5997d91b547af8",
   "outputs": [],
   "execution_count": 92
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-28T06:30:39.593665Z",
     "start_time": "2025-05-28T06:30:39.587833Z"
    }
   },
   "cell_type": "code",
   "source": [
    "decoder_blk=DecoderBlock(key_size=24,query_size=24,value_size=24,num_hiddens=24,norm_shape=[100,24],ffn_num_input=24,ffn_num_hiddens=48,num_heads=4,dropout=0.5,i=0)\n",
    "decoder_blk.eval()\n",
    "X=torch.ones((2,100,24))\n",
    "state=[encoder_blk(X,valid_lens),valid_lens,[None]]\n",
    "state[0].shape,decoder_blk(X, state)[0].shape"
   ],
   "id": "dd5db11c3b823262",
   "outputs": [],
   "execution_count": 93
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-28T07:24:10.035305Z",
     "start_time": "2025-05-28T07:24:10.013722Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class TransformerDecoder(nn.Module):\n",
    "    def __init__(self,vocab_size,key_size,query_size,value_size,num_hiddens,norm_shape,ffn_num_input,ffn_num_hiddens,num_heads,num_layers,dropout,**kwargs):\n",
    "        super(TransformerDecoder,self).__init__()\n",
    "        self.num_hiddens = num_hiddens\n",
    "        self.num_layers = num_layers\n",
    "        self.embedding = nn.Embedding(vocab_size,num_hiddens)\n",
    "        self.pos_encoding=PositionalEncoding(num_hiddens,dropout)\n",
    "        self.blks=nn.Sequential()\n",
    "        for i in range(num_layers):\n",
    "            self.blks.add_module('block'+str(i),\n",
    "                                 DecoderBlock(key_size,query_size,value_size,num_hiddens,norm_shape,ffn_num_input,ffn_num_hiddens,num_heads,dropout,i))\n",
    "        self.dense=nn.Linear(num_hiddens,vocab_size)\n",
    "    def init_state(self,enc_outputs,enc_valid_lens,*args):\n",
    "        return [enc_outputs,enc_valid_lens,[None]*self.num_layers]\n",
    "    \n",
    "    def forward(self,X,state):\n",
    "        # 将X放大避免整个embeding 被位置编码的大小淹没 因为位置编码是-1 1之间\n",
    "        X = self.pos_encoding(self.embedding(X)*torch.sqrt(torch.tensor(self.num_hiddens)))\n",
    "        self._attention_weights = [[None] * len(self.blks) for _ in range(2)]\n",
    "        for i,blk in enumerate(self.blks):\n",
    "            X,state = blk(X, state)\n",
    "            # 保留自注意力权重信息\n",
    "            self._attention_weights[0][i] = blk.attention1.attention.attention_weights\n",
    "            # 保留编码解码注意力权重\n",
    "            self._attention_weights[1][i] = blk.attention2.attention.attention_weights\n",
    "            \n",
    "        return self.dense(X),state\n",
    "        \n",
    "    @property\n",
    "    def attention_weights(self):\n",
    "        return self._attention_weights"
   ],
   "id": "511684e7933b9191",
   "outputs": [],
   "execution_count": 119
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-28T08:03:55.232419Z",
     "start_time": "2025-05-28T08:03:55.224662Z"
    }
   },
   "cell_type": "code",
   "source": [
    "num_hiddens,num_layers,dropout,batch_size,num_steps=32,2,0.1,64,10\n",
    "lr,num_epochs,device=0.005,200,'cpu'\n",
    "ffn_num_input=32\n",
    "ffn_num_hiddens=64\n",
    "num_heads=4\n",
    "key_size,query_size,value_size=32,32,32\n",
    "norm_shape=[32]"
   ],
   "id": "72414a099f78a9d2",
   "outputs": [],
   "execution_count": 126
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-28T08:04:02.238299Z",
     "start_time": "2025-05-28T08:03:55.731946Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "c2bd7dfcb549bd5c",
   "outputs": [],
   "execution_count": 127
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-28T08:04:02.255179Z",
     "start_time": "2025-05-28T08:04:02.238299Z"
    }
   },
   "cell_type": "code",
   "source": [
    "encoder = TransformerEncoder(\n",
    "    len(src_vocab), key_size, query_size, value_size, num_hiddens,\n",
    "    norm_shape, ffn_num_input, ffn_num_hiddens, num_heads,\n",
    "    num_layers, dropout)\n",
    "decoder = TransformerDecoder(\n",
    "    len(tgt_vocab), key_size, query_size, value_size, num_hiddens,\n",
    "    norm_shape, ffn_num_input, ffn_num_hiddens, num_heads,\n",
    "    num_layers, dropout)"
   ],
   "id": "837ddd29753f00c1",
   "outputs": [],
   "execution_count": 128
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-28T09:28:59.354672Z",
     "start_time": "2025-05-28T09:28:59.349230Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class EncoderDecoder(nn.Module):\n",
    "    def __init__(self,encoder,decoder):\n",
    "        super(EncoderDecoder,self).__init__()\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "    def forward(self,enc_x,dec_x,*args):\n",
    "        enc_outputs=self.encoder(enc_x)\n",
    "        state=self.decoder.init_state(enc_outputs,*args)\n",
    "        dec_outputs=self.decoder(dec_x,state)\n",
    "        return dec_outputs"
   ],
   "id": "37096b9058598ca6",
   "outputs": [],
   "execution_count": 136
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-28T09:29:00.599110Z",
     "start_time": "2025-05-28T09:29:00.595529Z"
    }
   },
   "cell_type": "code",
   "source": "net = EncoderDecoder(encoder, decoder)",
   "id": "84b75ba3c700144b",
   "outputs": [],
   "execution_count": 137
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-28T09:29:04.148307Z",
     "start_time": "2025-05-28T09:29:02.183004Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from torch import optim\n",
    "\n",
    "# train\n",
    "optimizer = optim.Adam(net.parameters(), lr=0.005)\n",
    "for epoch in range(300):\n",
    "    for batch in train_data:\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        src,src_valid,tgt,tgt_valid=batch\n",
    "        Y=torch.cat((torch.tensor([tgt_vocab['<bos>']]).unsqueeze(0).repeat(tgt.shape[0],1),tgt),dim=1)[:,:-1]\n",
    "        # 易错点1：训练的时候应该使用带有bos的Y 表示强制教学 此时输出的y_hat实际上是没有bos的\n",
    "        y_hat,_=net(src,Y,src_valid)\n",
    "        # 点2 因为输出的y_hat 没有bos 因此在计算loss的时候应该使用原始序列作为目标序列\n",
    "        l=loss(y_hat,tgt,tgt_valid).sum()\n",
    "        l.backward()\n",
    "        grad_clipping(net, 1)\n",
    "        optimizer.step()\n",
    "    print(l)"
   ],
   "id": "b996d767ef33940d",
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "TransformerEncoder.forward() missing 1 required positional argument: 'valid_lens'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mTypeError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[138], line 12\u001B[0m\n\u001B[0;32m     10\u001B[0m Y\u001B[38;5;241m=\u001B[39mtorch\u001B[38;5;241m.\u001B[39mcat((torch\u001B[38;5;241m.\u001B[39mtensor([tgt_vocab[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m<bos>\u001B[39m\u001B[38;5;124m'\u001B[39m]])\u001B[38;5;241m.\u001B[39munsqueeze(\u001B[38;5;241m0\u001B[39m)\u001B[38;5;241m.\u001B[39mrepeat(tgt\u001B[38;5;241m.\u001B[39mshape[\u001B[38;5;241m0\u001B[39m],\u001B[38;5;241m1\u001B[39m),tgt),dim\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m1\u001B[39m)[:,:\u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m]\n\u001B[0;32m     11\u001B[0m \u001B[38;5;66;03m# 易错点1：训练的时候应该使用带有bos的Y 表示强制教学 此时输出的y_hat实际上是没有bos的\u001B[39;00m\n\u001B[1;32m---> 12\u001B[0m y_hat,_\u001B[38;5;241m=\u001B[39m\u001B[43mnet\u001B[49m\u001B[43m(\u001B[49m\u001B[43msrc\u001B[49m\u001B[43m,\u001B[49m\u001B[43mY\u001B[49m\u001B[43m,\u001B[49m\u001B[43msrc_valid\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     13\u001B[0m \u001B[38;5;66;03m# 点2 因为输出的y_hat 没有bos 因此在计算loss的时候应该使用原始序列作为目标序列\u001B[39;00m\n\u001B[0;32m     14\u001B[0m l\u001B[38;5;241m=\u001B[39mloss(y_hat,tgt,tgt_valid)\u001B[38;5;241m.\u001B[39msum()\n",
      "File \u001B[1;32mD:\\work softwar\\python\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1739\u001B[0m, in \u001B[0;36mModule._wrapped_call_impl\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1737\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compiled_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[0;32m   1738\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m-> 1739\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call_impl\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32mD:\\work softwar\\python\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1750\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1745\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[0;32m   1746\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[0;32m   1747\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[0;32m   1748\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[0;32m   1749\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[1;32m-> 1750\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1752\u001B[0m result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[0;32m   1753\u001B[0m called_always_called_hooks \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mset\u001B[39m()\n",
      "Cell \u001B[1;32mIn[136], line 7\u001B[0m, in \u001B[0;36mEncoderDecoder.forward\u001B[1;34m(self, enc_x, dec_x, *args)\u001B[0m\n\u001B[0;32m      6\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mforward\u001B[39m(\u001B[38;5;28mself\u001B[39m,enc_x,dec_x,\u001B[38;5;241m*\u001B[39margs):\n\u001B[1;32m----> 7\u001B[0m     enc_outputs\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mencoder\u001B[49m\u001B[43m(\u001B[49m\u001B[43menc_x\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m      8\u001B[0m     state\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdecoder\u001B[38;5;241m.\u001B[39minit_state(enc_outputs,\u001B[38;5;241m*\u001B[39margs)\n\u001B[0;32m      9\u001B[0m     dec_outputs\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdecoder(dec_x,state)\n",
      "File \u001B[1;32mD:\\work softwar\\python\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1739\u001B[0m, in \u001B[0;36mModule._wrapped_call_impl\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1737\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compiled_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[0;32m   1738\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m-> 1739\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call_impl\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32mD:\\work softwar\\python\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1750\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1745\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[0;32m   1746\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[0;32m   1747\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[0;32m   1748\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[0;32m   1749\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[1;32m-> 1750\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1752\u001B[0m result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[0;32m   1753\u001B[0m called_always_called_hooks \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mset\u001B[39m()\n",
      "\u001B[1;31mTypeError\u001B[0m: TransformerEncoder.forward() missing 1 required positional argument: 'valid_lens'"
     ]
    }
   ],
   "execution_count": 138
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-28T09:29:36.451265Z",
     "start_time": "2025-05-28T09:29:31.074538Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "7aef42da1e27db77",
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "too many values to unpack (expected 2)",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[140], line 20\u001B[0m\n\u001B[0;32m     15\u001B[0m decoder \u001B[38;5;241m=\u001B[39m TransformerDecoder(\n\u001B[0;32m     16\u001B[0m     \u001B[38;5;28mlen\u001B[39m(tgt_vocab), key_size, query_size, value_size, num_hiddens,\n\u001B[0;32m     17\u001B[0m     norm_shape, ffn_num_input, ffn_num_hiddens, num_heads,\n\u001B[0;32m     18\u001B[0m     num_layers, dropout)\n\u001B[0;32m     19\u001B[0m net \u001B[38;5;241m=\u001B[39m d2l\u001B[38;5;241m.\u001B[39mEncoderDecoder(encoder, decoder)\n\u001B[1;32m---> 20\u001B[0m \u001B[43md2l\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtrain_seq2seq\u001B[49m\u001B[43m(\u001B[49m\u001B[43mnet\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtrain_iter\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mlr\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mnum_epochs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtgt_vocab\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdevice\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32mD:\\work softwar\\python\\Lib\\site-packages\\d2l\\torch.py:3421\u001B[0m, in \u001B[0;36mtrain_seq2seq\u001B[1;34m(net, data_iter, lr, num_epochs, tgt_vocab, device)\u001B[0m\n\u001B[0;32m   3418\u001B[0m bos \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39mtensor([tgt_vocab[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m<bos>\u001B[39m\u001B[38;5;124m'\u001B[39m]] \u001B[38;5;241m*\u001B[39m Y\u001B[38;5;241m.\u001B[39mshape[\u001B[38;5;241m0\u001B[39m],\n\u001B[0;32m   3419\u001B[0m                    device\u001B[38;5;241m=\u001B[39mdevice)\u001B[38;5;241m.\u001B[39mreshape(\u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m, \u001B[38;5;241m1\u001B[39m)\n\u001B[0;32m   3420\u001B[0m dec_input \u001B[38;5;241m=\u001B[39m d2l\u001B[38;5;241m.\u001B[39mconcat([bos, Y[:, :\u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m]], \u001B[38;5;241m1\u001B[39m)  \u001B[38;5;66;03m# Teacher forcing\u001B[39;00m\n\u001B[1;32m-> 3421\u001B[0m Y_hat, _ \u001B[38;5;241m=\u001B[39m net(X, dec_input, X_valid_len)\n\u001B[0;32m   3422\u001B[0m l \u001B[38;5;241m=\u001B[39m loss(Y_hat, Y, Y_valid_len)\n\u001B[0;32m   3423\u001B[0m l\u001B[38;5;241m.\u001B[39msum()\u001B[38;5;241m.\u001B[39mbackward()  \u001B[38;5;66;03m# Make the loss scalar for `backward`\u001B[39;00m\n",
      "\u001B[1;31mValueError\u001B[0m: too many values to unpack (expected 2)"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 350x250 with 1 Axes>"
      ],
      "image/svg+xml": "<?xml version=\"1.0\" encoding=\"utf-8\" standalone=\"no\"?>\n<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n  \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n<svg xmlns:xlink=\"http://www.w3.org/1999/xlink\" width=\"240.554688pt\" height=\"173.477344pt\" viewBox=\"0 0 240.554688 173.477344\" xmlns=\"http://www.w3.org/2000/svg\" version=\"1.1\">\n <metadata>\n  <rdf:RDF xmlns:dc=\"http://purl.org/dc/elements/1.1/\" xmlns:cc=\"http://creativecommons.org/ns#\" xmlns:rdf=\"http://www.w3.org/1999/02/22-rdf-syntax-ns#\">\n   <cc:Work>\n    <dc:type rdf:resource=\"http://purl.org/dc/dcmitype/StillImage\"/>\n    <dc:date>2025-05-28T17:29:36.432665</dc:date>\n    <dc:format>image/svg+xml</dc:format>\n    <dc:creator>\n     <cc:Agent>\n      <dc:title>Matplotlib v3.7.2, https://matplotlib.org/</dc:title>\n     </cc:Agent>\n    </dc:creator>\n   </cc:Work>\n  </rdf:RDF>\n </metadata>\n <defs>\n  <style type=\"text/css\">*{stroke-linejoin: round; stroke-linecap: butt}</style>\n </defs>\n <g id=\"figure_1\">\n  <g id=\"patch_1\">\n   <path d=\"M 0 173.477344 \nL 240.554688 173.477344 \nL 240.554688 0 \nL 0 0 \nz\n\" style=\"fill: #ffffff\"/>\n  </g>\n  <g id=\"axes_1\">\n   <g id=\"patch_2\">\n    <path d=\"M 30.103125 149.599219 \nL 225.403125 149.599219 \nL 225.403125 10.999219 \nL 30.103125 10.999219 \nz\n\" style=\"fill: #ffffff\"/>\n   </g>\n   <g id=\"matplotlib.axis_1\">\n    <g id=\"xtick_1\">\n     <g id=\"line2d_1\">\n      <defs>\n       <path id=\"m6eb8b74866\" d=\"M 0 0 \nL 0 3.5 \n\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </defs>\n      <g>\n       <use xlink:href=\"#m6eb8b74866\" x=\"30.103125\" y=\"149.599219\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_1\">\n      <!-- 0.0 -->\n      <g transform=\"translate(22.151563 164.197656) scale(0.1 -0.1)\">\n       <defs>\n        <path id=\"DejaVuSans-30\" d=\"M 2034 4250 \nQ 1547 4250 1301 3770 \nQ 1056 3291 1056 2328 \nQ 1056 1369 1301 889 \nQ 1547 409 2034 409 \nQ 2525 409 2770 889 \nQ 3016 1369 3016 2328 \nQ 3016 3291 2770 3770 \nQ 2525 4250 2034 4250 \nz\nM 2034 4750 \nQ 2819 4750 3233 4129 \nQ 3647 3509 3647 2328 \nQ 3647 1150 3233 529 \nQ 2819 -91 2034 -91 \nQ 1250 -91 836 529 \nQ 422 1150 422 2328 \nQ 422 3509 836 4129 \nQ 1250 4750 2034 4750 \nz\n\" transform=\"scale(0.015625)\"/>\n        <path id=\"DejaVuSans-2e\" d=\"M 684 794 \nL 1344 794 \nL 1344 0 \nL 684 0 \nL 684 794 \nz\n\" transform=\"scale(0.015625)\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-30\"/>\n       <use xlink:href=\"#DejaVuSans-2e\" x=\"63.623047\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"95.410156\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_2\">\n     <g id=\"line2d_2\">\n      <g>\n       <use xlink:href=\"#m6eb8b74866\" x=\"69.163125\" y=\"149.599219\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_2\">\n      <!-- 0.2 -->\n      <g transform=\"translate(61.211563 164.197656) scale(0.1 -0.1)\">\n       <defs>\n        <path id=\"DejaVuSans-32\" d=\"M 1228 531 \nL 3431 531 \nL 3431 0 \nL 469 0 \nL 469 531 \nQ 828 903 1448 1529 \nQ 2069 2156 2228 2338 \nQ 2531 2678 2651 2914 \nQ 2772 3150 2772 3378 \nQ 2772 3750 2511 3984 \nQ 2250 4219 1831 4219 \nQ 1534 4219 1204 4116 \nQ 875 4013 500 3803 \nL 500 4441 \nQ 881 4594 1212 4672 \nQ 1544 4750 1819 4750 \nQ 2544 4750 2975 4387 \nQ 3406 4025 3406 3419 \nQ 3406 3131 3298 2873 \nQ 3191 2616 2906 2266 \nQ 2828 2175 2409 1742 \nQ 1991 1309 1228 531 \nz\n\" transform=\"scale(0.015625)\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-30\"/>\n       <use xlink:href=\"#DejaVuSans-2e\" x=\"63.623047\"/>\n       <use xlink:href=\"#DejaVuSans-32\" x=\"95.410156\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_3\">\n     <g id=\"line2d_3\">\n      <g>\n       <use xlink:href=\"#m6eb8b74866\" x=\"108.223125\" y=\"149.599219\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_3\">\n      <!-- 0.4 -->\n      <g transform=\"translate(100.271563 164.197656) scale(0.1 -0.1)\">\n       <defs>\n        <path id=\"DejaVuSans-34\" d=\"M 2419 4116 \nL 825 1625 \nL 2419 1625 \nL 2419 4116 \nz\nM 2253 4666 \nL 3047 4666 \nL 3047 1625 \nL 3713 1625 \nL 3713 1100 \nL 3047 1100 \nL 3047 0 \nL 2419 0 \nL 2419 1100 \nL 313 1100 \nL 313 1709 \nL 2253 4666 \nz\n\" transform=\"scale(0.015625)\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-30\"/>\n       <use xlink:href=\"#DejaVuSans-2e\" x=\"63.623047\"/>\n       <use xlink:href=\"#DejaVuSans-34\" x=\"95.410156\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_4\">\n     <g id=\"line2d_4\">\n      <g>\n       <use xlink:href=\"#m6eb8b74866\" x=\"147.283125\" y=\"149.599219\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_4\">\n      <!-- 0.6 -->\n      <g transform=\"translate(139.331563 164.197656) scale(0.1 -0.1)\">\n       <defs>\n        <path id=\"DejaVuSans-36\" d=\"M 2113 2584 \nQ 1688 2584 1439 2293 \nQ 1191 2003 1191 1497 \nQ 1191 994 1439 701 \nQ 1688 409 2113 409 \nQ 2538 409 2786 701 \nQ 3034 994 3034 1497 \nQ 3034 2003 2786 2293 \nQ 2538 2584 2113 2584 \nz\nM 3366 4563 \nL 3366 3988 \nQ 3128 4100 2886 4159 \nQ 2644 4219 2406 4219 \nQ 1781 4219 1451 3797 \nQ 1122 3375 1075 2522 \nQ 1259 2794 1537 2939 \nQ 1816 3084 2150 3084 \nQ 2853 3084 3261 2657 \nQ 3669 2231 3669 1497 \nQ 3669 778 3244 343 \nQ 2819 -91 2113 -91 \nQ 1303 -91 875 529 \nQ 447 1150 447 2328 \nQ 447 3434 972 4092 \nQ 1497 4750 2381 4750 \nQ 2619 4750 2861 4703 \nQ 3103 4656 3366 4563 \nz\n\" transform=\"scale(0.015625)\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-30\"/>\n       <use xlink:href=\"#DejaVuSans-2e\" x=\"63.623047\"/>\n       <use xlink:href=\"#DejaVuSans-36\" x=\"95.410156\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_5\">\n     <g id=\"line2d_5\">\n      <g>\n       <use xlink:href=\"#m6eb8b74866\" x=\"186.343125\" y=\"149.599219\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_5\">\n      <!-- 0.8 -->\n      <g transform=\"translate(178.391563 164.197656) scale(0.1 -0.1)\">\n       <defs>\n        <path id=\"DejaVuSans-38\" d=\"M 2034 2216 \nQ 1584 2216 1326 1975 \nQ 1069 1734 1069 1313 \nQ 1069 891 1326 650 \nQ 1584 409 2034 409 \nQ 2484 409 2743 651 \nQ 3003 894 3003 1313 \nQ 3003 1734 2745 1975 \nQ 2488 2216 2034 2216 \nz\nM 1403 2484 \nQ 997 2584 770 2862 \nQ 544 3141 544 3541 \nQ 544 4100 942 4425 \nQ 1341 4750 2034 4750 \nQ 2731 4750 3128 4425 \nQ 3525 4100 3525 3541 \nQ 3525 3141 3298 2862 \nQ 3072 2584 2669 2484 \nQ 3125 2378 3379 2068 \nQ 3634 1759 3634 1313 \nQ 3634 634 3220 271 \nQ 2806 -91 2034 -91 \nQ 1263 -91 848 271 \nQ 434 634 434 1313 \nQ 434 1759 690 2068 \nQ 947 2378 1403 2484 \nz\nM 1172 3481 \nQ 1172 3119 1398 2916 \nQ 1625 2713 2034 2713 \nQ 2441 2713 2670 2916 \nQ 2900 3119 2900 3481 \nQ 2900 3844 2670 4047 \nQ 2441 4250 2034 4250 \nQ 1625 4250 1398 4047 \nQ 1172 3844 1172 3481 \nz\n\" transform=\"scale(0.015625)\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-30\"/>\n       <use xlink:href=\"#DejaVuSans-2e\" x=\"63.623047\"/>\n       <use xlink:href=\"#DejaVuSans-38\" x=\"95.410156\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_6\">\n     <g id=\"line2d_6\">\n      <g>\n       <use xlink:href=\"#m6eb8b74866\" x=\"225.403125\" y=\"149.599219\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_6\">\n      <!-- 1.0 -->\n      <g transform=\"translate(217.451563 164.197656) scale(0.1 -0.1)\">\n       <defs>\n        <path id=\"DejaVuSans-31\" d=\"M 794 531 \nL 1825 531 \nL 1825 4091 \nL 703 3866 \nL 703 4441 \nL 1819 4666 \nL 2450 4666 \nL 2450 531 \nL 3481 531 \nL 3481 0 \nL 794 0 \nL 794 531 \nz\n\" transform=\"scale(0.015625)\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-31\"/>\n       <use xlink:href=\"#DejaVuSans-2e\" x=\"63.623047\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"95.410156\"/>\n      </g>\n     </g>\n    </g>\n   </g>\n   <g id=\"matplotlib.axis_2\">\n    <g id=\"ytick_1\">\n     <g id=\"line2d_7\">\n      <defs>\n       <path id=\"mf5afe7f27c\" d=\"M 0 0 \nL -3.5 0 \n\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </defs>\n      <g>\n       <use xlink:href=\"#mf5afe7f27c\" x=\"30.103125\" y=\"149.599219\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_7\">\n      <!-- 0.0 -->\n      <g transform=\"translate(7.2 153.398438) scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-30\"/>\n       <use xlink:href=\"#DejaVuSans-2e\" x=\"63.623047\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"95.410156\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_2\">\n     <g id=\"line2d_8\">\n      <g>\n       <use xlink:href=\"#mf5afe7f27c\" x=\"30.103125\" y=\"121.879219\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_8\">\n      <!-- 0.2 -->\n      <g transform=\"translate(7.2 125.678438) scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-30\"/>\n       <use xlink:href=\"#DejaVuSans-2e\" x=\"63.623047\"/>\n       <use xlink:href=\"#DejaVuSans-32\" x=\"95.410156\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_3\">\n     <g id=\"line2d_9\">\n      <g>\n       <use xlink:href=\"#mf5afe7f27c\" x=\"30.103125\" y=\"94.159219\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_9\">\n      <!-- 0.4 -->\n      <g transform=\"translate(7.2 97.958438) scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-30\"/>\n       <use xlink:href=\"#DejaVuSans-2e\" x=\"63.623047\"/>\n       <use xlink:href=\"#DejaVuSans-34\" x=\"95.410156\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_4\">\n     <g id=\"line2d_10\">\n      <g>\n       <use xlink:href=\"#mf5afe7f27c\" x=\"30.103125\" y=\"66.439219\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_10\">\n      <!-- 0.6 -->\n      <g transform=\"translate(7.2 70.238438) scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-30\"/>\n       <use xlink:href=\"#DejaVuSans-2e\" x=\"63.623047\"/>\n       <use xlink:href=\"#DejaVuSans-36\" x=\"95.410156\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_5\">\n     <g id=\"line2d_11\">\n      <g>\n       <use xlink:href=\"#mf5afe7f27c\" x=\"30.103125\" y=\"38.719219\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_11\">\n      <!-- 0.8 -->\n      <g transform=\"translate(7.2 42.518438) scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-30\"/>\n       <use xlink:href=\"#DejaVuSans-2e\" x=\"63.623047\"/>\n       <use xlink:href=\"#DejaVuSans-38\" x=\"95.410156\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_6\">\n     <g id=\"line2d_12\">\n      <g>\n       <use xlink:href=\"#mf5afe7f27c\" x=\"30.103125\" y=\"10.999219\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_12\">\n      <!-- 1.0 -->\n      <g transform=\"translate(7.2 14.798438) scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-31\"/>\n       <use xlink:href=\"#DejaVuSans-2e\" x=\"63.623047\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"95.410156\"/>\n      </g>\n     </g>\n    </g>\n   </g>\n   <g id=\"patch_3\">\n    <path d=\"M 30.103125 149.599219 \nL 30.103125 10.999219 \n\" style=\"fill: none; stroke: #000000; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square\"/>\n   </g>\n   <g id=\"patch_4\">\n    <path d=\"M 225.403125 149.599219 \nL 225.403125 10.999219 \n\" style=\"fill: none; stroke: #000000; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square\"/>\n   </g>\n   <g id=\"patch_5\">\n    <path d=\"M 30.103125 149.599219 \nL 225.403125 149.599219 \n\" style=\"fill: none; stroke: #000000; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square\"/>\n   </g>\n   <g id=\"patch_6\">\n    <path d=\"M 30.103125 10.999219 \nL 225.403125 10.999219 \n\" style=\"fill: none; stroke: #000000; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square\"/>\n   </g>\n  </g>\n </g>\n</svg>\n"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 140
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "81cc56cdfd972945"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
