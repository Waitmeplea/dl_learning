{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-05-27T01:34:31.212089Z",
     "start_time": "2025-05-27T01:34:28.467687Z"
    }
   },
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from dplearning_second_part.limu_dplearning.utils.useful_func import masked_softmax"
   ],
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-27T09:17:03.572549Z",
     "start_time": "2025-05-27T09:17:03.562318Z"
    }
   },
   "cell_type": "code",
   "source": [
    "logit=torch.tensor([0.3,0.4])\n",
    "target=torch.tensor([1,1],dtype=torch.float)\n",
    "F.binary_cross_entropy_with_logits(logit,target)"
   ],
   "id": "18e7b29624619a09",
   "outputs": [],
   "execution_count": 60
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-27T09:17:03.771117Z",
     "start_time": "2025-05-27T09:17:03.736040Z"
    }
   },
   "cell_type": "code",
   "source": "F.binary_cross_entropy_with_logits(logit,target)",
   "id": "8fff9654be5b06d1",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.5337)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 61
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-27T09:26:04.328938Z",
     "start_time": "2025-05-27T09:26:04.323532Z"
    }
   },
   "cell_type": "code",
   "source": "F.sigmoid(torch.tensor([[0.3,0.4],[1,2]]))",
   "id": "7b473bbec71b8778",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.5744, 0.5987],\n",
       "        [0.7311, 0.8808]])"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 75
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-27T01:34:31.224848Z",
     "start_time": "2025-05-27T01:34:31.212089Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "# 位置编码\n",
    "class PositionalEncoding(nn.Module):\n",
    "    \"\"\"位置编码\"\"\"\n",
    "    def __init__(self, num_hiddens, dropout=0.1, max_len=1000):\n",
    "        super(PositionalEncoding, self).__init__()\n",
    "        # 创建一个足够长的P 长是指第2个维度 第一个维度应该是batch_size\n",
    "        # 每一个batch用的是一套位置编码 如果不用一套的话就无法学习到位置信息泛化能力极差\n",
    "        self.P=torch.zeros(1,max_len,num_hiddens)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        X=torch.arange(max_len,dtype=torch.float32).reshape(-1,1)/\\\n",
    "            torch.pow(10000,torch.arange(0,num_hiddens,2)/num_hiddens)\n",
    "        self.P[:,:,0::2]=torch.sin(X)\n",
    "        self.P[:,:,1::2]=torch.cos(X)\n",
    "    def forward(self, X):\n",
    "        X = X+self.P[:,:X.shape[1],:].to(X.device)\n",
    "        return self.dropout(X)\n",
    "\n",
    "\n",
    "# 先实现一个点积注意力\n",
    "class DotProductAttention(nn.Module):\n",
    "    def __init__(self, dropout=0.2):\n",
    "        super(DotProductAttention, self).__init__()\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.attention_weights = None\n",
    "    # q(b,step,embed_size)\n",
    "    # k(b,键值对个数,embed_size)\n",
    "    # v(b,键值对个数,embed_size)\n",
    "    def forward(self, q, k, v,valid_lens):\n",
    "        attn_weights = torch.bmm(q, k.transpose(1, 2))/torch.sqrt(torch.tensor(q.shape[-1]))\n",
    "        self.attention_weights=masked_softmax(attn_weights,valid_lens)\n",
    "        return torch.bmm(self.dropout(self.attention_weights), v)\n",
    "\n",
    "#@save\n",
    "class MultiHeadAttention(nn.Module):\n",
    "    \"\"\"多头注意力\"\"\"\n",
    "    # qkv各自的embed_size, 隐藏层大小 头数量\n",
    "    # 需要并行运算多个头 因此num_hiddens 必须能够整除以num_heads\n",
    "    def __init__(self,key_size,query_size,value_size,num_hiddens,num_heads,dropout,bias=False, **kwargs):\n",
    "        super(MultiHeadAttention, self).__init__(**kwargs)\n",
    "        self.num_heads = num_heads\n",
    "        self.attention = DotProductAttention(dropout)\n",
    "        self.W_q=nn.Linear(query_size,num_hiddens,bias=bias)\n",
    "        self.W_k=nn.Linear(key_size,num_hiddens,bias=bias)\n",
    "        self.W_v=nn.Linear(value_size,num_hiddens,bias=bias)\n",
    "        self.W_o=nn.Linear(num_hiddens,num_hiddens,bias=bias)\n",
    "\n",
    "    def forward(self, q, k, v,valid_lens=None):\n",
    "\n",
    "        queries=self.W_q(q)\n",
    "        keys=self.W_k(k)\n",
    "        values=self.W_v(v)\n",
    "\n",
    "        # 在这一步需要对qkv拆分为多头 并行计算attention\n",
    "        queries=queries.reshape(queries.shape[0],queries.shape[1],self.num_heads,-1).permute(0,2,1,3)\n",
    "        keys=keys.reshape(keys.shape[0],keys.shape[1],self.num_heads,-1).permute(0,2,1,3)\n",
    "        values=values.reshape(values.shape[0],values.shape[1],self.num_heads,-1).permute(0,2,1,3)\n",
    "\n",
    "        queries=queries.reshape(-1,queries.shape[2],queries.shape[3])\n",
    "        keys=keys.reshape(-1,keys.shape[2],keys.shape[3])\n",
    "        values=values.reshape(-1,values.shape[2],values.shape[3])\n",
    "\n",
    "        if valid_lens is not None:\n",
    "            # 在轴0，将第一项（标量或者矢量）复制num_heads次，\n",
    "            # 然后如此复制第二项，然后诸如此类。\n",
    "            valid_lens = torch.repeat_interleave(\n",
    "                valid_lens, repeats=self.num_heads, dim=0)\n",
    "\n",
    "        attn_weights=self.attention(queries,keys,values,valid_lens)\n",
    "        attn_weights=attn_weights.reshape(-1,self.num_heads,attn_weights.shape[1],attn_weights.shape[2])\n",
    "        attn_weights=attn_weights.permute(0,2,1,3)\n",
    "        attn_weights=attn_weights.reshape(attn_weights.shape[0],attn_weights.shape[1],-1)\n",
    "\n",
    "        return self.W_o(attn_weights)\n"
   ],
   "id": "d38ebef52929b469",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-27T01:34:31.230359Z",
     "start_time": "2025-05-27T01:34:31.224848Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class PositionWiseFFN(nn.Module):\n",
    "    \"\"\"基于位置的前馈网络\"\"\"\n",
    "    def __init__(self,ffn_num_input,ffn_num_hiddens,ffn_num_outputs,**kwargs):\n",
    "        super(PositionWiseFFN,self).__init__(**kwargs)\n",
    "        self.dense1=nn.Linear(ffn_num_input,ffn_num_hiddens)\n",
    "        self.relu=nn.ReLU()\n",
    "        self.dense2=nn.Linear(ffn_num_hiddens,ffn_num_outputs)\n",
    "    def forward(self,x):\n",
    "        return self.dense2(self.relu(self.dense1(x)))"
   ],
   "id": "5564bf4d2e4464d8",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-27T01:34:31.308848Z",
     "start_time": "2025-05-27T01:34:31.230359Z"
    }
   },
   "cell_type": "code",
   "source": [
    "ffn=PositionWiseFFN(ffn_num_input=4,ffn_num_hiddens=4,ffn_num_outputs=8)\n",
    "ffn.eval()\n",
    "ffn(torch.ones((2,3,4))).shape"
   ],
   "id": "1204f7b63ecc1632",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 3, 8])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-27T01:34:31.312629Z",
     "start_time": "2025-05-27T01:34:31.308848Z"
    }
   },
   "cell_type": "code",
   "source": "# 残差连接和层规范化",
   "id": "fc174191f0bf2b8b",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-27T01:34:31.324346Z",
     "start_time": "2025-05-27T01:34:31.312629Z"
    }
   },
   "cell_type": "code",
   "source": [
    "ln = nn.LayerNorm(2)\n",
    "bn = nn.BatchNorm1d(2)"
   ],
   "id": "7bd318b369af9d76",
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-27T01:34:31.372172Z",
     "start_time": "2025-05-27T01:34:31.324346Z"
    }
   },
   "cell_type": "code",
   "source": [
    "x=torch.tensor([[1,2],[2,3]],dtype=torch.float32)\n",
    "x,x.shape"
   ],
   "id": "ad278bb0ac7ab58d",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[1., 2.],\n",
       "         [2., 3.]]),\n",
       " torch.Size([2, 2]))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-27T01:56:02.079122Z",
     "start_time": "2025-05-27T01:56:02.075537Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 残差连接和层规范化\n",
    "class AddNorm(nn.Module):\n",
    "    def __init__(self,normalized_shape,dropout,**kwargs):\n",
    "        super(AddNorm,self).__init__()\n",
    "        self.dropout=nn.Dropout(dropout)\n",
    "        self.ln=nn.LayerNorm(normalized_shape)\n",
    "        \n",
    "    def forward(self,X,Y):\n",
    "        return self.ln(self.dropout(Y) + X)"
   ],
   "id": "d879ec795cb9e9c6",
   "outputs": [],
   "execution_count": 34
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-27T01:56:02.261342Z",
     "start_time": "2025-05-27T01:56:02.254110Z"
    }
   },
   "cell_type": "code",
   "source": [
    "add_norm = AddNorm([3, 4], 0.5)\n",
    "add_norm.eval()"
   ],
   "id": "a66677e2919f8b59",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AddNorm(\n",
       "  (dropout): Dropout(p=0.5, inplace=False)\n",
       "  (ln): LayerNorm((3, 4), eps=1e-05, elementwise_affine=True)\n",
       ")"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 35
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-27T01:56:02.476587Z",
     "start_time": "2025-05-27T01:56:02.454908Z"
    }
   },
   "cell_type": "code",
   "source": "add_norm(torch.ones((2, 3, 4)), torch.ones((2, 3, 4))).shape",
   "id": "acc33c8074dfc490",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 3, 4])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 36
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-27T01:56:03.072846Z",
     "start_time": "2025-05-27T01:56:03.064199Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class EncoderBlock(nn.Module):\n",
    "    def __init__(self,key_size,query_size,value_size,num_hiddens,norm_shape\n",
    "                 ,ffn_num_input,ffn_num_hiddens,num_heads,dropout,use_bias=False,**kwargs):\n",
    "        super(EncoderBlock,self).__init__()\n",
    "        self.attention = MultiHeadAttention(key_size,query_size,value_size,num_hiddens,num_heads,dropout,bias=use_bias)\n",
    "        self.addnorm1=AddNorm(norm_shape, dropout)\n",
    "        self.ffn = PositionWiseFFN(ffn_num_input,ffn_num_hiddens,num_hiddens,**kwargs)\n",
    "        self.addnorm2=AddNorm(norm_shape, dropout)\n",
    "        \n",
    "    def forward(self,X,valid_lens):\n",
    "        Y=self.addnorm1(X,self.attention(X,X,X,valid_lens))\n",
    "        return self.addnorm2(Y,self.ffn(Y))"
   ],
   "id": "d7cc7bfcb9c9e3e9",
   "outputs": [],
   "execution_count": 37
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-27T01:56:03.487667Z",
     "start_time": "2025-05-27T01:56:03.478410Z"
    }
   },
   "cell_type": "code",
   "source": [
    "x=torch.ones((2,100,24))\n",
    "valid_lens=torch.tensor([3,2])\n",
    "encoder_blk=EncoderBlock(key_size=24,query_size=24,value_size=24,num_hiddens=24,norm_shape=[100,24],ffn_num_input=24,ffn_num_hiddens=48,num_heads=8,dropout=0.5)\n",
    "encoder_blk.eval()"
   ],
   "id": "b00281a03e505be3",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "EncoderBlock(\n",
       "  (attention): MultiHeadAttention(\n",
       "    (attention): DotProductAttention(\n",
       "      (dropout): Dropout(p=0.5, inplace=False)\n",
       "    )\n",
       "    (W_q): Linear(in_features=24, out_features=24, bias=False)\n",
       "    (W_k): Linear(in_features=24, out_features=24, bias=False)\n",
       "    (W_v): Linear(in_features=24, out_features=24, bias=False)\n",
       "    (W_o): Linear(in_features=24, out_features=24, bias=False)\n",
       "  )\n",
       "  (addnorm1): AddNorm(\n",
       "    (dropout): Dropout(p=0.5, inplace=False)\n",
       "    (ln): LayerNorm((100, 24), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       "  (ffn): PositionWiseFFN(\n",
       "    (dense1): Linear(in_features=24, out_features=48, bias=True)\n",
       "    (relu): ReLU()\n",
       "    (dense2): Linear(in_features=48, out_features=24, bias=True)\n",
       "  )\n",
       "  (addnorm2): AddNorm(\n",
       "    (dropout): Dropout(p=0.5, inplace=False)\n",
       "    (ln): LayerNorm((100, 24), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 38
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-27T01:56:04.035153Z",
     "start_time": "2025-05-27T01:56:03.954526Z"
    }
   },
   "cell_type": "code",
   "source": "encoder_blk(x,valid_lens).shape",
   "id": "1ca9657b5a63e5bc",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 100, 24])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 39
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-27T02:00:37.300864Z",
     "start_time": "2025-05-27T02:00:37.292399Z"
    }
   },
   "cell_type": "code",
   "source": "encoder_blk.attention.attention.attention_weights",
   "id": "e8ed2966391c7a71",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0.3333, 0.3333, 0.3333,  ..., 0.0000, 0.0000, 0.0000],\n",
       "         [0.3333, 0.3333, 0.3333,  ..., 0.0000, 0.0000, 0.0000],\n",
       "         [0.3333, 0.3333, 0.3333,  ..., 0.0000, 0.0000, 0.0000],\n",
       "         ...,\n",
       "         [0.3333, 0.3333, 0.3333,  ..., 0.0000, 0.0000, 0.0000],\n",
       "         [0.3333, 0.3333, 0.3333,  ..., 0.0000, 0.0000, 0.0000],\n",
       "         [0.3333, 0.3333, 0.3333,  ..., 0.0000, 0.0000, 0.0000]],\n",
       "\n",
       "        [[0.3333, 0.3333, 0.3333,  ..., 0.0000, 0.0000, 0.0000],\n",
       "         [0.3333, 0.3333, 0.3333,  ..., 0.0000, 0.0000, 0.0000],\n",
       "         [0.3333, 0.3333, 0.3333,  ..., 0.0000, 0.0000, 0.0000],\n",
       "         ...,\n",
       "         [0.3333, 0.3333, 0.3333,  ..., 0.0000, 0.0000, 0.0000],\n",
       "         [0.3333, 0.3333, 0.3333,  ..., 0.0000, 0.0000, 0.0000],\n",
       "         [0.3333, 0.3333, 0.3333,  ..., 0.0000, 0.0000, 0.0000]],\n",
       "\n",
       "        [[0.3333, 0.3333, 0.3333,  ..., 0.0000, 0.0000, 0.0000],\n",
       "         [0.3333, 0.3333, 0.3333,  ..., 0.0000, 0.0000, 0.0000],\n",
       "         [0.3333, 0.3333, 0.3333,  ..., 0.0000, 0.0000, 0.0000],\n",
       "         ...,\n",
       "         [0.3333, 0.3333, 0.3333,  ..., 0.0000, 0.0000, 0.0000],\n",
       "         [0.3333, 0.3333, 0.3333,  ..., 0.0000, 0.0000, 0.0000],\n",
       "         [0.3333, 0.3333, 0.3333,  ..., 0.0000, 0.0000, 0.0000]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[0.5000, 0.5000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "         [0.5000, 0.5000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "         [0.5000, 0.5000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "         ...,\n",
       "         [0.5000, 0.5000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "         [0.5000, 0.5000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "         [0.5000, 0.5000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]],\n",
       "\n",
       "        [[0.5000, 0.5000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "         [0.5000, 0.5000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "         [0.5000, 0.5000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "         ...,\n",
       "         [0.5000, 0.5000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "         [0.5000, 0.5000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "         [0.5000, 0.5000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]],\n",
       "\n",
       "        [[0.5000, 0.5000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "         [0.5000, 0.5000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "         [0.5000, 0.5000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "         ...,\n",
       "         [0.5000, 0.5000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "         [0.5000, 0.5000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "         [0.5000, 0.5000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]]],\n",
       "       grad_fn=<SoftmaxBackward0>)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 54
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-27T02:02:43.519943Z",
     "start_time": "2025-05-27T02:02:43.513577Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class TransformerEncoder(nn.Module):\n",
    "    def __init__(self, vocab_size, key_size, query_size, value_size,\n",
    "                 num_hiddens, norm_shape, ffn_num_input, ffn_num_hiddens,\n",
    "                 num_heads, num_layers, dropout, use_bias=False, **kwargs):\n",
    "        super(TransformerEncoder,self).__init__()\n",
    "        self.num_hiddens = num_hiddens\n",
    "        self.embedding = nn.Embedding(vocab_size,num_hiddens)\n",
    "        self.pos_encoding=PositionalEncoding(num_hiddens,dropout)\n",
    "        self.blks=nn.Sequential()\n",
    "        for i in range(num_layers):\n",
    "            self.blks.add_module('block'+str(i)\n",
    "                                 ,EncoderBlock(key_size,query_size,value_size,num_hiddens\n",
    "                                               ,norm_shape,ffn_num_input,ffn_num_hiddens\n",
    "                                               ,num_heads,dropout,use_bias))\n",
    "    def forward(self,X,valid_lens,*args):\n",
    "        # 因为位置编码值在-1和1之间，\n",
    "        # 因此嵌入值乘以嵌入维度的平方根进行缩放， 因为嵌入层会把整个层的元素都压缩在均值为0方差为1的分布中 \n",
    "        # 因此当num_hiddens越大单个值会越小所以这么乘 保证每个元素也是在-1 1之间\n",
    "        # 然后再与位置编码相加。\n",
    "        X=self.pos_encoding(self.embedding(X)*torch.sqrt(torch.tensor(self.num_hiddens)))\n",
    "        self.attention_weights = [None] * len(self.blks)\n",
    "        for i, blk in enumerate(self.blks):\n",
    "            X = blk(X, valid_lens)\n",
    "            self.attention_weights[\n",
    "                i] = blk.attention.attention.attention_weights\n",
    "        return X"
   ],
   "id": "5e5c0f360463c19c",
   "outputs": [],
   "execution_count": 56
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-27T02:02:43.673745Z",
     "start_time": "2025-05-27T02:02:43.658743Z"
    }
   },
   "cell_type": "code",
   "source": [
    "encoder = TransformerEncoder(\n",
    "    200, 24, 24, 24, 24, [100, 24], 24, 48, 8, 2, 0.5)\n",
    "encoder.eval()\n",
    "encoder(torch.ones((2, 100), dtype=torch.long), valid_lens).shape"
   ],
   "id": "ac16a9590078dc5b",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 100, 24])"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 57
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "class DecoderBlock(nn.Module):\n",
    "    \"\"\"解码器中的第i个块\"\"\"\n",
    "    def __init__(self,key_size,query_size,value_size,num_hiddens,norm_shape\n",
    "                 ,ffn_num_input,ffn_num_hiddens,num_heads,dropout,i,**kwargs):\n",
    "        super(DecoderBlock,self).__init__()\n",
    "        self.i=i\n",
    "        self.attention1=MultiHeadAttention(key_size,query_size,value_size,num_hiddens,num_heads,dropout)\n",
    "        self.addnorm1=AddNorm(norm_shape, dropout)\n",
    "        self.attention2=MultiHeadAttention(key_size,query_size,value_size,num_hiddens,num_heads,dropout)\n",
    "        self.addnorm2=AddNorm(norm_shape,dropout)\n",
    "        self.ffn=PositionWiseFFN(ffn_num_input,ffn_num_hiddens,num_hiddens,**kwargs)\n",
    "        self.addnorm3=AddNorm(norm_shape, dropout)\n",
    "    def forward(self,X,state):\n",
    "        "
   ],
   "id": "ea5997d91b547af8"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "cda15a056a26b8e7"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "79fc0e521b575fe3"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
