{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-05-19T07:45:00.960801Z",
     "start_time": "2025-05-19T07:44:54.605576Z"
    }
   },
   "source": [
    "import os\n",
    "import torch\n",
    "import requests\n",
    "import matplotlib.pyplot as plt\n",
    "from torch import nn\n",
    "from utils.useful_func import *"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-19T07:45:00.966604Z",
     "start_time": "2025-05-19T07:45:00.962806Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def read_data_nmt():\n",
    "    with open(r'../data/fra-eng/fra.txt','r',encoding='utf-8') as f:\n",
    "        result=f.read()\n",
    "    return result"
   ],
   "id": "e8584bf9f8c87c92",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-19T07:45:00.973098Z",
     "start_time": "2025-05-19T07:45:00.967605Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#@save\n",
    "def preprocess_nmt(text):\n",
    "    \"\"\"预处理“英语－法语”数据集\"\"\"\n",
    "    def no_space(char, prev_char):\n",
    "        return char in set(',.!?') and prev_char != ' '\n",
    "\n",
    "    # 使用空格替换不间断空格\n",
    "    # 使用小写字母替换大写字母\n",
    "    text = text.replace('\\u202f', ' ').replace('\\xa0', ' ').lower()\n",
    "    # 在单词和标点符号之间插入空格\n",
    "    out = [' ' + char if i > 0 and no_space(char, text[i - 1]) else char\n",
    "           for i, char in enumerate(text)]\n",
    "    return ''.join(out)\n"
   ],
   "id": "be316cc948eefba1",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-19T07:45:00.977865Z",
     "start_time": "2025-05-19T07:45:00.974116Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def tokenize_nmt(text,num_examples=None):\n",
    "    source,target=[],[]\n",
    "    for i,line in enumerate(text.split('\\n')):\n",
    "        if num_examples and i>=num_examples:\n",
    "            break\n",
    "        parts=line.split('\\t')\n",
    "        ## 必须得有原始和目标值所以长度得为2\n",
    "        if len(parts)==2:\n",
    "            source.append(parts[0].split(' '))\n",
    "            target.append(parts[1].split(' '))\n",
    "    return source,target"
   ],
   "id": "8d956ae399db370f",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-19T07:45:00.981717Z",
     "start_time": "2025-05-19T07:45:00.978872Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#@save\n",
    "def truncate_pad(line, num_steps, padding_token):\n",
    "    \"\"\"截断或填充文本序列\"\"\"\n",
    "    if len(line) >= num_steps:\n",
    "        return line[:num_steps]\n",
    "    return line+[padding_token]*(num_steps-len(line))"
   ],
   "id": "c6b145523ac3ed13",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-19T07:45:00.986530Z",
     "start_time": "2025-05-19T07:45:00.982743Z"
    }
   },
   "cell_type": "code",
   "source": [
    "## 将文本数据作为批量数据，并且加入<eos>至末尾 同时统计有效字符 包含eos\n",
    "def build_array_nmt(lines, vocab, num_steps):\n",
    "    lines=[vocab[i] for i in lines]\n",
    "    lines=[i+[vocab['<eos>']] for i in lines]\n",
    "    array=torch.tensor([truncate_pad(i,num_steps,vocab['<pad>']) for i in lines])\n",
    "    valid_len =(array != vocab['<pad>']).type(torch.int32).sum(dim=1)\n",
    "    return array, valid_len"
   ],
   "id": "711acc7a42a43e0c",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-19T07:45:00.992837Z",
     "start_time": "2025-05-19T07:45:00.986530Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def load_data_nmt(batch_size, num_steps, num_examples=600):\n",
    "    ## 结果是原始列表 列表表长度 目标列表 目标列表长度\n",
    "    source, target = tokenize_nmt(preprocess_nmt(read_data_nmt()), num_examples)\n",
    "    src_vocab = Vocal(source, min_feq=2,\n",
    "                              reserved_tokens=['<pad>', '<bos>', '<eos>'])\n",
    "    tgt_vocab = Vocal(target, min_feq=2,\n",
    "                              reserved_tokens=['<pad>', '<bos>', '<eos>'])\n",
    "    src_array, src_valid_len = build_array_nmt(source, src_vocab, num_steps)\n",
    "    tgt_array, tgt_valid_len = build_array_nmt(target, tgt_vocab, num_steps)\n",
    "    data_arrays = (src_array, src_valid_len, tgt_array, tgt_valid_len)\n",
    "    dataset = torch.utils.data.TensorDataset(*data_arrays)\n",
    "    return torch.utils.data.DataLoader(dataset, batch_size=batch_size,shuffle=True),src_vocab, tgt_vocab"
   ],
   "id": "7d8fcabe788475d2",
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-19T07:45:00.998233Z",
     "start_time": "2025-05-19T07:45:00.993846Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class Encoder(nn.Module):\n",
    "    \"\"\"编码器—解码器架构的基本编码器接口\"\"\"\n",
    "    def __init__(self, **kwargs):\n",
    "        super(Encoder, self).__init__(**kwargs)\n",
    "    def forward(self, X,*args):\n",
    "        raise NotImplementedError\n",
    "\n",
    "class Decoder(nn.Module):\n",
    "    \"\"\"编码器-解码器架构的基本解码器接口\"\"\"\n",
    "    def __init__(self,**kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "    \n",
    "    def init_state(self,enc_outputs,*args):\n",
    "        raise NotImplementedError\n",
    "    \n",
    "    def forward(self,X,state):\n",
    "        raise NotImplementedError"
   ],
   "id": "a31d3e796ebf702a",
   "outputs": [],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-19T07:45:01.003827Z",
     "start_time": "2025-05-19T07:45:00.999290Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "\n",
    "class EncoderDecoder(nn.Module):\n",
    "    def __init__(self,encoder,decoder,**kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "    def forward(self, enc_X, dec_X, *args):\n",
    "        enc_outputs = self.encoder(enc_X)\n",
    "        dec_state=self.decoder.init_state(enc_outputs,*args)\n",
    "        return self.decoder(dec_X,dec_state)\n",
    "        "
   ],
   "id": "c12b2c8281935fbb",
   "outputs": [],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-19T07:45:05.845074Z",
     "start_time": "2025-05-19T07:45:01.004829Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import collections\n",
    "import math\n",
    "import torch\n",
    "from torch import nn\n",
    "from d2l import torch as d2l"
   ],
   "id": "b3a63b14d92ad739",
   "outputs": [],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-19T07:45:05.855346Z",
     "start_time": "2025-05-19T07:45:05.846083Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class Seq2SeqEncoder(Encoder):\n",
    "    def __init__(self,vocab_size,embed_size,num_hiddens,num_layers,dropout=0,**kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        # 嵌入层\n",
    "        self.embedding = nn.Embedding(vocab_size,embed_size)\n",
    "        self.rnn = nn.GRU(embed_size,num_hiddens,num_layers,dropout=dropout)\n",
    "        \n",
    "    def forward(self, X, *args):\n",
    "        # 输出'X'的形状：(batch_size,num_steps,embed_size)\n",
    "        X = self.embedding(X)\n",
    "        # 在循环神经网络模型中，第一个轴对应于时间步\n",
    "        X = X.permute(1, 0, 2)\n",
    "        ## 无初始状态则初始状态为0\n",
    "        output, state = self.rnn(X)\n",
    "        return output, state\n",
    "        \n",
    "\n",
    "class Seq2SeqDecoder(Decoder):\n",
    "    def __init__(self,vocab_size,embed_size,num_hiddens,num_layers,dropout=0,**kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.embedding = nn.Embedding(vocab_size,embed_size)\n",
    "        self.rnn=nn.GRU(embed_size + num_hiddens,num_hiddens,num_layers,dropout=dropout)\n",
    "        self.dense=nn.Linear(num_hiddens,vocab_size)\n",
    "        \n",
    "    def init_state(self,enc_outputs,*args):\n",
    "        return enc_outputs[1]\n",
    "    \n",
    "    def forward(self,X,dec_state):\n",
    "        # 传入的x是 batch_size 时间步 向量大小\n",
    "        X=(self.embedding(X))\n",
    "        X=X.permute(1, 0, 2)\n",
    "        # 广播context，使state最后时刻最后一层 具有与X相同的num_steps\n",
    "        context=dec_state[-1].repeat(X.shape[0],1,1)\n",
    "        X_and_context=torch.cat((X,context),dim=-1)\n",
    "        output,state=self.rnn(X_and_context,dec_state)\n",
    "        # output的形状:(batch_size,num_steps,vocab_size)\n",
    "        output=self.dense(output).permute(1,0,2)\n",
    "        # state的形状:(num_layers,batch_size,num_hiddens)\n",
    "        return output,state\n",
    "        "
   ],
   "id": "b792b46249d5a1fa",
   "outputs": [],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-19T07:45:05.870389Z",
     "start_time": "2025-05-19T07:45:05.857534Z"
    }
   },
   "cell_type": "code",
   "source": [
    "encoder=Seq2SeqEncoder(10,8,16,2)\n",
    "encoder.eval()\n",
    "X=torch.zeros((4,7),dtype=torch.long)\n",
    "output,state=encoder(X)\n",
    "## 7是时间步 4是batch_size, 16是隐藏层维度\n",
    "output.shape\n",
    "## 层数 batch_size 隐藏层维度\n",
    "# state.shape"
   ],
   "id": "10933595fc271f6f",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([7, 4, 16])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-19T07:45:05.884309Z",
     "start_time": "2025-05-19T07:45:05.871391Z"
    }
   },
   "cell_type": "code",
   "source": [
    "decoder = Seq2SeqDecoder(vocab_size=10, embed_size=8, num_hiddens=16,\n",
    "                         num_layers=2)\n",
    "\n",
    "dec_state=decoder.init_state(encoder(X))\n",
    "output,state=decoder.forward(X,dec_state)\n",
    "## 4，7，10 4是batch_size 最后一个维度是词表大小 进行softmax之后 就是4 7 7是约定的时间步大小但是实际需要的会比这个要小\n",
    "output.shape"
   ],
   "id": "e7a9fd508e298fbc",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 7, 10])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 13
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-19T07:45:05.892047Z",
     "start_time": "2025-05-19T07:45:05.886313Z"
    }
   },
   "cell_type": "code",
   "source": "state.shape",
   "id": "a61505e5d351ba56",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 4, 16])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 14
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "损失函数",
   "id": "aa5bf544589daf06"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-19T07:45:05.903310Z",
     "start_time": "2025-05-19T07:45:05.895050Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def sequence_mask(X,valid_len,value=0):\n",
    "    \"\"\"在序列中屏蔽不相关的项\"\"\"\n",
    "    # 首先x是二维的 最内层维度是句子长度 注意：是训练集所以才知道句子真实长度\n",
    "    # 拿出总的长度 得到长度\n",
    "    maxlen = X.shape[1]\n",
    "    # 然后用总长度生成一个1维的向量 使用函数扩展成2维以便与valid_len进行广播\n",
    "    mask=torch.unsqueeze(torch.arange(0, maxlen, dtype=torch.long),dim=0)\n",
    "    # mask在0维度扩充 valid在1维度扩充 因为每一个valid对应的是每一个x valid的数字其实是x的第二维向量\n",
    "    mask=(mask<torch.unsqueeze(valid_len,dim=1)) # 这里小于号就够了 因为<eos>所在位置的索引其实是valid_len-1\n",
    "    X[~mask]=value\n",
    "    return X\n",
    "\n",
    "# 拓展的softmax因为对填充值进行softmax其实没有什么意义\n",
    "class MaskedSoftmaxCELoss(nn.CrossEntropyLoss):\n",
    "    def forward(self, pred, label,valid_len):\n",
    "        weights=torch.ones_like(label)\n",
    "        weights=sequence_mask(weights,valid_len)\n",
    "        self.reduction='none'\n",
    "        pred=pred.permute(0,2,1)\n",
    "        unweight_loss=super().forward(pred,label)\n",
    "        weights_loss=unweight_loss*weights\n",
    "        return weights_loss.mean(dim=1)\n",
    "        "
   ],
   "id": "6de45bcca82396c2",
   "outputs": [],
   "execution_count": 15
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-19T07:45:05.907064Z",
     "start_time": "2025-05-19T07:45:05.904313Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "468fbd458cb0a875",
   "outputs": [],
   "execution_count": 15
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# 训练",
   "id": "78132e8fcaba474d"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-19T07:45:30.511476Z",
     "start_time": "2025-05-19T07:45:30.503074Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def train_seq2seq(net, train_iter, lr, num_epochs, tgt_vocab, device):\n",
    "    def xavier_init_weights(m):\n",
    "        if type(m) == nn.Linear:\n",
    "            nn.init.xavier_uniform_(m.weight)\n",
    "        if type(m) == nn.GRU:\n",
    "            for param in m._flat_weights_names:\n",
    "                if \"weight\" in param:\n",
    "                    nn.init.xavier_uniform_(m._parameters[param])\n",
    "    net.apply(xavier_init_weights)\n",
    "    net.to(device)\n",
    "    optimizer=torch.optim.Adam(net.parameters(), lr=lr)\n",
    "    loss = MaskedSoftmaxCELoss()\n",
    "    # 进入训练模式\n",
    "    net.train()\n",
    "    animator = Animator(xlabel='epoch', ylabel='loss',\n",
    "                         xlim=[10, num_epochs])\n",
    "    for epoch in range(num_epochs):\n",
    "        timer=Timer()\n",
    "        metric=Accumulator(2)\n",
    "        for batch in train_iter:\n",
    "            optimizer.zero_grad()\n",
    "            X, X_valid_len, Y, Y_valid_len = [x.to(device) for x in batch]\n",
    "            bos=torch.tensor([tgt_vocab['<bos>']]*Y.shape[0],device=device).reshape(-1,1)\n",
    "            dec_input=torch.cat([bos,Y[:,:-1]],dim=1)\n",
    "            y_hat,_=net(X,dec_input,X_valid_len)\n",
    "            print(y_hat.shape,Y.shape)\n",
    "            l = loss(y_hat,Y,Y_valid_len)\n",
    "            l.sum().backward()\n",
    "            grad_clipping(net,1)\n",
    "            optimizer.step()\n",
    "            num_tokens=Y_valid_len.sum()\n",
    "            with torch.no_grad():\n",
    "                metric.add(l.sum(), num_tokens)\n",
    "        if (epoch + 1) % 10 == 0:\n",
    "            animator.add(epoch + 1, (metric[0] / metric[1],))\n",
    "    print(f'loss {metric[0] / metric[1]:.3f}, {metric[1] / timer.stop():.1f} '\n",
    "        f'tokens/sec on {str(device)}')\n",
    "embed_size, num_hiddens, num_layers, dropout = 32, 32, 2, 0.1\n",
    "batch_size, num_steps = 64, 10\n",
    "lr, num_epochs, device = 0.005, 300, 'cpu'\n",
    "\n",
    "train_iter, src_vocab, tgt_vocab = load_data_nmt(batch_size, num_steps)\n",
    "encoder = Seq2SeqEncoder(len(src_vocab), embed_size, num_hiddens, num_layers,\n",
    "                        dropout)\n",
    "decoder = Seq2SeqDecoder(len(tgt_vocab), embed_size, num_hiddens, num_layers,\n",
    "                        dropout)\n",
    "net = EncoderDecoder(encoder, decoder)\n",
    "train_seq2seq(net, train_iter, lr, num_epochs, tgt_vocab, device)\n",
    "net.eval()"
   ],
   "id": "dfcaebfda3257cf9",
   "outputs": [],
   "execution_count": 16
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-19T07:45:40.498288Z",
     "start_time": "2025-05-19T07:45:34.074192Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "965f1c05eba68de4",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 10, 201]) torch.Size([64, 10])\n",
      "torch.Size([64, 10, 201]) torch.Size([64, 10])\n",
      "torch.Size([64, 10, 201]) torch.Size([64, 10])\n",
      "torch.Size([64, 10, 201]) torch.Size([64, 10])\n",
      "torch.Size([64, 10, 201]) torch.Size([64, 10])\n",
      "torch.Size([64, 10, 201]) torch.Size([64, 10])\n",
      "torch.Size([64, 10, 201]) torch.Size([64, 10])\n",
      "torch.Size([64, 10, 201]) torch.Size([64, 10])\n",
      "torch.Size([64, 10, 201]) torch.Size([64, 10])\n",
      "torch.Size([24, 10, 201]) torch.Size([24, 10])\n",
      "torch.Size([64, 10, 201]) torch.Size([64, 10])\n",
      "torch.Size([64, 10, 201]) torch.Size([64, 10])\n",
      "torch.Size([64, 10, 201]) torch.Size([64, 10])\n",
      "torch.Size([64, 10, 201]) torch.Size([64, 10])\n",
      "torch.Size([64, 10, 201]) torch.Size([64, 10])\n",
      "torch.Size([64, 10, 201]) torch.Size([64, 10])\n",
      "torch.Size([64, 10, 201]) torch.Size([64, 10])\n",
      "torch.Size([64, 10, 201]) torch.Size([64, 10])\n",
      "torch.Size([64, 10, 201]) torch.Size([64, 10])\n",
      "torch.Size([24, 10, 201]) torch.Size([24, 10])\n",
      "torch.Size([64, 10, 201]) torch.Size([64, 10])\n",
      "torch.Size([64, 10, 201]) torch.Size([64, 10])\n",
      "torch.Size([64, 10, 201]) torch.Size([64, 10])\n",
      "torch.Size([64, 10, 201]) torch.Size([64, 10])\n",
      "torch.Size([64, 10, 201]) torch.Size([64, 10])\n",
      "torch.Size([64, 10, 201]) torch.Size([64, 10])\n",
      "torch.Size([64, 10, 201]) torch.Size([64, 10])\n",
      "torch.Size([64, 10, 201]) torch.Size([64, 10])\n",
      "torch.Size([64, 10, 201]) torch.Size([64, 10])\n",
      "torch.Size([24, 10, 201]) torch.Size([24, 10])\n",
      "torch.Size([64, 10, 201]) torch.Size([64, 10])\n",
      "torch.Size([64, 10, 201]) torch.Size([64, 10])\n",
      "torch.Size([64, 10, 201]) torch.Size([64, 10])\n",
      "torch.Size([64, 10, 201]) torch.Size([64, 10])\n",
      "torch.Size([64, 10, 201]) torch.Size([64, 10])\n",
      "torch.Size([64, 10, 201]) torch.Size([64, 10])\n",
      "torch.Size([64, 10, 201]) torch.Size([64, 10])\n",
      "torch.Size([64, 10, 201]) torch.Size([64, 10])\n",
      "torch.Size([64, 10, 201]) torch.Size([64, 10])\n",
      "torch.Size([24, 10, 201]) torch.Size([24, 10])\n",
      "torch.Size([64, 10, 201]) torch.Size([64, 10])\n",
      "torch.Size([64, 10, 201]) torch.Size([64, 10])\n",
      "torch.Size([64, 10, 201]) torch.Size([64, 10])\n",
      "torch.Size([64, 10, 201]) torch.Size([64, 10])\n",
      "torch.Size([64, 10, 201]) torch.Size([64, 10])\n",
      "torch.Size([64, 10, 201]) torch.Size([64, 10])\n",
      "torch.Size([64, 10, 201]) torch.Size([64, 10])\n",
      "torch.Size([64, 10, 201]) torch.Size([64, 10])\n",
      "torch.Size([64, 10, 201]) torch.Size([64, 10])\n",
      "torch.Size([24, 10, 201]) torch.Size([24, 10])\n",
      "torch.Size([64, 10, 201]) torch.Size([64, 10])\n",
      "torch.Size([64, 10, 201]) torch.Size([64, 10])\n",
      "torch.Size([64, 10, 201]) torch.Size([64, 10])\n",
      "torch.Size([64, 10, 201]) torch.Size([64, 10])\n",
      "torch.Size([64, 10, 201]) torch.Size([64, 10])\n",
      "torch.Size([64, 10, 201]) torch.Size([64, 10])\n",
      "torch.Size([64, 10, 201]) torch.Size([64, 10])\n",
      "torch.Size([64, 10, 201]) torch.Size([64, 10])\n",
      "torch.Size([64, 10, 201]) torch.Size([64, 10])\n",
      "torch.Size([24, 10, 201]) torch.Size([24, 10])\n",
      "torch.Size([64, 10, 201]) torch.Size([64, 10])\n",
      "torch.Size([64, 10, 201]) torch.Size([64, 10])\n",
      "torch.Size([64, 10, 201]) torch.Size([64, 10])\n",
      "torch.Size([64, 10, 201]) torch.Size([64, 10])\n",
      "torch.Size([64, 10, 201]) torch.Size([64, 10])\n",
      "torch.Size([64, 10, 201]) torch.Size([64, 10])\n",
      "torch.Size([64, 10, 201]) torch.Size([64, 10])\n",
      "torch.Size([64, 10, 201]) torch.Size([64, 10])\n",
      "torch.Size([64, 10, 201]) torch.Size([64, 10])\n",
      "torch.Size([24, 10, 201]) torch.Size([24, 10])\n",
      "torch.Size([64, 10, 201]) torch.Size([64, 10])\n",
      "torch.Size([64, 10, 201]) torch.Size([64, 10])\n",
      "torch.Size([64, 10, 201]) torch.Size([64, 10])\n",
      "torch.Size([64, 10, 201]) torch.Size([64, 10])\n",
      "torch.Size([64, 10, 201]) torch.Size([64, 10])\n",
      "torch.Size([64, 10, 201]) torch.Size([64, 10])\n",
      "torch.Size([64, 10, 201]) torch.Size([64, 10])\n",
      "torch.Size([64, 10, 201]) torch.Size([64, 10])\n",
      "torch.Size([64, 10, 201]) torch.Size([64, 10])\n",
      "torch.Size([24, 10, 201]) torch.Size([24, 10])\n",
      "torch.Size([64, 10, 201]) torch.Size([64, 10])\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[17], line 11\u001B[0m\n\u001B[0;32m      8\u001B[0m decoder \u001B[38;5;241m=\u001B[39m Seq2SeqDecoder(\u001B[38;5;28mlen\u001B[39m(tgt_vocab), embed_size, num_hiddens, num_layers,\n\u001B[0;32m      9\u001B[0m                         dropout)\n\u001B[0;32m     10\u001B[0m net \u001B[38;5;241m=\u001B[39m EncoderDecoder(encoder, decoder)\n\u001B[1;32m---> 11\u001B[0m \u001B[43mtrain_seq2seq\u001B[49m\u001B[43m(\u001B[49m\u001B[43mnet\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtrain_iter\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mlr\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mnum_epochs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtgt_vocab\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdevice\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     12\u001B[0m net\u001B[38;5;241m.\u001B[39meval()\n",
      "Cell \u001B[1;32mIn[16], line 25\u001B[0m, in \u001B[0;36mtrain_seq2seq\u001B[1;34m(net, train_iter, lr, num_epochs, tgt_vocab, device)\u001B[0m\n\u001B[0;32m     23\u001B[0m bos\u001B[38;5;241m=\u001B[39mtorch\u001B[38;5;241m.\u001B[39mtensor([tgt_vocab[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m<bos>\u001B[39m\u001B[38;5;124m'\u001B[39m]]\u001B[38;5;241m*\u001B[39mY\u001B[38;5;241m.\u001B[39mshape[\u001B[38;5;241m0\u001B[39m],device\u001B[38;5;241m=\u001B[39mdevice)\u001B[38;5;241m.\u001B[39mreshape(\u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m,\u001B[38;5;241m1\u001B[39m)\n\u001B[0;32m     24\u001B[0m dec_input\u001B[38;5;241m=\u001B[39mtorch\u001B[38;5;241m.\u001B[39mcat([bos,Y[:,:\u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m]],dim\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m1\u001B[39m)\n\u001B[1;32m---> 25\u001B[0m y_hat,_\u001B[38;5;241m=\u001B[39m\u001B[43mnet\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\u001B[43mdec_input\u001B[49m\u001B[43m,\u001B[49m\u001B[43mX_valid_len\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     26\u001B[0m \u001B[38;5;28mprint\u001B[39m(y_hat\u001B[38;5;241m.\u001B[39mshape,Y\u001B[38;5;241m.\u001B[39mshape)\n\u001B[0;32m     27\u001B[0m l \u001B[38;5;241m=\u001B[39m loss(y_hat,Y,Y_valid_len)\n",
      "File \u001B[1;32mD:\\work softwar\\python\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1739\u001B[0m, in \u001B[0;36mModule._wrapped_call_impl\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1737\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compiled_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[0;32m   1738\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m-> 1739\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call_impl\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32mD:\\work softwar\\python\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1750\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1745\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[0;32m   1746\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[0;32m   1747\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[0;32m   1748\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[0;32m   1749\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[1;32m-> 1750\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1752\u001B[0m result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[0;32m   1753\u001B[0m called_always_called_hooks \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mset\u001B[39m()\n",
      "Cell \u001B[1;32mIn[9], line 9\u001B[0m, in \u001B[0;36mEncoderDecoder.forward\u001B[1;34m(self, enc_X, dec_X, *args)\u001B[0m\n\u001B[0;32m      7\u001B[0m enc_outputs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mencoder(enc_X)\n\u001B[0;32m      8\u001B[0m dec_state\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdecoder\u001B[38;5;241m.\u001B[39minit_state(enc_outputs,\u001B[38;5;241m*\u001B[39margs)\n\u001B[1;32m----> 9\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdecoder\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdec_X\u001B[49m\u001B[43m,\u001B[49m\u001B[43mdec_state\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32mD:\\work softwar\\python\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1739\u001B[0m, in \u001B[0;36mModule._wrapped_call_impl\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1737\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compiled_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[0;32m   1738\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m-> 1739\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call_impl\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32mD:\\work softwar\\python\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1750\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1745\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[0;32m   1746\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[0;32m   1747\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[0;32m   1748\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[0;32m   1749\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[1;32m-> 1750\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1752\u001B[0m result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[0;32m   1753\u001B[0m called_always_called_hooks \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mset\u001B[39m()\n",
      "Cell \u001B[1;32mIn[11], line 35\u001B[0m, in \u001B[0;36mSeq2SeqDecoder.forward\u001B[1;34m(self, X, dec_state)\u001B[0m\n\u001B[0;32m     33\u001B[0m context\u001B[38;5;241m=\u001B[39mdec_state[\u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m]\u001B[38;5;241m.\u001B[39mrepeat(X\u001B[38;5;241m.\u001B[39mshape[\u001B[38;5;241m0\u001B[39m],\u001B[38;5;241m1\u001B[39m,\u001B[38;5;241m1\u001B[39m)\n\u001B[0;32m     34\u001B[0m X_and_context\u001B[38;5;241m=\u001B[39mtorch\u001B[38;5;241m.\u001B[39mcat((X,context),dim\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m)\n\u001B[1;32m---> 35\u001B[0m output,state\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrnn\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX_and_context\u001B[49m\u001B[43m,\u001B[49m\u001B[43mdec_state\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     36\u001B[0m \u001B[38;5;66;03m# output的形状:(batch_size,num_steps,vocab_size)\u001B[39;00m\n\u001B[0;32m     37\u001B[0m output\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdense(output)\u001B[38;5;241m.\u001B[39mpermute(\u001B[38;5;241m1\u001B[39m,\u001B[38;5;241m0\u001B[39m,\u001B[38;5;241m2\u001B[39m)\n",
      "File \u001B[1;32mD:\\work softwar\\python\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1739\u001B[0m, in \u001B[0;36mModule._wrapped_call_impl\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1737\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compiled_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[0;32m   1738\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m-> 1739\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call_impl\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32mD:\\work softwar\\python\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1750\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1745\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[0;32m   1746\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[0;32m   1747\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[0;32m   1748\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[0;32m   1749\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[1;32m-> 1750\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1752\u001B[0m result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[0;32m   1753\u001B[0m called_always_called_hooks \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mset\u001B[39m()\n",
      "File \u001B[1;32mD:\\work softwar\\python\\Lib\\site-packages\\torch\\nn\\modules\\rnn.py:1393\u001B[0m, in \u001B[0;36mGRU.forward\u001B[1;34m(self, input, hx)\u001B[0m\n\u001B[0;32m   1391\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcheck_forward_args(\u001B[38;5;28minput\u001B[39m, hx, batch_sizes)\n\u001B[0;32m   1392\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m batch_sizes \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m-> 1393\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[43m_VF\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mgru\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m   1394\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1395\u001B[0m \u001B[43m        \u001B[49m\u001B[43mhx\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1396\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_flat_weights\u001B[49m\u001B[43m,\u001B[49m\u001B[43m  \u001B[49m\u001B[38;5;66;43;03m# type: ignore[arg-type]\u001B[39;49;00m\n\u001B[0;32m   1397\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbias\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1398\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mnum_layers\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1399\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdropout\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1400\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtraining\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1401\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbidirectional\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1402\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbatch_first\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1403\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1404\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m   1405\u001B[0m     result \u001B[38;5;241m=\u001B[39m _VF\u001B[38;5;241m.\u001B[39mgru(\n\u001B[0;32m   1406\u001B[0m         \u001B[38;5;28minput\u001B[39m,\n\u001B[0;32m   1407\u001B[0m         batch_sizes,\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m   1414\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mbidirectional,\n\u001B[0;32m   1415\u001B[0m     )\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 320x250 with 1 Axes>"
      ],
      "image/png": "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\n"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 17
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-08T06:27:36.617896Z",
     "start_time": "2025-05-08T06:27:36.615008Z"
    }
   },
   "cell_type": "code",
   "source": "# predict_seq2seq(net, eng, src_vocab, tgt_vocab, num_steps, device)",
   "id": "3988563f6d2a2831",
   "outputs": [],
   "execution_count": 20
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-08T06:27:36.951259Z",
     "start_time": "2025-05-08T06:27:36.924653Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#@save\n",
    "def predict_seq2seq(net, src_sentence, src_vocab, tgt_vocab, num_steps,\n",
    "                    device, save_attention_weights=False):\n",
    "    \"\"\"序列到序列模型的预测\"\"\"\n",
    "    # 在预测时将net设置为评估模式\n",
    "    net.eval()\n",
    "    src_tokens = src_vocab[src_sentence.lower().split(' ')] + [\n",
    "        src_vocab['<eos>']]\n",
    "    enc_valid_len = torch.tensor([len(src_tokens)], device=device)\n",
    "    src_tokens = d2l.truncate_pad(src_tokens, num_steps, src_vocab['<pad>'])\n",
    "    # 添加批量轴\n",
    "    enc_X = torch.unsqueeze(\n",
    "        torch.tensor(src_tokens, dtype=torch.long, device=device), dim=0)\n",
    "    enc_outputs = net.encoder(enc_X, enc_valid_len)\n",
    "    dec_state = net.decoder.init_state(enc_outputs, enc_valid_len)\n",
    "    # 添加批量轴\n",
    "    dec_X = torch.unsqueeze(torch.tensor(\n",
    "        [tgt_vocab['<bos>']], dtype=torch.long, device=device), dim=0)\n",
    "    output_seq, attention_weight_seq = [], []\n",
    "    for _ in range(num_steps):\n",
    "        Y, dec_state = net.decoder(dec_X, dec_state)\n",
    "        # 我们使用具有预测最高可能性的词元，作为解码器在下一时间步的输入\n",
    "        dec_X = Y.argmax(dim=2)\n",
    "        pred = dec_X.squeeze(dim=0).type(torch.int32).item()\n",
    "        # 保存注意力权重（稍后讨论）\n",
    "        if save_attention_weights:\n",
    "            attention_weight_seq.append(net.decoder.attention_weights)\n",
    "        # 一旦序列结束词元被预测，输出序列的生成就完成了\n",
    "        if pred == tgt_vocab['<eos>']:\n",
    "            break\n",
    "        output_seq.append(pred)\n",
    "    return ' '.join(tgt_vocab.to_tokens(output_seq)), attention_weight_seq\n",
    "\n",
    "engs = ['go .', \"i lost .\", 'he\\'s calm .', 'i\\'m home .']\n",
    "fras = ['va !', 'j\\'ai perdu .', 'il est calme .', 'je suis chez moi .']\n",
    "for eng, fra in zip(engs, fras):\n",
    "    translation, attention_weight_seq = predict_seq2seq(\n",
    "        net, eng, src_vocab, tgt_vocab, num_steps, device)\n",
    "    print(f'{eng} => {translation}')"
   ],
   "id": "f98bca60835bd1b3",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "go . => va au feu !\n",
      "i lost . => j'ai perdu .\n",
      "he's calm . => il court .\n",
      "i'm home . => je suis chez moi qui qui mort ?\n"
     ]
    }
   ],
   "execution_count": 21
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-08T07:02:34.434500Z",
     "start_time": "2025-05-08T07:02:34.430427Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def bleu(pred_seq, label_seq, k):  #@save\n",
    "    \"\"\"计算BLEU\"\"\"\n",
    "    pred_tokens, label_tokens = pred_seq.split(' '), label_seq.split(' ')\n",
    "    len_pred, len_label = len(pred_tokens), len(label_tokens)\n",
    "    score = math.exp(min(0, 1 - len_label / len_pred))\n",
    "    for n in range(1, k + 1):\n",
    "        num_matches, label_subs = 0, collections.defaultdict(int)\n",
    "        for i in range(len_label - n + 1):\n",
    "            label_subs[' '.join(label_tokens[i: i + n])] += 1\n",
    "        for i in range(len_pred - n + 1):\n",
    "            if label_subs[' '.join(pred_tokens[i: i + n])] > 0:\n",
    "                num_matches += 1\n",
    "                label_subs[' '.join(pred_tokens[i: i + n])] -= 1\n",
    "        score *= math.pow(num_matches / (len_pred - n + 1), math.pow(0.5, n))\n",
    "    return score"
   ],
   "id": "f9e363063c8f6271",
   "outputs": [],
   "execution_count": 37
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-08T07:02:40.676464Z",
     "start_time": "2025-05-08T07:02:40.650513Z"
    }
   },
   "cell_type": "code",
   "source": [
    "engs = ['go .', \"i lost .\", 'he\\'s calm .', 'i\\'m home .']\n",
    "fras = ['va !', 'j\\'ai perdu .', 'il est calme .', 'je suis chez moi .']\n",
    "for eng, fra in zip(engs, fras):\n",
    "    translation, attention_weight_seq = predict_seq2seq(\n",
    "        net, eng, src_vocab, tgt_vocab, num_steps, device)\n",
    "    print(f'{eng} => {translation}, bleu {bleu(translation, fra, k=2):.3f}')"
   ],
   "id": "b088dc4cd3461ad6",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "go . => va au feu !, bleu 0.000\n",
      "i lost . => j'ai perdu ., bleu 1.000\n",
      "he's calm . => il court ., bleu 0.000\n",
      "i'm home . => je suis chez moi qui qui mort ?, bleu 0.572\n"
     ]
    }
   ],
   "execution_count": 38
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "8d8ded94fa781781"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
