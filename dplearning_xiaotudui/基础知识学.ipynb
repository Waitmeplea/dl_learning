{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-03-25T23:27:08.049537Z",
     "start_time": "2025-03-25T23:27:02.691374Z"
    }
   },
   "source": "import torch",
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-25T23:27:08.132762Z",
     "start_time": "2025-03-25T23:27:08.066740Z"
    }
   },
   "cell_type": "code",
   "source": "torch.cuda.is_available()",
   "id": "ffd785bd4d89666f",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "nvidia-smi 查看cuda情况\n",
    "dir() 查看包内有什么\n",
    "help() 查看帮助"
   ],
   "id": "6623ca2c1d8839e4"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-25T23:27:08.233369Z",
     "start_time": "2025-03-25T23:27:08.230787Z"
    }
   },
   "cell_type": "code",
   "source": "from torch.utils.data import Dataset, DataLoader",
   "id": "b6ba2aaf8bcf5733",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "PyTorch中的torch.utils.data.Dataset类是一个用于表示数据集的抽象类，它定义了访问数据样本及其标签的标准方式。以下是其核心作用和使用方法的详细说明：\n",
    "Dataset 是一个抽象基类（Abstract Base Class），它定义了 __len__ 和 __getitem__ 这两个必须实现的方法，但具体如何加载数据、从哪里加载数据，完全由用户自定义。\n",
    "\n",
    "核心作用\n",
    "\n",
    "数据封装与标准化接口：\n",
    "\n",
    "Dataset类将数据（如图像、文本等）及其标签封装为一个统一的对象，要求用户实现__len__和__getitem__方法。\n",
    "__len__：返回数据集的样本总数。\n",
    "__getitem__：根据索引返回对应的样本和标签（支持张量或其他格式）。\n",
    "\n",
    "与DataLoader配合：\n",
    "\n",
    "Dataset通常与DataLoader结合使用。DataLoader负责批量加载数据、多线程加速、数据打乱等操作，而Dataset专注于单个样本的读取和预处理。\n",
    "\n",
    "灵活性：\n",
    "\n",
    "内置数据集（如MNIST、CIFAR-10）已实现Dataset接口，可直接使用。\n",
    "自定义数据集时，继承Dataset并实现关键方法，可处理任意存储格式的数据（如文件夹、CSV文件、数据库）。\n",
    "实现自定义Dataset的步骤\n",
    "\n",
    "继承Dataset类：\n",
    "\n",
    "python\n",
    "复制代码\n",
    "from torch.utils.data import Dataset\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, data, labels, transform=None):\n",
    "        self.data = data          # 数据路径或数据本身\n",
    "        self.labels = labels      # 标签\n",
    "        self.transform = transform# 数据预处理（如transforms.Compose）\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        sample = self.data[idx]\n",
    "        label = self.labels[idx]\n",
    "        if self.transform:\n",
    "            sample = self.transform(sample)\n",
    "        return sample, label\n",
    "\n",
    "\n",
    "使用DataLoader加载：\n",
    "\n",
    "python\n",
    "复制代码\n",
    "from torch.utils.data import DataLoader\n",
    "dataset = CustomDataset(data, labels, transform=my_transforms)\n",
    "dataloader = DataLoader(dataset, batch_size=32, shuffle=True, num_workers=4)\n",
    "\n",
    "实际应用场景\n",
    "图像处理：读取图片文件，应用数据增强（随机裁剪、翻转等）。\n",
    "文本处理：加载文本数据并转换为词向量。\n",
    "非标准数据：处理自定义存储结构的数据（如数据库查询结果）。\n",
    "内置工具与优化\n",
    "\n",
    "TensorDataset：若数据已存储在张量中，可直接使用TensorDataset快速封装。\n",
    "\n",
    "python\n",
    "复制代码\n",
    "import torch\n",
    "from torch.utils.data import TensorDataset\n",
    "data_tensor = torch.tensor(...)\n",
    "labels_tensor = torch.tensor(...)\n",
    "dataset = TensorDataset(data_tensor, labels_tensor)\n",
    "\n",
    "\n",
    "数据增强：通过torchvision.transforms模块定义预处理流程，并在__getitem__中应用。\n",
    "\n",
    "注意事项\n",
    "线程安全：确保__getitem__的实现是线程安全的（避免全局变量修改）。\n",
    "高效读取：对于大规模数据（如图像），避免在__init__中一次性加载全部数据，应动态读取（如按需加载图片文件）。\n",
    "\n",
    "总结来说，Dataset类是PyTorch数据处理流程的基石，通过自定义实现，用户能够灵活适配各种数据源和预处理需求，而DataLoader则在此基础上提供了高效的数据加载和管理功能。"
   ],
   "id": "28c158f4c6a058ea"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-25T23:27:08.263259Z",
     "start_time": "2025-03-25T23:27:08.238525Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from PIL import Image\n",
    "import os"
   ],
   "id": "3048353b9233b035",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 1、Dataset类学习",
   "id": "4af083c559612aee"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-25T23:27:08.293452Z",
     "start_time": "2025-03-25T23:27:08.291356Z"
    }
   },
   "cell_type": "code",
   "source": [
    "##os.path.dirname(path) 是 Python 的 os.path 模块中的一个函数，用于从一个文件路径中提取其所在目录的路径。它的核心功能是返回路径的父目录部分，常用于文件路径的解析和处理。\n",
    "##D:\\bigdata\\dl_learning\\dplearning_xiaotudui\\hymenoptera_data\\train\\ants"
   ],
   "id": "a9ad1cdb4167c249",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-25T23:27:08.304396Z",
     "start_time": "2025-03-25T23:27:08.300544Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class Mydata(Dataset):\n",
    "    def __init__(self,root_dir,label_dir):\n",
    "        self.root_dir=root_dir\n",
    "        self.label_dir=label_dir\n",
    "        self.path=os.path.join(self.root_dir,self.label_dir)\n",
    "        self.img_path=os.listdir(self.path)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_name=self.img_path[idx]\n",
    "        img_item_path=os.path.join(self.path,img_name)\n",
    "        img=Image.open(img_item_path)\n",
    "        return img,self.label_dir\n",
    "    def __len__(self):\n",
    "        return len(self.img_path)"
   ],
   "id": "515f4f9cfda91585",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-25T23:27:08.315674Z",
     "start_time": "2025-03-25T23:27:08.312982Z"
    }
   },
   "cell_type": "code",
   "source": [
    "root_dir=r'D:\\bigdata\\dl_learning\\dplearning_xiaotudui\\hymenoptera_data\\train'\n",
    "ants_data=Mydata(root_dir,'ants')\n",
    "\n",
    "bees_path=Mydata(root_dir,'bees')"
   ],
   "id": "b6a6ed67c6178c9",
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-25T23:27:08.329532Z",
     "start_time": "2025-03-25T23:27:08.326563Z"
    }
   },
   "cell_type": "code",
   "source": "train_data=ants_data+bees_path",
   "id": "383806deed9857f5",
   "outputs": [],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-25T23:27:08.340255Z",
     "start_time": "2025-03-25T23:27:08.338570Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "bd273304f80d2d2c",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 2、Tensorboard",
   "id": "c9e2c218f8d789ab"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-25T23:27:08.616110Z",
     "start_time": "2025-03-25T23:27:08.362563Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "##pip install standard-imghdr tensorboard需要imghdr内置模块但不再支持需要装这个\n",
    "# !tensorboard --logdir=logs --port=6007\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import os\n",
    "img_path=r'D:\\\\bigdata\\\\dl_learning\\\\dplearning_xiaotudui\\\\practice_data\\\\train\\\\bees_image\\\\132826773_dbbcb117b9.jpg'\n",
    "img=Image.open(img_path)\n",
    "img_array=np.array(img)\n",
    "tensorboard=SummaryWriter('logs')\n",
    "writer = SummaryWriter('logs')\n",
    "writer.add_image('train',img_array,2,dataformats='HWC')\n",
    "\n"
   ],
   "id": "46b9d753a285560f",
   "outputs": [],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-25T23:27:08.647601Z",
     "start_time": "2025-03-25T23:27:08.622699Z"
    }
   },
   "cell_type": "code",
   "source": [
    "for i in range(100):\n",
    "    writer.add_scalar(tag='y=x',scalar_value=10*i,global_step=i)\n",
    "writer.close()"
   ],
   "id": "b59252a23dc61dab",
   "outputs": [],
   "execution_count": 10
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 3、transform",
   "id": "c5b916babe2c0792"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-25T23:27:24.615622Z",
     "start_time": "2025-03-25T23:27:23.226713Z"
    }
   },
   "cell_type": "code",
   "source": "from torchvision import transforms",
   "id": "d0660652e3b8903",
   "outputs": [],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-25T23:27:26.947514Z",
     "start_time": "2025-03-25T23:27:26.939590Z"
    }
   },
   "cell_type": "code",
   "source": [
    "##tensor数据类型\n",
    "##通过transforms.ToTensor来看两个问题\n",
    "##1、transforms如何使用\n",
    "##2、为什么需要Tensor数据类型"
   ],
   "id": "f2acd437976b8f82",
   "outputs": [],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-25T23:34:37.028862Z",
     "start_time": "2025-03-25T23:34:37.023188Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "img_path=r'D:\\bigdata\\dl_learning\\dplearning_xiaotudui\\practice_data\\train\\ants_image\\5650366_e22b7e1065.jpg'\n",
    "img=Image.open(img_path)\n",
    "tensor_trans=transforms.ToTensor()##totensor会把数值全部除以255\n",
    "tensor_img=tensor_trans(img)\n"
   ],
   "id": "ef51193d7c98510",
   "outputs": [],
   "execution_count": 16
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "###Normalize则是可以按通道传入均值方差 对应归一化\n",
    "##在训练模型时对每张图片单独标准化，应使用整个数据集的统计值 不应该对单个图片标准化\n",
    "##所有需要预测的新数据（包括实际应用中的未知数据）必须使用训练集计算得到的均值和标准差进行标准化。这是确保数据预处理一致性的核心原则，具体原因和实施方法如下："
   ],
   "id": "b4816353442f1d54"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-25T23:28:18.960620Z",
     "start_time": "2025-03-25T23:28:18.953425Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "tensor_normal=transforms.Normalize(mean=[tensor_img[0].mean(), tensor_img[1].mean(), tensor_img[2].mean()],std=[tensor_img[0].std(), tensor_img[1].std(), tensor_img[2].std()])"
   ],
   "id": "a658d0603bf7b9cc",
   "outputs": [],
   "execution_count": 14
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-25T23:28:20.685448Z",
     "start_time": "2025-03-25T23:28:20.670400Z"
    }
   },
   "cell_type": "code",
   "source": "tensor_normal(tensor_img)[0].std()",
   "id": "847238c8c3083611",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 15
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "transform resize方法可以把图片进行对应放缩",
   "id": "af2df3ed20dee196"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-25T23:35:42.588418Z",
     "start_time": "2025-03-25T23:35:42.586475Z"
    }
   },
   "cell_type": "code",
   "source": [
    "trans_rsize=transforms.Resize((512,512))\n",
    "resize_img=trans_rsize(img)\n",
    "print(resize_img)"
   ],
   "id": "50328b8eff99dc1c",
   "outputs": [],
   "execution_count": 19
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "compose方法，列表保存多个transform方法 从前往后执行，但是前一个的输出必须可以作为后一个的输入否则报错",
   "id": "726113dc63002479"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-25T23:44:46.709988Z",
     "start_time": "2025-03-25T23:44:46.707065Z"
    }
   },
   "cell_type": "code",
   "source": "trans_compose=transforms.Compose([transforms.Resize((512,512)),transforms.ToTensor()])",
   "id": "6611cc938390424a",
   "outputs": [],
   "execution_count": 28
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-25T23:45:07.565145Z",
     "start_time": "2025-03-25T23:45:07.559343Z"
    }
   },
   "cell_type": "code",
   "source": "img_compose=trans_compose(img)",
   "id": "27a956f8deb93cd",
   "outputs": [],
   "execution_count": 30
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "randomcrop方法",
   "id": "cdbb265a22f74150"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-25T23:52:07.943726Z",
     "start_time": "2025-03-25T23:52:07.909329Z"
    }
   },
   "cell_type": "code",
   "source": [
    "trans_random=transforms.RandomCrop(128)\n",
    "for i in range(4):\n",
    "    trans_random(img).show()"
   ],
   "id": "5335d814ea076708",
   "outputs": [],
   "execution_count": 37
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-25T23:51:34.227836Z",
     "start_time": "2025-03-25T23:51:34.172854Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "7a304aefd1881ecd",
   "outputs": [],
   "execution_count": 34
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "c566878fbd564384"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
