{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-01T11:52:48.214317Z",
     "start_time": "2025-04-01T11:52:46.302514Z"
    }
   },
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import time\n",
    "torch.cuda.is_available()##判断是否有cuda\n",
    "\n",
    "###注意 这里其实除了数据其他不需要再赋值了 直接net.to(device)就可以了 \n",
    "def is_cuda(x,use_cuda=True):\n",
    "    if use_cuda:\n",
    "        return x.cuda() if torch.cuda.is_available() else x\n",
    "    else:\n",
    "        return x\n",
    "    \n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.sequential = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=3, out_channels=32, kernel_size=5, stride=1, padding=2),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "            nn.Conv2d(in_channels=32, out_channels=32, kernel_size=5, stride=1, padding=2),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "            nn.Conv2d(in_channels=32, out_channels=64, kernel_size=5, stride=1, padding=2),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "            nn.Flatten(start_dim=1),\n",
    "            nn.Linear(in_features=64 * 4 * 4, out_features=10)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.sequential(x)\n",
    "        return out"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "id": "c5f49b39-a687-4d42-a4cd-06def821ed6b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-01T11:54:44.466211Z",
     "start_time": "2025-04-01T11:54:38.607735Z"
    }
   },
   "source": [
    "###原始数据集\n",
    "rootdir=r'D:\\bigdata\\dl_learning\\dplearning_xiaotudui\\data'\n",
    "train_datasets=torchvision.datasets.CIFAR10(rootdir,transform=torchvision.transforms.ToTensor(),train=True)\n",
    "test_datasets=torchvision.datasets.CIFAR10(rootdir,transform=torchvision.transforms.ToTensor(),train=False)\n",
    "train_size=len(train_datasets)\n",
    "test_size=len(test_datasets)\n",
    "print('训练集数据大小{},测试集数据大小{}'.format(train_size,test_size))\n",
    "###数据集加载\n",
    "train_dataloader=torch.utils.data.DataLoader(train_datasets,batch_size=64,shuffle=True)\n",
    "test_dataloader=torch.utils.data.DataLoader(test_datasets,batch_size=64,shuffle=True)\n",
    "###模型加载\n",
    "net=Net()\n",
    "###这样判断 有cuda 则进行cuda运算更合理\n",
    "net=is_cuda(net)\n",
    "\n",
    "\n",
    "###定义loss function\n",
    "loss_func=nn.CrossEntropyLoss()\n",
    "loss_func=is_cuda(loss_func)\n",
    "\n",
    "\n",
    "###定义优化器\n",
    "optimz=torch.optim.SGD(net.parameters(),momentum=0.9)\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练集数据大小50000,测试集数据大小10000\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "cell_type": "code",
   "id": "7486b617-891f-44a4-9d98-a0f778d551ce",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-01T05:29:49.070622Z",
     "start_time": "2025-04-01T05:29:38.326435Z"
    }
   },
   "source": [
    "epoch=10\n",
    "train_step=0\n",
    "test_step=0\n",
    "start_time=time.time()\n",
    "for i in range(1,epoch+1):\n",
    "    for datas in train_dataloader:\n",
    "        optimz.zero_grad()\n",
    "        data,target=datas\n",
    "        ###数据上cuda\n",
    "        data=is_cuda(data,use_cuda=True)\n",
    "        target=is_cuda(target,use_cuda=True)\n",
    "        \n",
    "        output=net(data)\n",
    "        loss=loss_func(output,target)\n",
    "        loss.backward()\n",
    "        optimz.step()\n",
    "        if train_step%100==0:\n",
    "            end_time=time.time()\n",
    "            print(end_time-start_time)\n",
    "            print(end_time-start_time)\n",
    "            print('训练第{}步，训练集上的损失为{}'.format(train_step,loss))\n",
    "        train_step+=1\n",
    "    with torch.no_grad():\n",
    "        total_loss=0\n",
    "        total_accuracy=0\n",
    "        for datas in test_dataloader:\n",
    "            data,target=datas\n",
    "            ###转入cuda\n",
    "            data=is_cuda(data,use_cuda=True)\n",
    "            target=is_cuda(target,use_cuda=True)\n",
    "            \n",
    "            output=net(data)\n",
    "            loss=loss_func(output,target)\n",
    "            total_loss+=loss\n",
    "            total_accuracy+=(output.argmax(1)==target).sum()\n",
    "        \n",
    "        print('测试集上的梯度{}'.format(total_loss))\n",
    "        print('测试集上的准确率{}'.format(total_accuracy/test_size))"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.042516469955444336\n",
      "0.042516469955444336\n",
      "训练第0步，训练集上的损失为2.2905068397521973\n",
      "3.23594331741333\n",
      "3.23594331741333\n",
      "训练第100步，训练集上的损失为2.27164363861084\n",
      "6.131002426147461\n",
      "6.131002426147461\n",
      "训练第200步，训练集上的损失为2.180856704711914\n",
      "9.11557126045227\n",
      "9.11557126045227\n",
      "训练第300步，训练集上的损失为2.100832462310791\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[17], line 15\u001B[0m\n\u001B[0;32m     13\u001B[0m output\u001B[38;5;241m=\u001B[39mnet(data)\n\u001B[0;32m     14\u001B[0m loss\u001B[38;5;241m=\u001B[39mloss_func(output,target)\n\u001B[1;32m---> 15\u001B[0m \u001B[43mloss\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbackward\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     16\u001B[0m optimz\u001B[38;5;241m.\u001B[39mstep()\n\u001B[0;32m     17\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m train_step\u001B[38;5;241m%\u001B[39m\u001B[38;5;241m100\u001B[39m\u001B[38;5;241m==\u001B[39m\u001B[38;5;241m0\u001B[39m:\n",
      "File \u001B[1;32mD:\\work softwar\\python\\Lib\\site-packages\\torch\\_tensor.py:626\u001B[0m, in \u001B[0;36mTensor.backward\u001B[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001B[0m\n\u001B[0;32m    616\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m has_torch_function_unary(\u001B[38;5;28mself\u001B[39m):\n\u001B[0;32m    617\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m handle_torch_function(\n\u001B[0;32m    618\u001B[0m         Tensor\u001B[38;5;241m.\u001B[39mbackward,\n\u001B[0;32m    619\u001B[0m         (\u001B[38;5;28mself\u001B[39m,),\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    624\u001B[0m         inputs\u001B[38;5;241m=\u001B[39minputs,\n\u001B[0;32m    625\u001B[0m     )\n\u001B[1;32m--> 626\u001B[0m \u001B[43mtorch\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mautograd\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbackward\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    627\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mgradient\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mretain_graph\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcreate_graph\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43minputs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43minputs\u001B[49m\n\u001B[0;32m    628\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32mD:\\work softwar\\python\\Lib\\site-packages\\torch\\autograd\\__init__.py:347\u001B[0m, in \u001B[0;36mbackward\u001B[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001B[0m\n\u001B[0;32m    342\u001B[0m     retain_graph \u001B[38;5;241m=\u001B[39m create_graph\n\u001B[0;32m    344\u001B[0m \u001B[38;5;66;03m# The reason we repeat the same comment below is that\u001B[39;00m\n\u001B[0;32m    345\u001B[0m \u001B[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001B[39;00m\n\u001B[0;32m    346\u001B[0m \u001B[38;5;66;03m# calls in the traceback and some print out the last line\u001B[39;00m\n\u001B[1;32m--> 347\u001B[0m \u001B[43m_engine_run_backward\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    348\u001B[0m \u001B[43m    \u001B[49m\u001B[43mtensors\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    349\u001B[0m \u001B[43m    \u001B[49m\u001B[43mgrad_tensors_\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    350\u001B[0m \u001B[43m    \u001B[49m\u001B[43mretain_graph\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    351\u001B[0m \u001B[43m    \u001B[49m\u001B[43mcreate_graph\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    352\u001B[0m \u001B[43m    \u001B[49m\u001B[43minputs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    353\u001B[0m \u001B[43m    \u001B[49m\u001B[43mallow_unreachable\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[0;32m    354\u001B[0m \u001B[43m    \u001B[49m\u001B[43maccumulate_grad\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[0;32m    355\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32mD:\\work softwar\\python\\Lib\\site-packages\\torch\\autograd\\graph.py:823\u001B[0m, in \u001B[0;36m_engine_run_backward\u001B[1;34m(t_outputs, *args, **kwargs)\u001B[0m\n\u001B[0;32m    821\u001B[0m     unregister_hooks \u001B[38;5;241m=\u001B[39m _register_logging_hooks_on_whole_graph(t_outputs)\n\u001B[0;32m    822\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m--> 823\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mVariable\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_execution_engine\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrun_backward\u001B[49m\u001B[43m(\u001B[49m\u001B[43m  \u001B[49m\u001B[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001B[39;49;00m\n\u001B[0;32m    824\u001B[0m \u001B[43m        \u001B[49m\u001B[43mt_outputs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\n\u001B[0;32m    825\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m  \u001B[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001B[39;00m\n\u001B[0;32m    826\u001B[0m \u001B[38;5;28;01mfinally\u001B[39;00m:\n\u001B[0;32m    827\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m attach_logging_hooks:\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "execution_count": 17
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-01T04:24:44.089607Z",
     "start_time": "2025-04-01T04:24:44.086075Z"
    }
   },
   "cell_type": "code",
   "source": [
    "####使用cpu或gpu计算 定义设备\n",
    "device1=torch.device('cpu')\n",
    "###如果有多个cuda 可以torch.device('cuda:0')代表第一个gpu\n",
    "device2=torch.device('cuda')\n",
    "###然后可以把变量转移到设备上\n",
    "net=net.to(device1)"
   ],
   "id": "c242f90d218a1eb2",
   "outputs": [],
   "execution_count": 14
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-01T04:23:09.878716Z",
     "start_time": "2025-04-01T04:23:09.873814Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "26c81b6b5e76d143",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-01T11:54:45.028573Z",
     "start_time": "2025-04-01T11:54:45.025447Z"
    }
   },
   "cell_type": "code",
   "source": [
    "for i in range(len(test_datasets.classes)):\n",
    "    print('第{}个标签，对应的图片是{}'.format(i,test_datasets.classes[i]))"
   ],
   "id": "b2c2a49f904288a7",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "第0个标签，对应的图片是airplane\n",
      "第1个标签，对应的图片是automobile\n",
      "第2个标签，对应的图片是bird\n",
      "第3个标签，对应的图片是cat\n",
      "第4个标签，对应的图片是deer\n",
      "第5个标签，对应的图片是dog\n",
      "第6个标签，对应的图片是frog\n",
      "第7个标签，对应的图片是horse\n",
      "第8个标签，对应的图片是ship\n",
      "第9个标签，对应的图片是truck\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "a77988c936c9ee38"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
