{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-01T04:15:39.623096Z",
     "start_time": "2025-04-01T04:15:39.617321Z"
    }
   },
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import time\n",
    "torch.cuda.is_available()##判断是否有cuda\n",
    "\n",
    "###注意 这里其实除了数据其他不需要再赋值了 直接net.to(device)就可以了 \n",
    "def is_cuda(x,use_cuda=True):\n",
    "    if use_cuda:\n",
    "        return x.cuda() if torch.cuda.is_available() else x\n",
    "    else:\n",
    "        return x\n",
    "    \n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.sequential = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=3, out_channels=32, kernel_size=5, stride=1, padding=2),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "            nn.Conv2d(in_channels=32, out_channels=32, kernel_size=5, stride=1, padding=2),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "            nn.Conv2d(in_channels=32, out_channels=64, kernel_size=5, stride=1, padding=2),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "            nn.Flatten(start_dim=1),\n",
    "            nn.Linear(in_features=64 * 4 * 4, out_features=10)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.sequential(x)\n",
    "        return out"
   ],
   "outputs": [],
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "id": "c5f49b39-a687-4d42-a4cd-06def821ed6b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-01T04:15:41.780185Z",
     "start_time": "2025-04-01T04:15:40.835951Z"
    }
   },
   "source": [
    "###原始数据集\n",
    "rootdir=r'D:\\code_file\\dplearning_xiaotudui\\data'\n",
    "train_datasets=torchvision.datasets.CIFAR10(rootdir,transform=torchvision.transforms.ToTensor(),train=True)\n",
    "test_datasets=torchvision.datasets.CIFAR10(rootdir,transform=torchvision.transforms.ToTensor(),train=False)\n",
    "train_size=len(train_datasets)\n",
    "test_size=len(test_datasets)\n",
    "print('训练集数据大小{},测试集数据大小{}'.format(train_size,test_size))\n",
    "###数据集加载\n",
    "train_dataloader=torch.utils.data.DataLoader(train_datasets,batch_size=64,shuffle=True)\n",
    "test_dataloader=torch.utils.data.DataLoader(test_datasets,batch_size=64,shuffle=True)\n",
    "###模型加载\n",
    "net=Net()\n",
    "###这样判断 有cuda 则进行cuda运算更合理\n",
    "net=is_cuda(net)\n",
    "\n",
    "\n",
    "###定义loss function\n",
    "loss_func=nn.CrossEntropyLoss()\n",
    "loss_func=is_cuda(loss_func)\n",
    "\n",
    "\n",
    "###定义优化器\n",
    "optimz=torch.optim.SGD(net.parameters(),momentum=0.9)\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练集数据大小50000,测试集数据大小10000\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "cell_type": "code",
   "id": "7486b617-891f-44a4-9d98-a0f778d551ce",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-01T04:20:27.511403Z",
     "start_time": "2025-04-01T04:15:41.781191Z"
    }
   },
   "source": [
    "epoch=10\n",
    "train_step=0\n",
    "test_step=0\n",
    "start_time=time.time()\n",
    "for i in range(1,epoch+1):\n",
    "    for datas in train_dataloader:\n",
    "        optimz.zero_grad()\n",
    "        data,target=datas\n",
    "        ###数据上cuda\n",
    "        data=is_cuda(data,use_cuda=True)\n",
    "        target=is_cuda(target,use_cuda=True)\n",
    "        \n",
    "        output=net(data)\n",
    "        loss=loss_func(output,target)\n",
    "        loss.backward()\n",
    "        optimz.step()\n",
    "        if train_step%100==0:\n",
    "            end_time=time.time()\n",
    "            print(end_time-start_time)\n",
    "            print(end_time-start_time)\n",
    "            print('训练第{}步，训练集上的损失为{}'.format(train_step,loss))\n",
    "        train_step+=1\n",
    "    with torch.no_grad():\n",
    "        total_loss=0\n",
    "        total_accuracy=0\n",
    "        for datas in test_dataloader:\n",
    "            data,target=datas\n",
    "            ###转入cuda\n",
    "            data=is_cuda(data,use_cuda=True)\n",
    "            target=is_cuda(target,use_cuda=True)\n",
    "            \n",
    "            output=net(data)\n",
    "            loss=loss_func(output,target)\n",
    "            total_loss+=loss\n",
    "            total_accuracy+=(output.argmax(1)==target).sum()\n",
    "        \n",
    "        print('测试集上的梯度{}'.format(total_loss))\n",
    "        print('测试集上的准确率{}'.format(total_accuracy/test_size))"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.04743671417236328\n",
      "0.04743671417236328\n",
      "训练第0步，训练集上的损失为2.309211254119873\n",
      "3.539426326751709\n",
      "3.539426326751709\n",
      "训练第100步，训练集上的损失为2.280055284500122\n",
      "6.860842704772949\n",
      "6.860842704772949\n",
      "训练第200步，训练集上的损失为2.2650651931762695\n",
      "10.161633014678955\n",
      "10.161633014678955\n",
      "训练第300步，训练集上的损失为2.121889114379883\n",
      "13.494877576828003\n",
      "13.494877576828003\n",
      "训练第400步，训练集上的损失为1.993196725845337\n",
      "16.902547121047974\n",
      "16.902547121047974\n",
      "训练第500步，训练集上的损失为2.0427794456481934\n",
      "20.266924381256104\n",
      "20.266924381256104\n",
      "训练第600步，训练集上的损失为1.8557003736495972\n",
      "23.689820528030396\n",
      "23.689820528030396\n",
      "训练第700步，训练集上的损失为1.8310956954956055\n",
      "测试集上的梯度283.2325439453125\n",
      "测试集上的准确率0.36640000343322754\n",
      "30.314990282058716\n",
      "30.314990282058716\n",
      "训练第800步，训练集上的损失为1.8817858695983887\n",
      "33.75321817398071\n",
      "33.75321817398071\n",
      "训练第900步，训练集上的损失为1.7570765018463135\n",
      "37.253735303878784\n",
      "37.253735303878784\n",
      "训练第1000步，训练集上的损失为1.6986826658248901\n",
      "40.63629865646362\n",
      "40.63629865646362\n",
      "训练第1100步，训练集上的损失为1.5896015167236328\n",
      "44.08307075500488\n",
      "44.08307075500488\n",
      "训练第1200步，训练集上的损失为1.6320250034332275\n",
      "47.611043214797974\n",
      "47.611043214797974\n",
      "训练第1300步，训练集上的损失为1.7861446142196655\n",
      "51.07964849472046\n",
      "51.07964849472046\n",
      "训练第1400步，训练集上的损失为1.592011570930481\n",
      "54.58840894699097\n",
      "54.58840894699097\n",
      "训练第1500步，训练集上的损失为1.5244343280792236\n",
      "测试集上的梯度258.892578125\n",
      "测试集上的准确率0.41690000891685486\n",
      "61.4749071598053\n",
      "61.4749071598053\n",
      "训练第1600步，训练集上的损失为1.7398840188980103\n",
      "64.98379349708557\n",
      "64.98379349708557\n",
      "训练第1700步，训练集上的损失为1.4916512966156006\n",
      "68.44238758087158\n",
      "68.44238758087158\n",
      "训练第1800步，训练集上的损失为1.4216707944869995\n",
      "71.97007465362549\n",
      "71.97007465362549\n",
      "训练第1900步，训练集上的损失为1.6130590438842773\n",
      "75.4632842540741\n",
      "75.4632842540741\n",
      "训练第2000步，训练集上的损失为1.6705280542373657\n",
      "78.98557662963867\n",
      "78.98557662963867\n",
      "训练第2100步，训练集上的损失为1.6213183403015137\n",
      "82.52614307403564\n",
      "82.52614307403564\n",
      "训练第2200步，训练集上的损失为1.49176824092865\n",
      "85.9771192073822\n",
      "85.9771192073822\n",
      "训练第2300步，训练集上的损失为1.6226699352264404\n",
      "测试集上的梯度236.1270751953125\n",
      "测试集上的准确率0.4666000008583069\n",
      "92.77883315086365\n",
      "92.77883315086365\n",
      "训练第2400步，训练集上的损失为1.4088120460510254\n",
      "96.31369304656982\n",
      "96.31369304656982\n",
      "训练第2500步，训练集上的损失为1.5603363513946533\n",
      "99.86029386520386\n",
      "99.86029386520386\n",
      "训练第2600步，训练集上的损失为1.5910087823867798\n",
      "103.34259724617004\n",
      "103.34259724617004\n",
      "训练第2700步，训练集上的损失为1.4335092306137085\n",
      "106.8025131225586\n",
      "106.8025131225586\n",
      "训练第2800步，训练集上的损失为1.3630272150039673\n",
      "110.28124141693115\n",
      "110.28124141693115\n",
      "训练第2900步，训练集上的损失为1.310701847076416\n",
      "113.77936673164368\n",
      "113.77936673164368\n",
      "训练第3000步，训练集上的损失为1.4959964752197266\n",
      "117.22900176048279\n",
      "117.22900176048279\n",
      "训练第3100步，训练集上的损失为1.5342168807983398\n",
      "测试集上的梯度227.93756103515625\n",
      "测试集上的准确率0.48669999837875366\n",
      "124.05295372009277\n",
      "124.05295372009277\n",
      "训练第3200步，训练集上的损失为1.4835633039474487\n",
      "127.554025888443\n",
      "127.554025888443\n",
      "训练第3300步，训练集上的损失为1.444571852684021\n",
      "131.04867315292358\n",
      "131.04867315292358\n",
      "训练第3400步，训练集上的损失为1.3875032663345337\n",
      "134.56255793571472\n",
      "134.56255793571472\n",
      "训练第3500步，训练集上的损失为1.344045877456665\n",
      "138.04214000701904\n",
      "138.04214000701904\n",
      "训练第3600步，训练集上的损失为1.5037975311279297\n",
      "141.45179653167725\n",
      "141.45179653167725\n",
      "训练第3700步，训练集上的损失为1.190592646598816\n",
      "144.97036409378052\n",
      "144.97036409378052\n",
      "训练第3800步，训练集上的损失为1.235265851020813\n",
      "148.48404550552368\n",
      "148.48404550552368\n",
      "训练第3900步，训练集上的损失为1.2744081020355225\n",
      "测试集上的梯度213.03099060058594\n",
      "测试集上的准确率0.519599974155426\n",
      "155.42357683181763\n",
      "155.42357683181763\n",
      "训练第4000步，训练集上的损失为1.3503645658493042\n",
      "158.95823526382446\n",
      "158.95823526382446\n",
      "训练第4100步，训练集上的损失为1.1973943710327148\n",
      "162.4775161743164\n",
      "162.4775161743164\n",
      "训练第4200步，训练集上的损失为1.2031456232070923\n",
      "165.99887371063232\n",
      "165.99887371063232\n",
      "训练第4300步，训练集上的损失为1.187356948852539\n",
      "169.49934339523315\n",
      "169.49934339523315\n",
      "训练第4400步，训练集上的损失为1.4532597064971924\n",
      "173.07735204696655\n",
      "173.07735204696655\n",
      "训练第4500步，训练集上的损失为1.1890201568603516\n",
      "176.60572981834412\n",
      "176.60572981834412\n",
      "训练第4600步，训练集上的损失为1.362872838973999\n",
      "测试集上的梯度205.8910675048828\n",
      "测试集上的准确率0.5400999784469604\n",
      "183.4845848083496\n",
      "183.4845848083496\n",
      "训练第4700步，训练集上的损失为1.4542360305786133\n",
      "187.0352339744568\n",
      "187.0352339744568\n",
      "训练第4800步，训练集上的损失为1.3485910892486572\n",
      "190.56876063346863\n",
      "190.56876063346863\n",
      "训练第4900步，训练集上的损失为1.331095576286316\n",
      "194.04237532615662\n",
      "194.04237532615662\n",
      "训练第5000步，训练集上的损失为1.1515860557556152\n",
      "197.57697987556458\n",
      "197.57697987556458\n",
      "训练第5100步，训练集上的损失为1.177964210510254\n",
      "201.29857659339905\n",
      "201.29857659339905\n",
      "训练第5200步，训练集上的损失为1.088959813117981\n",
      "204.8288254737854\n",
      "204.8288254737854\n",
      "训练第5300步，训练集上的损失为1.1787607669830322\n",
      "208.3098864555359\n",
      "208.3098864555359\n",
      "训练第5400步，训练集上的损失为1.0610870122909546\n",
      "测试集上的梯度196.84014892578125\n",
      "测试集上的准确率0.5616000294685364\n",
      "215.25992131233215\n",
      "215.25992131233215\n",
      "训练第5500步，训练集上的损失为1.1487641334533691\n",
      "218.82474899291992\n",
      "218.82474899291992\n",
      "训练第5600步，训练集上的损失为0.9252784252166748\n",
      "222.35872602462769\n",
      "222.35872602462769\n",
      "训练第5700步，训练集上的损失为1.3230476379394531\n",
      "225.98109555244446\n",
      "225.98109555244446\n",
      "训练第5800步，训练集上的损失为1.3261816501617432\n",
      "229.54249954223633\n",
      "229.54249954223633\n",
      "训练第5900步，训练集上的损失为1.2721971273422241\n",
      "233.11109495162964\n",
      "233.11109495162964\n",
      "训练第6000步，训练集上的损失为0.9881531596183777\n",
      "236.65862488746643\n",
      "236.65862488746643\n",
      "训练第6100步，训练集上的损失为1.2264527082443237\n",
      "240.20643424987793\n",
      "240.20643424987793\n",
      "训练第6200步，训练集上的损失为1.2853895425796509\n",
      "测试集上的梯度194.49337768554688\n",
      "测试集上的准确率0.5583999752998352\n",
      "247.08417558670044\n",
      "247.08417558670044\n",
      "训练第6300步，训练集上的损失为1.298310399055481\n",
      "250.61670470237732\n",
      "250.61670470237732\n",
      "训练第6400步，训练集上的损失为1.0415006875991821\n",
      "254.10574626922607\n",
      "254.10574626922607\n",
      "训练第6500步，训练集上的损失为1.2167291641235352\n",
      "257.605176448822\n",
      "257.605176448822\n",
      "训练第6600步，训练集上的损失为1.5289300680160522\n",
      "261.13391280174255\n",
      "261.13391280174255\n",
      "训练第6700步，训练集上的损失为0.9354201555252075\n",
      "264.8888785839081\n",
      "264.8888785839081\n",
      "训练第6800步，训练集上的损失为1.382572889328003\n",
      "268.7955548763275\n",
      "268.7955548763275\n",
      "训练第6900步，训练集上的损失为1.1673192977905273\n",
      "272.42695784568787\n",
      "272.42695784568787\n",
      "训练第7000步，训练集上的损失为1.123052954673767\n",
      "测试集上的梯度180.3545379638672\n",
      "测试集上的准确率0.6018000245094299\n",
      "279.16063833236694\n",
      "279.16063833236694\n",
      "训练第7100步，训练集上的损失为1.2765722274780273\n",
      "282.6233379840851\n",
      "282.6233379840851\n",
      "训练第7200步，训练集上的损失为1.2049661874771118\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[6], line 15\u001B[0m\n\u001B[0;32m     13\u001B[0m output\u001B[38;5;241m=\u001B[39mnet(data)\n\u001B[0;32m     14\u001B[0m loss\u001B[38;5;241m=\u001B[39mloss_func(output,target)\n\u001B[1;32m---> 15\u001B[0m \u001B[43mloss\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbackward\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     16\u001B[0m optimz\u001B[38;5;241m.\u001B[39mstep()\n\u001B[0;32m     17\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m train_step\u001B[38;5;241m%\u001B[39m\u001B[38;5;241m100\u001B[39m\u001B[38;5;241m==\u001B[39m\u001B[38;5;241m0\u001B[39m:\n",
      "File \u001B[1;32mD:\\work softwar\\python\\Lib\\site-packages\\torch\\_tensor.py:626\u001B[0m, in \u001B[0;36mTensor.backward\u001B[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001B[0m\n\u001B[0;32m    616\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m has_torch_function_unary(\u001B[38;5;28mself\u001B[39m):\n\u001B[0;32m    617\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m handle_torch_function(\n\u001B[0;32m    618\u001B[0m         Tensor\u001B[38;5;241m.\u001B[39mbackward,\n\u001B[0;32m    619\u001B[0m         (\u001B[38;5;28mself\u001B[39m,),\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    624\u001B[0m         inputs\u001B[38;5;241m=\u001B[39minputs,\n\u001B[0;32m    625\u001B[0m     )\n\u001B[1;32m--> 626\u001B[0m \u001B[43mtorch\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mautograd\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbackward\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    627\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mgradient\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mretain_graph\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcreate_graph\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43minputs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43minputs\u001B[49m\n\u001B[0;32m    628\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32mD:\\work softwar\\python\\Lib\\site-packages\\torch\\autograd\\__init__.py:347\u001B[0m, in \u001B[0;36mbackward\u001B[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001B[0m\n\u001B[0;32m    342\u001B[0m     retain_graph \u001B[38;5;241m=\u001B[39m create_graph\n\u001B[0;32m    344\u001B[0m \u001B[38;5;66;03m# The reason we repeat the same comment below is that\u001B[39;00m\n\u001B[0;32m    345\u001B[0m \u001B[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001B[39;00m\n\u001B[0;32m    346\u001B[0m \u001B[38;5;66;03m# calls in the traceback and some print out the last line\u001B[39;00m\n\u001B[1;32m--> 347\u001B[0m \u001B[43m_engine_run_backward\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    348\u001B[0m \u001B[43m    \u001B[49m\u001B[43mtensors\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    349\u001B[0m \u001B[43m    \u001B[49m\u001B[43mgrad_tensors_\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    350\u001B[0m \u001B[43m    \u001B[49m\u001B[43mretain_graph\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    351\u001B[0m \u001B[43m    \u001B[49m\u001B[43mcreate_graph\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    352\u001B[0m \u001B[43m    \u001B[49m\u001B[43minputs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    353\u001B[0m \u001B[43m    \u001B[49m\u001B[43mallow_unreachable\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[0;32m    354\u001B[0m \u001B[43m    \u001B[49m\u001B[43maccumulate_grad\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[0;32m    355\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32mD:\\work softwar\\python\\Lib\\site-packages\\torch\\autograd\\graph.py:823\u001B[0m, in \u001B[0;36m_engine_run_backward\u001B[1;34m(t_outputs, *args, **kwargs)\u001B[0m\n\u001B[0;32m    821\u001B[0m     unregister_hooks \u001B[38;5;241m=\u001B[39m _register_logging_hooks_on_whole_graph(t_outputs)\n\u001B[0;32m    822\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m--> 823\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mVariable\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_execution_engine\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrun_backward\u001B[49m\u001B[43m(\u001B[49m\u001B[43m  \u001B[49m\u001B[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001B[39;49;00m\n\u001B[0;32m    824\u001B[0m \u001B[43m        \u001B[49m\u001B[43mt_outputs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\n\u001B[0;32m    825\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m  \u001B[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001B[39;00m\n\u001B[0;32m    826\u001B[0m \u001B[38;5;28;01mfinally\u001B[39;00m:\n\u001B[0;32m    827\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m attach_logging_hooks:\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-01T04:24:44.089607Z",
     "start_time": "2025-04-01T04:24:44.086075Z"
    }
   },
   "cell_type": "code",
   "source": [
    "####使用cpu或gpu计算 定义设备\n",
    "device1=torch.device('cpu')\n",
    "###如果有多个cuda 可以torch.device('cuda:0')代表第一个gpu\n",
    "device2=torch.device('cuda')\n",
    "###然后可以把变量转移到设备上\n",
    "net=net.to(device1)"
   ],
   "id": "c242f90d218a1eb2",
   "outputs": [],
   "execution_count": 14
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-01T04:23:09.878716Z",
     "start_time": "2025-04-01T04:23:09.873814Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "26c81b6b5e76d143",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "b2c2a49f904288a7"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
