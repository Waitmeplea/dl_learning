{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-27T11:57:54.768373Z",
     "start_time": "2025-08-27T11:57:39.546843Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import sys\n",
    "import torch\n",
    "from modelscope import AutoModelForCausalLM, AutoTokenizer,AutoModel\n",
    "from pathlib import Path\n",
    "from modelscope import AutoTokenizer, AutoModelForMaskedLM\n",
    "model_id='iic/nlp_gte_sentence-embedding_chinese-base'\n",
    "tokenizer=AutoTokenizer.from_pretrained(model_id)\n",
    "model = AutoModel.from_pretrained(model_id)"
   ],
   "id": "47fa7d075256a088",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading Model from https://www.modelscope.cn to directory: C:\\Users\\Zzz\\.cache\\modelscope\\hub\\models\\iic\\nlp_gte_sentence-embedding_chinese-base\n",
      "Downloading Model from https://www.modelscope.cn to directory: C:\\Users\\Zzz\\.cache\\modelscope\\hub\\models\\iic\\nlp_gte_sentence-embedding_chinese-base\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "sentences = [\n",
    "    \"今天天气真好！\",\n",
    "    \"今天的天气非常不错。\",\n",
    "    \"我明天要去上海。\",\n",
    "    \"北京是中国的首都。\"\n",
    "]\n",
    "\n",
    "# 5. 对句子进行编码\n",
    "# tokenizer 可以处理一个句子或一个句子列表\n",
    "# return_tensors='pt' 表示返回 PyTorch tensors\n",
    "# padding=True 会对较短的句子进行填充，使所有序列长度一致\n",
    "# truncation=True 会截断超过模型最大长度的句子\n",
    "inputs = tokenizer(sentences, return_tensors='pt', padding=True, truncation=True)\n",
    "\n",
    "with torch.no_grad():\n",
    "    result=model(**inputs)"
   ],
   "id": "3e46f42df9db9500"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-27T11:57:54.779225Z",
     "start_time": "2025-08-27T11:57:54.772108Z"
    }
   },
   "cell_type": "code",
   "source": "result",
   "id": "2ea1155ff526e807",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BaseModelOutputWithPoolingAndCrossAttentions(last_hidden_state=tensor([[[-0.0379, -0.0735, -0.0954,  ..., -0.3619,  0.2379,  0.1320],\n",
       "         [-0.3089,  0.0102, -0.5110,  ..., -0.2834,  0.2770, -0.1739],\n",
       "         [-0.2455,  0.0096, -0.5619,  ..., -0.2677,  0.2411, -0.0896],\n",
       "         ...,\n",
       "         [-0.0309, -0.0762, -0.0964,  ..., -0.3598,  0.2346,  0.1314],\n",
       "         [-0.0296, -0.0760, -0.0980,  ..., -0.3612,  0.2335,  0.1307],\n",
       "         [-0.0335, -0.0751, -0.0962,  ..., -0.3614,  0.2352,  0.1315]],\n",
       "\n",
       "        [[ 0.0862,  0.1291, -0.1025,  ..., -0.3512,  0.1808, -0.1394],\n",
       "         [-0.1793,  0.1856, -0.5745,  ..., -0.1923,  0.2844, -0.3296],\n",
       "         [-0.1129,  0.2033, -0.6373,  ..., -0.1809,  0.2547, -0.2429],\n",
       "         ...,\n",
       "         [ 0.0482,  0.1117, -0.4679,  ..., -0.1345, -0.2247, -0.5080],\n",
       "         [ 0.0840,  0.1961, -0.3224,  ..., -0.1682, -0.0501, -0.3593],\n",
       "         [ 0.0862,  0.1291, -0.1025,  ..., -0.3512,  0.1808, -0.1394]],\n",
       "\n",
       "        [[ 0.0566, -0.1998, -0.2247,  ..., -0.6102,  0.2019, -0.0676],\n",
       "         [ 0.2734,  0.0857, -0.0897,  ..., -0.7001,  0.4246,  0.1299],\n",
       "         [ 0.2058, -0.0481, -0.3986,  ..., -0.1633,  0.0209, -0.0031],\n",
       "         ...,\n",
       "         [ 0.0566, -0.1998, -0.2247,  ..., -0.6102,  0.2019, -0.0676],\n",
       "         [ 0.0661, -0.2001, -0.2242,  ..., -0.6049,  0.1988, -0.0643],\n",
       "         [ 0.0590, -0.1996, -0.2242,  ..., -0.6080,  0.2020, -0.0666]],\n",
       "\n",
       "        [[-0.1765, -0.5486, -0.0740,  ..., -0.6707,  0.2348, -0.0909],\n",
       "         [-0.2242, -0.3387, -0.3169,  ..., -0.4513,  0.3102, -0.2483],\n",
       "         [-0.2436, -0.3320, -0.3095,  ..., -0.4646,  0.2995, -0.2439],\n",
       "         ...,\n",
       "         [-0.0459, -0.3105, -0.3088,  ..., -0.4682,  0.0290, -0.2170],\n",
       "         [-0.1765, -0.5486, -0.0740,  ..., -0.6707,  0.2348, -0.0909],\n",
       "         [-0.1716, -0.5503, -0.0747,  ..., -0.6698,  0.2364, -0.0902]]]), pooler_output=tensor([[-0.1996, -0.1234, -0.0018,  ...,  0.0753, -0.1722, -0.0387],\n",
       "        [-0.1855,  0.0175,  0.1062,  ...,  0.0745, -0.0486,  0.0122],\n",
       "        [ 0.0293, -0.0241,  0.2465,  ...,  0.0277,  0.1306,  0.0731],\n",
       "        [-0.3415, -0.0400,  0.2486,  ...,  0.1367, -0.2919,  0.2983]]), hidden_states=None, past_key_values=None, attentions=None, cross_attentions=None)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "b25e4b78e9b1766f"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
