{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-25T13:02:15.742099Z",
     "start_time": "2025-08-25T13:02:15.738598Z"
    }
   },
   "cell_type": "code",
   "source": "import sys",
   "id": "78eb522d3083b1a4",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-25T13:03:48.472338Z",
     "start_time": "2025-08-25T13:02:19.895293Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch\n",
    "from modelscope import AutoModelForCausalLM, AutoTokenizer\n",
    "\n",
    "model_name = \"Qwen/Qwen3-4B\"\n",
    "\n",
    "# load the tokenizer and the model\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_name,\n",
    "    load_in_4bit=True,\n",
    "    torch_dtype=\"auto\",\n",
    "    device_map=\"cuda\"\n",
    ")"
   ],
   "id": "1e636daef600ef4",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\conda_env\\vllm\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading Model from https://www.modelscope.cn to directory: C:\\Users\\Zzz\\.cache\\modelscope\\hub\\models\\Qwen\\Qwen3-4B\n",
      "Downloading Model from https://www.modelscope.cn to directory: C:\\Users\\Zzz\\.cache\\modelscope\\hub\\models\\Qwen\\Qwen3-4B\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The `load_in_4bit` and `load_in_8bit` arguments are deprecated and will be removed in the future versions. Please, pass a `BitsAndBytesConfig` object in `quantization_config` argument instead.\n",
      "Loading checkpoint shards: 100%|██████████| 3/3 [00:09<00:00,  3.33s/it]\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-25T13:58:46.743038Z",
     "start_time": "2025-08-25T13:58:46.734792Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# prepare the model input\n",
    "prompt = \"中文回答 你是什么\"\n",
    "messages = [\n",
    "    {\"role\": \"user\", \"content\": prompt}\n",
    "]\n",
    "\n",
    "#apply_chat_template 函数本身是通用的\n",
    "text = tokenizer.apply_chat_template(\n",
    "    messages,\n",
    "    tokenize=False,#表示 apply_chat_template 返回的是格式化好的字符串，而不是直接返回 token IDs。\n",
    "    add_generation_prompt=True,#这会在格式化好的对话字符串末尾添加一个特殊的 token（例如 \\n<|assistant|>\\n 或类似的），告诉模型“轮到你了，请开始生成回答”。\n",
    "    enable_thinking=True # Switches between thinking and non-thinking modes. Default is True.\n",
    ")"
   ],
   "id": "e663861457a21871",
   "outputs": [],
   "execution_count": 15
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-25T13:59:15.650506Z",
     "start_time": "2025-08-25T13:59:15.644799Z"
    }
   },
   "cell_type": "code",
   "source": [
    "model_inputs = tokenizer([text], return_tensors=\"pt\").to(model.device) #将前面生成的格式化字符串 text 进行分词，转换成模型可以处理的 token IDs。\n",
    "#return_tensors=\"pt\" 指定返回 PyTorch tensors。\n",
    "# model_inputs现在是一个字典，里面包含 input_ids 和 attention_mask 等，这是模型直接的输入"
   ],
   "id": "3145ebfb69f139c4",
   "outputs": [],
   "execution_count": 17
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-25T14:04:03.031258Z",
     "start_time": "2025-08-25T14:03:42.091535Z"
    }
   },
   "cell_type": "code",
   "source": [
    "generated_ids = model.generate(\n",
    "    **model_inputs,\n",
    "    max_new_tokens=32768\n",
    ")#首先，它会生成“思考”部分.中间用think分割,然后才是真正的答案\n",
    "output_ids = generated_ids[0][len(model_inputs.input_ids[0]):].tolist()#只保留模型生成的新 token（即从输入结束位置之后的部分）。"
   ],
   "id": "f09a2a8eff829309",
   "outputs": [],
   "execution_count": 23
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-25T13:04:42.454866Z",
     "start_time": "2025-08-25T13:04:18.538236Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# parsing thinking content\n",
    "try:\n",
    "    # rindex finding 151668 (</think>)\n",
    "    index = len(output_ids) - output_ids[::-1].index(151668)#到模型输出中第一个 </think>（token ID 151668）的准确位置。\n",
    "except ValueError:\n",
    "    index = 0\n",
    "#可能 enable_thinking 没有生效，或者模型没有生成思考部分\n",
    "\n",
    "thinking_content = tokenizer.decode(output_ids[:index], skip_special_tokens=True).strip(\"\\n\")\n",
    "content = tokenizer.decode(output_ids[index:], skip_special_tokens=True).strip(\"\\n\")\n",
    "\n",
    "print(\"thinking content:\", thinking_content)\n",
    "print(\"content:\", content)"
   ],
   "id": "73ef1bd1757ab8a9",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "thinking content: <think>\n",
      "嗯，用户问“你是什么”，我需要回答这个问题。首先，我需要确定用户的需求是什么。可能他们想了解我的身份或者功能。我应该从基本的介绍开始，比如我是通义千问，阿里巴巴集团旗下的语言模型。\n",
      "\n",
      "接下来，用户可能想知道我的用途，比如能否回答问题、创作内容、编程等。需要简要说明我的能力范围，比如多语言支持、逻辑推理、创造性和开放式对话。\n",
      "\n",
      "然后，用户可能有更深层的需求，比如他们可能在寻找一个可靠的助手，或者想了解我的技术背景。需要提到我是基于大规模数据训练的，能够处理各种任务，但也要注意不要过度承诺，比如不能保证所有问题都能回答。\n",
      "\n",
      "另外，用户可能有潜在的问题，比如隐私和安全，需要说明我的设计原则，比如遵循法律法规，保护用户隐私。\n",
      "\n",
      "最后，保持回答简洁明了，同时提供足够的信息让用户了解我的能力和用途。可能需要用分点的方式，但用户要求中文回答，所以保持自然的口语化表达。\n",
      "</think>\n",
      "content: 我是通义千问，阿里巴巴集团旗下的大型语言模型，我能够帮助您回答问题、创作内容、进行编程等。我的设计目标是提供可靠、安全、高效的对话体验，同时遵循法律法规和伦理规范。如果您有任何问题或需要帮助，欢迎随时告诉我！\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-23T01:52:54.205989Z",
     "start_time": "2025-08-23T01:52:54.197815Z"
    }
   },
   "cell_type": "code",
   "source": " output_ids",
   "id": "c3cae78571050a0e",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[151667,\n",
       " 198,\n",
       " 106287,\n",
       " 3837,\n",
       " 20002,\n",
       " 56007,\n",
       " 2073,\n",
       " 56568,\n",
       " 102021,\n",
       " 33590,\n",
       " 35946,\n",
       " 85106,\n",
       " 102104,\n",
       " 105073,\n",
       " 1773,\n",
       " 101140,\n",
       " 3837,\n",
       " 35946,\n",
       " 85106,\n",
       " 60610,\n",
       " 20002,\n",
       " 99172,\n",
       " 99794,\n",
       " 99245,\n",
       " 1773,\n",
       " 87267,\n",
       " 99650,\n",
       " 109623,\n",
       " 97611,\n",
       " 101294,\n",
       " 5373,\n",
       " 98380,\n",
       " 3837,\n",
       " 100631,\n",
       " 97611,\n",
       " 105795,\n",
       " 1773,\n",
       " 100622,\n",
       " 31935,\n",
       " 64559,\n",
       " 99320,\n",
       " 56007,\n",
       " 3837,\n",
       " 35946,\n",
       " 101909,\n",
       " 101951,\n",
       " 102064,\n",
       " 104949,\n",
       " 3837,\n",
       " 73670,\n",
       " 102104,\n",
       " 100646,\n",
       " 86119,\n",
       " 3837,\n",
       " 104223,\n",
       " 108704,\n",
       " 3837,\n",
       " 71817,\n",
       " 105051,\n",
       " 49567,\n",
       " 3407,\n",
       " 104326,\n",
       " 3837,\n",
       " 35946,\n",
       " 85106,\n",
       " 101118,\n",
       " 20002,\n",
       " 87267,\n",
       " 9370,\n",
       " 102193,\n",
       " 1773,\n",
       " 104560,\n",
       " 100714,\n",
       " 20002,\n",
       " 3837,\n",
       " 99172,\n",
       " 99794,\n",
       " 97611,\n",
       " 99788,\n",
       " 24968,\n",
       " 74763,\n",
       " 104560,\n",
       " 113129,\n",
       " 3837,\n",
       " 99172,\n",
       " 99794,\n",
       " 97611,\n",
       " 99361,\n",
       " 104449,\n",
       " 1773,\n",
       " 100632,\n",
       " 3837,\n",
       " 86119,\n",
       " 99792,\n",
       " 98237,\n",
       " 99534,\n",
       " 3837,\n",
       " 87267,\n",
       " 100009,\n",
       " 100714,\n",
       " 20002,\n",
       " 99172,\n",
       " 81167,\n",
       " 97611,\n",
       " 101294,\n",
       " 3407,\n",
       " 101889,\n",
       " 3837,\n",
       " 35946,\n",
       " 85106,\n",
       " 103944,\n",
       " 102104,\n",
       " 102188,\n",
       " 100136,\n",
       " 110485,\n",
       " 1773,\n",
       " 85106,\n",
       " 66394,\n",
       " 104198,\n",
       " 107076,\n",
       " 100338,\n",
       " 111477,\n",
       " 31935,\n",
       " 64559,\n",
       " 104800,\n",
       " 100048,\n",
       " 9370,\n",
       " 3837,\n",
       " 100751,\n",
       " 102104,\n",
       " 86119,\n",
       " 5373,\n",
       " 104223,\n",
       " 108704,\n",
       " 5373,\n",
       " 110569,\n",
       " 5373,\n",
       " 105293,\n",
       " 49567,\n",
       " 1773,\n",
       " 91572,\n",
       " 3837,\n",
       " 73670,\n",
       " 104496,\n",
       " 97611,\n",
       " 100772,\n",
       " 3837,\n",
       " 101912,\n",
       " 42140,\n",
       " 102064,\n",
       " 100143,\n",
       " 5373,\n",
       " 101128,\n",
       " 102285,\n",
       " 16744,\n",
       " 49567,\n",
       " 3407,\n",
       " 104019,\n",
       " 60533,\n",
       " 20002,\n",
       " 87267,\n",
       " 9370,\n",
       " 114246,\n",
       " 100354,\n",
       " 1773,\n",
       " 101912,\n",
       " 3837,\n",
       " 99650,\n",
       " 87267,\n",
       " 99172,\n",
       " 81167,\n",
       " 35946,\n",
       " 64471,\n",
       " 101650,\n",
       " 3837,\n",
       " 100631,\n",
       " 107189,\n",
       " 105149,\n",
       " 98380,\n",
       " 1773,\n",
       " 99999,\n",
       " 85106,\n",
       " 102017,\n",
       " 97611,\n",
       " 100661,\n",
       " 3837,\n",
       " 101912,\n",
       " 100789,\n",
       " 107232,\n",
       " 5373,\n",
       " 42140,\n",
       " 102064,\n",
       " 100143,\n",
       " 5373,\n",
       " 105051,\n",
       " 99788,\n",
       " 49567,\n",
       " 3407,\n",
       " 100161,\n",
       " 3837,\n",
       " 101071,\n",
       " 107189,\n",
       " 114078,\n",
       " 105427,\n",
       " 3837,\n",
       " 101912,\n",
       " 64471,\n",
       " 85106,\n",
       " 104496,\n",
       " 112811,\n",
       " 108023,\n",
       " 57191,\n",
       " 116541,\n",
       " 1773,\n",
       " 77288,\n",
       " 86119,\n",
       " 99792,\n",
       " 101041,\n",
       " 3837,\n",
       " 87267,\n",
       " 104689,\n",
       " 106071,\n",
       " 106375,\n",
       " 1773,\n",
       " 100662,\n",
       " 102104,\n",
       " 110485,\n",
       " 30858,\n",
       " 34187,\n",
       " 3837,\n",
       " 91572,\n",
       " 102994,\n",
       " 99558,\n",
       " 98380,\n",
       " 8997,\n",
       " 151668,\n",
       " 271,\n",
       " 104198,\n",
       " 31935,\n",
       " 64559,\n",
       " 99320,\n",
       " 56007,\n",
       " 3837,\n",
       " 107076,\n",
       " 100338,\n",
       " 111477,\n",
       " 31935,\n",
       " 64559,\n",
       " 104800,\n",
       " 100048,\n",
       " 104197,\n",
       " 100176,\n",
       " 102064,\n",
       " 104949,\n",
       " 1773,\n",
       " 35946,\n",
       " 100006,\n",
       " 102104,\n",
       " 100646,\n",
       " 86119,\n",
       " 5373,\n",
       " 104223,\n",
       " 108704,\n",
       " 5373,\n",
       " 110569,\n",
       " 5373,\n",
       " 105293,\n",
       " 5373,\n",
       " 105395,\n",
       " 5373,\n",
       " 111540,\n",
       " 49567,\n",
       " 3837,\n",
       " 100143,\n",
       " 42140,\n",
       " 102064,\n",
       " 101069,\n",
       " 1773,\n",
       " 97611,\n",
       " 70500,\n",
       " 100160,\n",
       " 20412,\n",
       " 99553,\n",
       " 102188,\n",
       " 5373,\n",
       " 115404,\n",
       " 5373,\n",
       " 99795,\n",
       " 9370,\n",
       " 105051,\n",
       " 101904,\n",
       " 3837,\n",
       " 91572,\n",
       " 106466,\n",
       " 112811,\n",
       " 108023,\n",
       " 33108,\n",
       " 106221,\n",
       " 1773,\n",
       " 102056,\n",
       " 110117,\n",
       " 86119,\n",
       " 57191,\n",
       " 85106,\n",
       " 100364,\n",
       " 3837,\n",
       " 100437,\n",
       " 102422,\n",
       " 107666,\n",
       " 6313,\n",
       " 151645]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "a02b536822934ddc"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
